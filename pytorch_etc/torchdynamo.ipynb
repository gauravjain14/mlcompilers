{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Before we delve into trying to `jit` compile a pytorch module, it is important\n",
    "to understand what `Pytorch 2.0` brings with `torch.compile` and why `torch.jit.script`\n",
    "or `FX tracing` weren't good enough and what were the limitations.\n",
    "\n",
    "Refer to: https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html#comparison-to-torchscript-and-fx-tracing\n",
    "\n",
    "Essentially, scripting or tracing either error out or only capture the activated path in control\n",
    "flow instructions thus being erroneous or non-functional.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "We use `torch.dynamo` here to capture the graphs generated for the corresponding `nn.Module` and understand\n",
    "the number of `graph-breaks` in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/gaurav/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "access_token = os.environ[\"HF_ACCESS_TOKEN\"]\n",
    "login(token=access_token)\n",
    "\n",
    "os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"  # Dumps files in `torch_compile_debug/`\n",
    "\n",
    "# Choose which logs to enable\n",
    "# os.environ[\"TORCH_LOGS\"] = \"+dynamo,+aot_graphs,+inductor,+guards,+graph\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"+dynamo,guards,bytecode,graph_code\"\n",
    "os.environ[\"TORCH_LOGS\"] = \"+dynamo,graph_code\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch._dynamo import optimize\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First things first - \n",
    "\n",
    "The TorchDynamo deep-dive resource https://pytorch.org/docs/stable/torch.compiler_dynamo_deepdive.html#torch-compiler-dynamo-deepdive\n",
    "\n",
    "![TorchDynamo Guards](https://i.imgur.com/Pvq65gt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:54:18,148] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:18,149] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:18,149] torch._dynamo.eval_frame: [DEBUG] skipping helper /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:18,149] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:18,149] torch._dynamo.eval_frame: [DEBUG] skipping enable_dynamic /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-28 20:54:18,149] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:18,150] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:18,151] [0/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:18,153] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:18,153] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 20:54:18,158] [0/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:18,160] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:18,160] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:18,160] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 20:54:18,160] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:18,160] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 20:54:18,161] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,161] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:18,161] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 20:54:18,161] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 20:54:18,163] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 20:54:18,164] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:16\n",
      "[2024-12-28 20:54:18,164] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 20:54:18,164] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 20:54:18,164] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,164] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,165] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:18,165] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:17\n",
      "[2024-12-28 20:54:18,165] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return (n + 1) * y\n",
      "[2024-12-28 20:54:18,165] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 20:54:18,165] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_1823720/2999559549.py:17\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 20:54:18,166] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~^~~\n",
      "[2024-12-28 20:54:18,167] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:18,167] [0/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 20:54:18,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:18,168] [0/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/2999559549.py, line 17 in fn>], graph_break=False)\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_0 =====\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.0 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:17, code: return (n + 1) * y\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = 3 * pow_1;  pow_1 = None\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul,)\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_0 <eval_with_key>.0 opcode         name    target                   args        kwargs\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ----------  --------\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()          {}\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1   <built-in function pow>  (l_x_, 2)   {}\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (3, pow_1)  {}\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((mul,),)   {}\n",
      "[2024-12-28 20:54:18,169] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_0 =====\n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (200,)\n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:18,172] [0/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 20:54:23,178] [0/0] torch._inductor.debug: [WARNING] model___54 debug trace: /tmp/torchinductor_gaurav/ey/ceyso437ujvadsmwtcpdjwqr5oibtz6v4tzy4jmeunspjeplpybs.debug\n",
      "[2024-12-28 20:54:23,180] [0/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 20:54:23,207] [0/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:23,207] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # if n >= 0:  # mp/ipykernel_1823720/2999559549.py:16 in fn\n",
      "[2024-12-28 20:54:23,208] [0/0] torch._dynamo.guards.__guards: [DEBUG] L['n'] == 2                                                   # if n >= 0:  # mp/ipykernel_1823720/2999559549.py:16 in fn\n",
      "[2024-12-28 20:54:23,208] [0/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,209] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,209] [0/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,209] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,210] [0/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,211] [0/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,212] torch._dynamo.eval_frame: [DEBUG] skipping _fn /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-28 20:54:23,212] torch._dynamo.eval_frame: [DEBUG] skipping nothing /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-28 20:54:23,213] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:23,213] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-28 20:54:23,213] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:23,213] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function fn in /tmp/ipykernel_1823720/2999559549.py:13', 'set env var TORCHDYNAMO_REPORT_GUARD_FAILURES=1 to debug further')\n",
      "[2024-12-28 20:54:23,214] [0/1] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:23,214] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:23,214] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 20:54:23,215] [0/1] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:23,215] [0/1] torch._dynamo.variables.builder: [DEBUG] automatic dynamic int L['n'] val 3 != 2\n",
      "[2024-12-28 20:54:23,215] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 20:54:23,216] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 20:54:23,217] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 20:54:23,217] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:16\n",
      "[2024-12-28 20:54:23,217] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 20:54:23,217] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 20:54:23,218] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,218] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:23,218] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call ge from fn /tmp/ipykernel_1823720/2999559549.py:16\n",
      "[2024-12-28 20:54:23,218] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]     if n >= 0:\n",
      "[2024-12-28 20:54:23,218] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:17\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return (n + 1) * y\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,219] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from fn /tmp/ipykernel_1823720/2999559549.py:17\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~^~~\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [SymNodeVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_1823720/2999559549.py:17\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 20:54:23,220] [0/1] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~^~~\n",
      "[2024-12-28 20:54:23,221] [0/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:23,221] [0/1] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 20:54:23,221] [0/1] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:23,221] [0/1] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/2999559549.py, line 17 in fn>], graph_break=False)\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_1 =====\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.153 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor, L_n_ : torch.SymInt):\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_n_ = L_n_\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:16, code: if n >= 0:\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         ge = l_n_ >= 0\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:17, code: return (n + 1) * y\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_n_ + 1;  l_n_ = None\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = add * pow_1;  add = pow_1 = None\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul,)\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_1 <eval_with_key>.153 opcode         name    target                   args          kwargs\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ------------  --------\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()            {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_n_    L_n_                     ()            {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1   <built-in function pow>  (l_x_, 2)     {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  ge      <built-in function ge>   (l_n_, 0)     {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>  (l_n_, 1)     {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (add, pow_1)  {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((mul,),)     {}\n",
      "[2024-12-28 20:54:23,222] [0/1] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_1 =====\n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (200,)\n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:23,223] [0/1] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 20:54:23,248] [0/1] torch._inductor.debug: [WARNING] model__19_inference_55 debug trace: /tmp/torchinductor_gaurav/zj/czjxff7ejgernmy4f3baz7dnktoajbccc4mqrcgjeny6kniat26o.debug\n",
      "[2024-12-28 20:54:23,250] [0/1] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 20:54:23,252] [0/1] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:23,253] [0/1] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,254] [0/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,254] [0/1] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,255] [0/1] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,255] [0/1] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,256] [0/1] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,256] [0/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,256] [0/1] torch._dynamo.guards.__guards: [DEBUG] L['n'] >= 0                                                   # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,258] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:23,259] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function fn in /tmp/ipykernel_1823720/2999559549.py:13', 'set env var TORCHDYNAMO_REPORT_GUARD_FAILURES=1 to debug further')\n",
      "[2024-12-28 20:54:23,259] [0/2] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:23,259] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:13\n",
      "[2024-12-28 20:54:23,259] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 20:54:23,260] [0/2] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:23,261] [0/2] torch._dynamo.variables.builder: [DEBUG] automatic dynamic int L['n'] val -2 != None\n",
      "[2024-12-28 20:54:23,261] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:23,261] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:23,261] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 20:54:23,261] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:23,262] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 20:54:23,262] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:23,262] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_1823720/2999559549.py:15\n",
      "[2024-12-28 20:54:23,262] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 20:54:23,262] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 20:54:23,263] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 20:54:23,263] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:16\n",
      "[2024-12-28 20:54:23,263] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 20:54:23,264] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 20:54:23,264] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,264] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:23,265] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call ge from fn /tmp/ipykernel_1823720/2999559549.py:16\n",
      "[2024-12-28 20:54:23,265] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]     if n >= 0:\n",
      "[2024-12-28 20:54:23,265] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^\n",
      "[2024-12-28 20:54:23,265] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,266] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2999559549.py:19\n",
      "[2024-12-28 20:54:23,266] [0/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return y / n\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n [TensorVariable()]\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), SymNodeVariable()]\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from fn /tmp/ipykernel_1823720/2999559549.py:19\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]         return y / n\n",
      "[2024-12-28 20:54:23,267] [0/2] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~\n",
      "[2024-12-28 20:54:23,268] [0/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/2999559549.py, line 19 in fn>], graph_break=False)\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_2 =====\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.161 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor, L_n_ : torch.SymInt):\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_n_ = L_n_\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:16, code: if n >= 0:\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         ge = l_n_ >= 0\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2999559549.py:19, code: return y / n\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = pow_1 / l_n_;  pow_1 = l_n_ = None\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (truediv,)\n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:23,269] [0/2] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_2 <eval_with_key>.161 opcode         name     target                       args           kwargs\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------  ---------------------------  -------------  --------\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_     L_x_                         ()             {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_n_     L_n_                         ()             {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1    <built-in function pow>      (l_x_, 2)      {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  ge       <built-in function ge>       (l_n_, 0)      {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv  <built-in function truediv>  (pow_1, l_n_)  {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] output         output   output                       ((truediv,),)  {}\n",
      "[2024-12-28 20:54:23,270] [0/2] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_2 =====\n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (200,)\n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:23,271] [0/2] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 20:54:23,293] [0/2] torch._inductor.debug: [WARNING] model__20_inference_56 debug trace: /tmp/torchinductor_gaurav/6o/c6oai42bsq4si3ohtop4mz5hghunk6krbrn2gprgcvcdk2yrty2q.debug\n",
      "[2024-12-28 20:54:23,295] [0/2] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 20:54:23,297] [0/2] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:23,297] [0/2] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,298] [0/2] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,298] [0/2] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,299] [0/2] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,299] [0/2] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,300] [0/2] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,300] [0/2] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:23,301] [0/2] torch._dynamo.guards.__guards: [DEBUG] L['n'] < 0                                                    # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,301] [0/2] torch._dynamo.guards.__guards: [DEBUG] -9223372036854775808 <= L['n']                                # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 20:54:23,302] [0/2] torch._dynamo.guards.__guards: [DEBUG] -9223372036854775808 <= L['n']                                # _dynamo/output_graph.py:339 in init_ambient_guards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.0558e+00, -4.2923e-01, -5.7294e-02, -4.9200e-01, -2.0633e-01,\n",
       "        -5.2345e-02, -6.3143e-01, -3.2565e-01, -1.6012e-02, -5.6662e-01,\n",
       "        -1.1228e-01, -3.9566e-02, -1.4540e-01, -1.2521e-02, -2.6969e-02,\n",
       "        -2.6901e-01, -2.8028e-01, -8.4713e-01, -1.8860e-01, -2.5872e-03,\n",
       "        -8.5205e-04, -6.2060e-01, -1.3601e-01, -1.4168e+00, -2.3652e-01,\n",
       "        -1.4441e-01, -9.1329e-02, -5.7665e-02, -1.3922e-01, -5.2027e-01,\n",
       "        -2.7347e-01, -9.1317e-01, -2.8845e-01, -1.0548e+00, -8.8559e-01,\n",
       "        -7.9747e-02, -1.3130e-01, -1.1913e+00, -2.5932e+00, -1.1758e+00,\n",
       "        -5.3491e-04, -7.2466e-04, -8.3604e-03, -1.6489e+00, -6.6217e-03,\n",
       "        -7.6611e-01, -1.3994e-02, -1.8921e-03, -7.7017e-02, -2.7912e-01,\n",
       "        -1.2096e-02, -3.9584e-02, -2.0969e+00, -1.0752e+00, -1.5613e-01,\n",
       "        -1.0834e-02, -4.1103e-02, -1.3950e-02, -4.0941e-01, -3.5636e-03,\n",
       "        -1.7018e+00, -3.3508e-02, -1.2706e+00, -2.0389e-04, -4.2713e-02,\n",
       "        -2.3922e-01, -1.3649e+00, -4.4785e-01, -6.9144e-02, -8.0306e-01,\n",
       "        -1.7497e-01, -3.1187e-01, -1.1172e-01, -1.0047e-02, -6.6211e-02,\n",
       "        -4.7329e-02, -3.5242e-02, -1.5394e-03, -1.1972e-01, -9.7452e-03,\n",
       "        -7.2847e-01, -2.8612e-02, -9.0726e-01, -1.1020e+00, -4.0348e-01,\n",
       "        -7.3496e-01, -2.2106e-02, -4.4513e-03, -6.9898e-03, -3.3545e-01,\n",
       "        -2.0692e-01, -1.5565e+00, -4.3102e+00, -5.2524e-01, -2.4904e-02,\n",
       "        -7.4614e-02, -4.8146e-01, -3.4214e-01, -2.0865e+00, -2.8261e-01,\n",
       "        -9.2192e-01, -2.4310e-01, -1.6974e-04, -2.6854e+00, -3.4902e-01,\n",
       "        -1.6418e+00, -1.2281e+00, -2.3124e-01, -1.3276e-04, -4.7060e-02,\n",
       "        -4.8502e-02, -8.1537e-01, -2.4721e+00, -1.6864e-01, -3.4371e-01,\n",
       "        -2.1524e-01, -8.4506e-05, -1.0882e-01, -1.1870e-01, -3.9166e-01,\n",
       "        -1.1071e-01, -8.7851e-02, -2.3752e-01, -2.6112e-04, -4.8875e-02,\n",
       "        -1.9353e-02, -4.4509e-02, -5.7686e-04, -4.4052e+00, -2.4911e+00,\n",
       "        -7.4699e-01, -1.6785e+00, -3.6059e-01, -8.3133e-01, -2.7322e-01,\n",
       "        -6.1764e-02, -4.1806e-01, -5.7909e-01, -6.6566e-02, -1.1229e-01,\n",
       "        -1.5700e+00, -2.7004e-01, -2.0161e+00, -3.2325e-01, -4.4946e-01,\n",
       "        -6.9275e-01, -5.0914e-03, -3.3692e-03, -2.1525e+00, -1.9618e+00,\n",
       "        -3.3905e-01, -2.9311e-02, -1.0804e-03, -8.0035e-01, -4.2590e-02,\n",
       "        -4.2651e+00, -1.7704e-01, -1.1012e-01, -2.0507e+00, -7.7951e-01,\n",
       "        -1.0054e-02, -1.3735e-01, -7.1441e-02, -2.1627e-02, -3.0248e-02,\n",
       "        -1.1218e-02, -1.7510e+00, -1.6900e-02, -2.0870e+00, -3.7476e-03,\n",
       "        -1.8739e-02, -1.9530e-01, -8.0562e-03, -1.5372e-01, -9.0820e-01,\n",
       "        -6.5362e-01, -5.5872e-01, -6.0148e-02, -4.2720e+00, -4.5324e-03,\n",
       "        -2.7285e-02, -2.7524e+00, -3.1850e-01, -2.9265e-01, -8.6451e-02,\n",
       "        -1.6472e-01, -4.6648e-01, -4.1431e-01, -6.1175e-01, -7.3072e-02,\n",
       "        -3.2281e-02, -3.7546e-01, -4.4071e+00, -4.4221e-01, -3.6390e-01,\n",
       "        -1.6898e+00, -1.6671e-01, -9.3867e-04, -3.1177e-02, -8.7346e-01])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Set the environment variable\n",
    "# os.environ[\"TORCHDYNAMO_REPORT_GUARD_FAILURES\"] = \"1\"\n",
    "\n",
    "# The other interesting thing to note here is that Dynamo removed the second argument to the function. \n",
    "# Instead, it treated it as a constant and recorded the result of the operation n + 1 in the graph. \n",
    "# This is another feature of Dynamo: Dynamo will treat as constant any non-tensor value… other than ints.\n",
    "\n",
    "# The last defining property of Dynamo is that it knows how to handle dynamic shapes. Symbolic shapes refer to \n",
    "# Dynamo’s ability of tracing shapes, and more generally, integers, rather than leaving them as constants. \n",
    "# This allows for avoiding recompilations and deploying generic models that work for any size in production.\n",
    "\n",
    "@torch.compile\n",
    "def fn(x, n):\n",
    "    y = x ** 2\n",
    "    if n >= 0:\n",
    "        return (n + 1) * y\n",
    "    else:\n",
    "        return y / n\n",
    "\n",
    "x = torch.randn(200)\n",
    "fn(x, 2)\n",
    "fn(x, 3)\n",
    "fn(x, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:412: UserWarning: changing options to `torch.compile()` may require calling `torch._dynamo.reset()` to take effect\n",
      "  warnings.warn(\n",
      "[2024-12-28 20:54:34,067] torch._dynamo.eval_frame: [DEBUG] skipping patch /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 20:54:34,068] torch._dynamo.eval_frame: [DEBUG] skipping ConfigPatch /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 20:54:34,068] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 20:54:34,069] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:34,069] [1/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_1823720/1791670339.py:3\n",
      "[2024-12-28 20:54:34,070] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/1791670339.py:3\n",
      "[2024-12-28 20:54:34,070] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile(dynamic=True)\n",
      "[2024-12-28 20:54:34,070] [1/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['a'] (8,) [<DimDynamic.DUCK: 1>] [None]\n",
      "[2024-12-28 20:54:34,075] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:34,075] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/1791670339.py:5\n",
      "[2024-12-28 20:54:34,075] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 20:54:34,075] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2024-12-28 20:54:34,076] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:54:34,076] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call size from fn /tmp/ipykernel_1823720/1791670339.py:5\n",
      "[2024-12-28 20:54:34,076] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 20:54:34,076] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^^\n",
      "[2024-12-28 20:54:34,078] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SizeVariable()]\n",
      "[2024-12-28 20:54:34,078] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:34,078] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:34,078] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:34,079] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_1823720/1791670339.py:5\n",
      "[2024-12-28 20:54:34,079] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 20:54:34,079] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ~~~~~~~~~~~^~~\n",
      "[2024-12-28 20:54:34,080] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 16 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:34,080] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP < [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:34,080] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call lt from fn /tmp/ipykernel_1823720/1791670339.py:5\n",
      "[2024-12-28 20:54:34,080] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 20:54:34,080] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:34,082] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 46 [SymNodeVariable()]\n",
      "[2024-12-28 20:54:34,085] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/1791670339.py:8\n",
      "[2024-12-28 20:54:34,085] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return a + 1\n",
      "[2024-12-28 20:54:34,086] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2024-12-28 20:54:34,086] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2024-12-28 20:54:34,086] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:34,087] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from fn /tmp/ipykernel_1823720/1791670339.py:8\n",
      "[2024-12-28 20:54:34,087] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return a + 1\n",
      "[2024-12-28 20:54:34,087] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~\n",
      "[2024-12-28 20:54:34,089] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:34,089] [1/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 20:54:34,089] [1/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:34,089] [1/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/1791670339.py, line 8 in fn>], graph_break=False)\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_3 =====\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.169 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, s0 : torch.SymInt, L_a_ : torch.Tensor):\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_a_ = L_a_\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/1791670339.py:5, code: if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         size = l_a_.size()\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = size[0];  size = None\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = getitem * 2;  getitem = None\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         lt = mul < 16;  mul = None\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/1791670339.py:8, code: return a + 1\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_a_ + 1;  l_a_ = None\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add,)\n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:34,090] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_3 <eval_with_key>.169 opcode         name     target                       args          kwargs\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------  ---------------------------  ------------  --------\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    s0       s0                           ()            {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_a_     L_a_                         ()            {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    size     size                         (l_a_,)       {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem  <built-in function getitem>  (size, 0)     {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul      <built-in function mul>      (getitem, 2)  {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  lt       <built-in function lt>       (mul, 16)     {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add      <built-in function add>      (l_a_, 1)     {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output   output                       ((add,),)     {}\n",
      "[2024-12-28 20:54:34,091] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_3 =====\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_a_: (s0,)\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_a_ (concrete): (8,)\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (s0,)\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add (concrete): (8,)\n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:34,092] [1/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 20:54:34,118] [1/0] torch._inductor.debug: [WARNING] model__21_inference_57 debug trace: /tmp/torchinductor_gaurav/fa/cfalodpsums5vhxbcetidoq4q2z4loklyqys5glcdrgqa3vclbts.debug\n",
      "[2024-12-28 20:54:34,120] [1/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 20:54:34,123] [1/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:34,123] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['a'], 117686336)                           # if a.shape[0] * 2 < 16:  # mp/ipykernel_1823720/1791670339.py:5 in fn\n",
      "[2024-12-28 20:54:34,125] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['a'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:34,125] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:34,126] [1/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:34,127] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:34,127] [1/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:34,128] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['a'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[None], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:34,128] [1/0] torch._dynamo.guards.__guards: [DEBUG] 2*L['a'].size()[0] >= 16                                      # _dynamo/output_graph.py:339 in init_ambient_guards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9796,  1.8508,  0.8055, -0.5374,  0.4547, -0.6044,  0.6725,  0.8765])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.compile(dynamic=True)\n",
    "def fn(a):\n",
    "    if a.shape[0] * 2 < 16:\n",
    "        return a\n",
    "    else:\n",
    "        return a + 1\n",
    "\n",
    "fn(torch.randn(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LLaMAFirstLayerModel(nn.Module):\n",
    "    def __init__(self, llama_model_name: str, output_dim: int):\n",
    "        super(LLaMAFirstLayerModel, self).__init__()\n",
    "\n",
    "        # Load the LLaMA model\n",
    "        full_llama = AutoModel.from_pretrained(llama_model_name)\n",
    "\n",
    "        # Extract and store the embedding layer\n",
    "        self.embed_tokens = full_llama.embed_tokens\n",
    "\n",
    "        # Extract and store the first decoder layer\n",
    "        self.first_layer = full_llama.layers[0]\n",
    "\n",
    "        # Linear layer to map to output dimensions\n",
    "        llama_hidden_dim = full_llama.config.hidden_size\n",
    "        self.linear = nn.Linear(llama_hidden_dim, output_dim)\n",
    "\n",
    "        # Softmax for output probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Explicit typing of input_ids and attention_mask for TorchScript\n",
    "    def forward(self, input_ids):\n",
    "        # Generate embeddings\n",
    "        embeddings = self.embed_tokens(input_ids)\n",
    "\n",
    "        # Check if position_ids need to be explicitly handled\n",
    "        position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Pass through the first layer with position_ids\n",
    "        layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
    "\n",
    "        # Pool the output (mean along sequence dimension)\n",
    "        pooled_output = torch.mean(layer_output, dim=1)\n",
    "\n",
    "        # Map to output dimension\n",
    "        logits = self.linear(pooled_output)\n",
    "\n",
    "        # Apply softmax\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # Replace with actual model name\n",
    "output_dim = 10  # Number of classes for classification\n",
    "\n",
    "# Initialize the model\n",
    "model = LLaMAFirstLayerModel(llama_model_name, output_dim).to(\"cuda\")\n",
    "\n",
    "# Example tokenizer and input\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "example_text = [\"This is an example input.\"]\n",
    "inputs = tokenizer(example_text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:694: UserWarning: explain(f, *args, **kwargs) is deprecated, use explain(f)(*args, **kwargs) instead.  If you don't migrate, we may break your explain call in the future if your user defined kwargs conflict with future kwargs added to explain(f).\n",
      "  warnings.warn(\n",
      "[2024-12-28 20:54:44,202] torch._dynamo.eval_frame: [DEBUG] skipping _wrapped_call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 20:54:44,203] torch._dynamo.eval_frame: [DEBUG] skipping _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 20:54:44,203] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,204] [2/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_1823720/343866.py:26\n",
      "[2024-12-28 20:54:44,205] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:26\n",
      "[2024-12-28 20:54:44,205] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-28 20:54:44,206] [2/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:44,207] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,207] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:28\n",
      "[2024-12-28 20:54:44,207] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:44,207] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,207] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,208] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,208] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,208] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,209] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_1823720/343866.py:28\n",
      "[2024-12-28 20:54:44,209] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:44,209] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,211] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 20:54:44,211] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:44,211] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:44,212] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,212] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,212] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:44,213] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,213] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:54:44,213] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,213] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,214] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,214] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,214] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:54:44,214] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:44,215] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:44,215] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:44,223] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:44,223] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:44,223] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,225] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:44,226] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:44,228] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 20:54:44,228] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:44,228] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:44,228] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,228] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,229] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,229] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,229] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,229] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,230] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,230] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:44,230] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:44,230] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,230] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,234] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,234] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,234] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,234] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,234] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,235] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,235] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,235] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,236] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,236] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,236] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,237] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,238] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,238] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,238] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,238] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,239] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,239] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,239] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,240] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,240] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,240] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,240] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,241] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,241] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,241] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,241] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,241] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,242] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,243] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,244] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,245] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,245] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,245] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,245] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,245] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,246] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,246] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:44,246] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,246] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,247] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,248] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,248] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,248] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,248] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371007a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:54:44,249] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,249] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:44,250] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,250] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,250] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:44,251] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,252] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:44,252] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,252] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:44,252] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,253] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,253] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,254] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,254] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,255] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,255] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:44,255] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,255] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,376] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,376] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,376] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,377] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,377] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,377] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,377] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,378] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,378] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,378] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,378] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,379] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,380] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,380] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,380] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,380] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,380] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,381] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,381] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,381] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,381] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,382] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,383] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,384] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,385] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,385] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,385] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:44,385] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,385] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,386] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,386] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,386] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,386] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,386] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:44,387] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,388] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:44,388] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,388] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,388] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:44,389] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,389] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:44,390] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,390] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,391] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:44,391] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:44,391] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,391] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:44,391] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,392] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,393] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,393] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,393] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,393] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:44,394] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:44,395] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,395] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,395] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,395] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,395] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:44,396] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:44,397] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:44,397] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,398] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,398] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,398] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,399] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,399] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,399] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,400] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:44,401] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,401] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,401] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,401] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:44,402] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,402] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:44,403] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,403] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,404] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:44,404] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,404] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,404] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,405] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,406] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,406] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,406] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,406] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,407] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,408] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,408] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,408] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,409] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,409] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,409] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,410] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,410] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,411] [2/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:44,411] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,412] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,413] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,414] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,415] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,415] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,415] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,416] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,416] [2/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:44,416] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,416] [2/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,417] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,417] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,417] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,417] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,417] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:54:44,418] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,418] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,418] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,418] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:44,418] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:44,419] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,420] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:54:44,421] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,422] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,422] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,422] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,422] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:54:44,423] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,426] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,426] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,427] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,428] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,428] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,428] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,429] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,429] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,430] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,430] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,431] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,431] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,432] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,432] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,433] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,433] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,433] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,433] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,434] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,434] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,434] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,434] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,435] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,435] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,435] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,436] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,436] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,436] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,436] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,436] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,437] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,438] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,439] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,440] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,440] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,440] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,441] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,441] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,441] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,442] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,442] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,442] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:44,443] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,443] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,443] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,446] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,446] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,446] [2/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,447] [2/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:44,449] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,449] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:44,451] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:44,451] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:44,452] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:44,452] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:44,453] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:44,453] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:44,454] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,454] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,454] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:44,454] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:44,455] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:44,456] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,457] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,457] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:44,458] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,458] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,458] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,459] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,459] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:44,459] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,459] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,460] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:44,461] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,461] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,462] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,462] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,462] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,463] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,463] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,464] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,464] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,464] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,465] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,465] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,465] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,467] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,468] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,468] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,468] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,468] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,469] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,470] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,470] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,471] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,471] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,471] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,474] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,474] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,474] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,474] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,475] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,476] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,476] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,476] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,477] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,477] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,477] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,479] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,479] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,479] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,480] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:44,480] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,481] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,481] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,481] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,482] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,482] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,482] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,483] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,484] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,484] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,484] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,484] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,485] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,486] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,486] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,487] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,487] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,488] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,488] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,488] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,489] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,489] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,489] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,489] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:44,490] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,490] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,491] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,491] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,492] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,493] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,493] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,494] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,494] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,495] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,495] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,495] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,496] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,497] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,498] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,499] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,500] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,502] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,502] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,502] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,503] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,503] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,503] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,504] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:44,504] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,505] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,505] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,505] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,506] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,506] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,507] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,507] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,508] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,509] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,509] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,509] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,511] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,512] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,512] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,512] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,513] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,513] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,513] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,513] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,514] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,514] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,514] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:44,515] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:44,515] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,515] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,516] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,516] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,516] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,517] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:44,518] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:44,519] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,519] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:44,519] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:44,520] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:54:44,520] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,520] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,521] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,521] [2/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,522] [2/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:44,522] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:44,522] [2/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,522] [2/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,523] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,523] [2/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,523] [2/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x74371007a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:54:44,523] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:44,524] [2/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,524] [2/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,524] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,524] [2/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:44,527] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,527] [2/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_4 =====\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.177 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,528] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_4 <eval_with_key>.177 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7437e931cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 20:54:44,529] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_4 =====\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:44,530] [2/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,531] [2/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,533] [2/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:44,534] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780047764688)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1823720/343866.py:28 in forward\n",
      "[2024-12-28 20:54:44,534] [2/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1823720/343866.py:28 in forward\n",
      "[2024-12-28 20:54:44,534] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117686336)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_1823720/343866.py:31 in forward\n",
      "[2024-12-28 20:54:44,535] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,535] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,535] [2/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,536] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,536] [2/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,536] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,558] torch._dynamo.eval_frame: [DEBUG] skipping __getattr__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 20:54:44,559] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,560] [3/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:54:44,561] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:54:44,561] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:44,562] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:44,563] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:44,565] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,565] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 20:54:44,565] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:44,565] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,565] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:44,566] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:54:44,566] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:44,566] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,566] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,566] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,567] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,567] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,567] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:54:44,567] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:44,567] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,568] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,571] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,571] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,572] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,572] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,572] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,572] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,573] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,573] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,574] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,574] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,574] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,575] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,575] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,575] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,575] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,575] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,576] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,576] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,576] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,577] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,577] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,577] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,578] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,578] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,578] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,579] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,579] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,579] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,580] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,580] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,580] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,580] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,580] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,581] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,581] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,581] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,581] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,582] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,583] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,584] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,584] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,584] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,584] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,585] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,585] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,585] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:44,585] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,586] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,586] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,586] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,586] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,586] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,587] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:44,587] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,587] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:44,588] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,588] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,588] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:44,588] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,588] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:44,590] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,590] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,590] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:44,590] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,591] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:44,591] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:44,592] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,593] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,594] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,594] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,594] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,594] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:44,594] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:44,595] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,595] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,595] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,595] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,595] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:44,596] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:44,596] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,597] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:44,599] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,600] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,602] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,604] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,608] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,608] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,608] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,610] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,610] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,610] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,610] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,611] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,612] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,612] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,612] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,612] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,613] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:44,614] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,614] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,615] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,616] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,616] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,616] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,616] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,617] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,617] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:44,617] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,618] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,618] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,618] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:44,618] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,618] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,619] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:54:44,619] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,619] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,619] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 20:54:44,619] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:54:44,620] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 20:54:44,621] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,622] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,623] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:54:44,624] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:54:44,625] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,627] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,627] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,628] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,628] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,628] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,628] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,628] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,629] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,629] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,629] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,629] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,629] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,630] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,630] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,630] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,630] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,630] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,631] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,631] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,631] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,631] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,631] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,632] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,632] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,632] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,632] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,633] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,634] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,635] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,636] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,636] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,636] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:44,636] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,636] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,637] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,638] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,638] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,638] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,638] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:44,640] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:44,641] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:44,642] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:44,642] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,642] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,642] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,643] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,644] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:44,644] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,644] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,644] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,645] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,646] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,646] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,646] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,646] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,649] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,649] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,649] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,650] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,650] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,650] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,650] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,650] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,651] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,651] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,651] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,654] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,656] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,656] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,658] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,658] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,659] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,659] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,659] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,660] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,660] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,660] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,665] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,665] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,665] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,665] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:44,666] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,666] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,666] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,666] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,667] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,667] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,667] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,668] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,668] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,669] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,669] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,669] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,671] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,671] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,672] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,672] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,675] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,676] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,676] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,676] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,677] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,678] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,678] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,678] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:44,679] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,679] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,680] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,680] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,681] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,681] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,681] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,682] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,682] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,683] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,683] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,683] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,684] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,684] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,684] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,685] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,685] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,685] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,685] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,685] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,686] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,686] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,686] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,686] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:44,686] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,687] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,687] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,687] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,687] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,687] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,688] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,689] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,689] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,690] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,691] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,691] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,691] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:44,691] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,692] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:44,693] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:44,693] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,693] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:44,694] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:44,694] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,694] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,694] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,694] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,695] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,695] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:44,696] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:44,696] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:44,696] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,696] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,697] [3/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:44,699] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,699] [3/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:44,700] [3/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_6 =====\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.178 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_6 <eval_with_key>.178 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7437e931cde0>  (add,)                                    {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 20:54:44,701] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_6 =====\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,702] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:44,703] [3/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,703] [3/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,707] [3/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:44,707] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780049436176)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,708] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,708] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:44,708] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:44,708] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,709] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,709] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117686336)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 20:54:44,710] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,710] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,710] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,710] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,711] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,711] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:44,711] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,712] [3/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,712] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,712] [3/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,712] [3/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:54:44,713] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,713] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,713] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,714] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,714] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,714] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,715] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,715] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:44,715] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,716] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,746] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,748] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:54:44,749] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:54:44,749] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:44,749] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:44,751] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:44,752] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:44,752] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:44,752] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:44,752] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:44,753] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:44,754] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,754] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:44,754] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:44,755] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,756] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:44,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,758] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:54:44,758] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,758] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,758] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,759] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,761] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,761] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:54:44,761] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,761] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,761] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,762] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,762] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,762] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,763] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:54:44,763] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,763] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,764] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,765] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:54:44,765] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,765] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,765] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,766] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,768] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,768] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:44,768] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,768] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:44,768] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,770] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,770] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,770] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,770] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,771] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:44,771] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,771] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,771] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,772] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,772] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,772] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,772] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,773] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:44,773] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,773] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,773] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,775] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,775] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,775] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,775] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,776] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,776] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,777] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:44,777] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,777] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,777] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,778] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,779] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,779] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:44,779] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,779] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:44,779] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,780] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,781] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,781] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,781] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:44,781] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,781] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,782] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:44,782] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,782] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,783] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,783] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,783] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:44,783] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,783] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,784] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:44,784] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 20:54:44,784] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:44,784] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:44,784] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:44,785] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,786] [4/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:44,787] [4/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:44,787] [4/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:44,788] [4/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_8 =====\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.179 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_8 <eval_with_key>.179 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 20:54:44,789] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_8 =====\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:44,790] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:44,791] [4/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,791] [4/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:44,802] [4/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:44,802] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127779758101328)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:54:44,803] [4/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:54:44,803] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:44,804] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:44,804] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,805] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,805] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 20:54:44,806] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,806] [4/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,806] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,807] [4/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:44,807] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40240208)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 20:54:44,808] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,809] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:44,833] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,833] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* warning_once             /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/utils/logging.py 319\n",
      "[2024-12-28 20:54:44,834] torch._dynamo.eval_frame: [DEBUG] skipping warning /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,834] torch._dynamo.eval_frame: [DEBUG] skipping isEnabledFor /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,835] torch._dynamo.eval_frame: [DEBUG] skipping _acquireLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,835] torch._dynamo.eval_frame: [DEBUG] skipping disable /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,835] torch._dynamo.eval_frame: [DEBUG] skipping getEffectiveLevel /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,835] torch._dynamo.eval_frame: [DEBUG] skipping _releaseLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,836] torch._dynamo.eval_frame: [DEBUG] skipping _log /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,836] torch._dynamo.eval_frame: [DEBUG] skipping findCaller /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,836] torch._dynamo.eval_frame: [DEBUG] skipping <lambda> /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,836] torch._dynamo.eval_frame: [DEBUG] skipping _is_internal_frame /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,837] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,838] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* normcase             <frozen posixpath> 52\n",
      "[2024-12-28 20:54:44,838] torch._dynamo.eval_frame: [DEBUG] skipping makeRecord /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,838] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,839] torch._dynamo.eval_frame: [DEBUG] skipping getLevelName /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,839] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,839] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* basename             <frozen posixpath> 140\n",
      "[2024-12-28 20:54:44,840] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,840] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _get_sep             <frozen posixpath> 41\n",
      "[2024-12-28 20:54:44,841] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,841] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* splitext             <frozen posixpath> 117\n",
      "[2024-12-28 20:54:44,842] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,842] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _splitext             <frozen genericpath> 121\n",
      "[2024-12-28 20:54:44,842] torch._dynamo.eval_frame: [DEBUG] skipping current_thread /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,842] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,843] torch._dynamo.eval_frame: [DEBUG] skipping current_process /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-28 20:54:44,843] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-28 20:54:44,844] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,844] torch._dynamo.eval_frame: [DEBUG] skipping filter /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,845] torch._dynamo.eval_frame: [DEBUG] skipping callHandlers /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,845] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,845] torch._dynamo.eval_frame: [DEBUG] skipping acquire /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,846] torch._dynamo.eval_frame: [DEBUG] skipping emit /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,846] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,847] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,847] torch._dynamo.eval_frame: [DEBUG] skipping getMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,847] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,848] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,848] torch._dynamo.eval_frame: [DEBUG] skipping formatMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,848] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,848] torch._dynamo.eval_frame: [DEBUG] skipping _format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,849] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,849] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* write             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 624\n",
      "[2024-12-28 20:54:44,850] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,850] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _is_master_process             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 519\n",
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "[2024-12-28 20:54:44,851] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,851] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _schedule_flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 546\n",
      "[2024-12-28 20:54:44,851] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,852] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* schedule             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 258\n",
      "[2024-12-28 20:54:44,852] torch._dynamo.eval_frame: [DEBUG] skipping is_alive /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,852] torch._dynamo.eval_frame: [DEBUG] skipping is_set /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,853] torch._dynamo.eval_frame: [DEBUG] skipping _wait_for_tstate_lock /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,853] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,854] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _event_pipe             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 137\n",
      "[2024-12-28 20:54:44,854] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,855] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* send             /home/gaurav/anaconda3/lib/python3.11/site-packages/zmq/sugar/socket.py 621\n",
      "[2024-12-28 20:54:44,855] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,855] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 561\n",
      "[2024-12-28 20:54:44,856] torch._dynamo.eval_frame: [DEBUG] skipping ident /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,856] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,856] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,856] torch._dynamo.eval_frame: [DEBUG] skipping wait /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,856] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,857] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 20:54:44,857] torch._dynamo.eval_frame: [DEBUG] skipping release /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 20:54:44,857] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:44,859] [5/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:44,860] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:44,860] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:44,860] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:44,862] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:44,863] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:44,865] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:44,866] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:44,868] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 20:54:44,868] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,869] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:44,869] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,869] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,869] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:54:44,869] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:54:44,870] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,870] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,870] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,870] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,870] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,871] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,871] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:54:44,871] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:54:44,871] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,871] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,874] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,874] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:44,875] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,875] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,875] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:44,875] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,875] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,876] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:44,876] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,876] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:44,877] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,877] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,877] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,878] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,878] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,878] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,878] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,878] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,879] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,879] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,879] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,879] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,879] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,880] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,880] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,880] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,880] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,881] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,882] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:44,883] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,884] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,885] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,885] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,885] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,885] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,885] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7437e9f56670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:44,886] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,887] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,888] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,888] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 20:54:44,888] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:44,888] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,888] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,889] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,889] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:44,889] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,889] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 20:54:44,889] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,890] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb045c0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:54:44,890] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,890] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 20:54:44,891] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,891] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,891] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 20:54:44,892] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 20:54:44,892] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,892] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,893] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,893] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,893] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,893] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:44,893] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:44,894] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,895] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:44,896] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,896] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,896] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,896] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:44,897] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,899] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:54:44,900] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,900] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,900] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,900] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:44,900] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:44,901] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:44,901] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:44,901] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 20:54:44,903] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 20:54:44,904] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,904] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,904] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,904] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,905] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,905] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,905] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:44,905] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,906] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 20:54:44,906] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,906] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:44,907] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 20:54:44,907] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,907] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,907] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,908] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:44,908] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,909] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,909] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,909] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:44,910] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,910] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,910] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:44,910] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,912] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:54:44,913] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,914] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,914] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,914] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:44,914] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:44,915] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 20:54:44,916] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,916] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 20:54:44,916] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:44,916] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 20:54:44,917] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:44,917] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,917] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,917] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 20:54:44,918] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 20:54:44,918] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 20:54:44,919] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,919] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:54:44,919] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:54:44,919] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,920] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:54:44,920] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,920] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,920] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,920] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:54:44,921] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,921] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,921] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,921] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:54:44,921] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,922] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,922] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 20:54:44,923] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:44,923] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,923] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,923] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:44,923] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 20:54:44,924] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 20:54:44,924] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,924] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,924] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,925] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,925] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,925] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,926] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,926] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,926] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:44,926] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,927] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,927] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,927] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,928] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,930] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:44,931] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:44,932] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,932] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,932] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:44,933] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,933] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,933] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,934] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,935] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,935] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:44,935] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,936] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,936] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,936] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 20:54:44,937] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,937] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,937] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:54:44,938] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:54:44,938] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,938] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 20:54:44,938] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:54:44,939] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,939] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,939] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 20:54:44,939] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,940] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,940] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:54:44,940] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:54:44,941] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,941] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 20:54:44,941] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:54:44,942] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,942] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,942] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:54:44,942] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,942] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,943] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:44,944] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:44,944] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:54:44,944] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,945] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:44,945] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,945] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:44,945] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,946] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:44,946] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,946] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:44,947] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:54:44,947] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:54:44,947] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:44,947] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:44,948] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,948] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:44,948] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,949] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:44,949] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,949] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:44,949] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:44,950] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:44,950] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,950] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:44,951] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,952] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,952] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,952] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,952] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:44,952] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,953] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:44,953] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,953] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:44,953] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:44,954] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,955] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,955] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:44,955] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:44,955] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:44,955] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb045c0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:54:44,956] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,957] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:44,957] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,957] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,957] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,958] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,958] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,958] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:44,958] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7437e9f56670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:54:44,958] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:44,959] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:44,959] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:54:44,959] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,959] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,960] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:54:44,961] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7437100e44b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:44,962] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:44,963] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,964] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:44,964] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,964] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:44,964] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:54:44,964] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,965] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:44,966] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:54:44,967] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:54:44,967] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:44,967] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,967] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:44,968] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:44,969] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:44,969] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:44,969] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,969] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:44,970] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:54:44,971] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,971] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,971] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,971] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,972] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:44,972] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,972] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,972] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:44,972] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,974] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:54:44,974] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,974] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:44,974] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:44,974] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:44,975] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:44,975] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:54:44,976] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:54:44,976] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,976] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,977] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,977] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,977] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,978] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:44,978] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:44,978] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,978] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:44,978] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,979] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:54:44,980] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,980] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:44,980] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:44,980] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:44,980] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:44,981] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,981] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,981] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:44,981] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:54:44,982] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:44,982] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,983] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:44,983] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,983] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,986] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:44,986] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,986] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:44,986] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:44,988] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:44,989] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:44,989] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,989] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,991] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,991] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:44,991] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:54:44,992] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,993] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,993] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:44,993] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:44,994] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:44,994] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,994] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:44,994] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 20:54:44,994] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:44,995] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,995] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,995] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:44,995] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:54:44,996] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:54:44,996] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:44,997] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,997] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:44,997] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:44,997] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:44,997] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:44,998] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:44,999] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:44,999] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:44,999] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:44,999] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:44,999] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:45,000] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:54:45,001] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,001] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,001] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,001] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,002] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:45,002] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:45,002] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,002] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:45,002] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,003] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:45,004] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:54:45,005] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:54:45,005] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,005] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,006] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,006] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,006] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,006] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:45,006] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:45,007] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,007] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:45,007] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,008] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:54:45,009] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,009] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:45,009] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,009] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,009] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:45,010] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,010] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,010] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:45,010] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:54:45,011] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,011] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,011] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:45,011] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,012] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,012] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,012] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,012] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:45,012] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,013] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,014] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:45,014] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,015] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,016] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,016] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:45,016] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:54:45,017] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,017] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,017] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:45,017] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,018] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,019] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:45,020] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7437100e44b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:54:45,020] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:54:45,020] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,020] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,021] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 20:54:45,021] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 20:54:45,021] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 20:54:45,022] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,022] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,022] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,023] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:54:45,023] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:45,023] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:54:45,023] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:45,024] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,024] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,025] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,025] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,025] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:54:45,025] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:45,025] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,026] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:45,026] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,026] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:54:45,027] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,027] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,027] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:54:45,027] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,028] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:54:45,028] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:54:45,029] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,029] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,029] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,029] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,030] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,030] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:54:45,031] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:54:45,031] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,031] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,032] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,033] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,033] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,033] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,033] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,034] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,034] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,034] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,035] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,035] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,035] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,036] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,036] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,036] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,037] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:45,037] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,037] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,037] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,038] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:45,038] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,038] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,038] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,042] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:45,044] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:45,044] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,045] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,045] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,045] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,045] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,046] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,046] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,046] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,046] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,047] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,047] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,047] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,047] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,047] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,048] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,049] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,049] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,049] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,049] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,049] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,050] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,050] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:45,051] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,051] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:54:45,051] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:45,051] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:54:45,051] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:45,052] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,052] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,052] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,052] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,053] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:54:45,053] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:45,053] [5/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,053] [5/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:54:45,054] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,055] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:54:45,056] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:54:45,057] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,057] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,057] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,058] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,058] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,058] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:54:45,058] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:54:45,058] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,059] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,060] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,060] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,060] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,060] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,061] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,061] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,061] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,061] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,062] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,062] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:45,062] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,062] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,062] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:45,063] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:45,063] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,063] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,063] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,065] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:45,065] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:45,066] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,066] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,066] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,066] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,066] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,067] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,067] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,067] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,067] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,068] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,068] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,068] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,068] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,069] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:45,069] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:45,069] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,069] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,069] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,070] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,070] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,070] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,071] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,071] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,071] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,071] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,072] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,072] [5/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:45,073] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,073] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:45,073] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:45,073] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,073] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,074] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:45,074] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,074] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,075] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:45,075] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,075] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,076] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,076] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:45,076] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:45,076] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:45,077] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,077] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,078] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:45,078] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:45,078] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,079] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 20:54:45,079] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:45,080] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 20:54:45,080] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,080] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,081] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,081] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:45,081] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:45,081] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:45,081] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,082] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:45,082] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 20:54:45,082] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:45,083] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:45,084] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:54:45,084] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,085] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:54:45,085] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>)]\n",
      "[2024-12-28 20:54:45,085] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,085] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:45,086] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,089] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:45,089] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:45,089] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:45,090] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:45,090] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:45,090] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:45,090] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:45,090] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,091] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:45,091] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:54:45,091] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:45,092] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:54:45,092] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,092] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:54:45,093] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>)]\n",
      "[2024-12-28 20:54:45,093] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,093] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,094] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:45,094] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,094] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,095] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,095] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,095] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:54:45,095] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:45,095] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,096] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:45,096] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:54:45,096] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:45,097] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,097] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,097] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:45,097] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,098] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,098] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,098] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:54:45,098] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:45,098] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:45,100] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:45,101] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:45,101] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 20:54:45,101] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,101] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,101] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:45,102] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,103] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,104] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:45,104] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:45,104] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:45,104] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 20:54:45,105] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:54:45,105] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:54:45,105] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:45,105] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:45,105] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:45,106] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,106] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:54:45,106] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:45,106] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:45,107] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:45,107] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:45,107] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:45,108] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,109] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,109] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 20:54:45,109] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:45,110] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,110] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,110] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:45,111] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,111] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,111] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,112] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:54:45,112] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:45,112] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,112] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,112] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,113] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,113] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,113] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:54:45,113] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:45,113] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 20:54:45,115] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,116] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:45,117] [5/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:45,117] [5/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:45,117] [5/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:45,118] [5/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_10 =====\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.180 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,120] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_10 <eval_with_key>.180 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7437eab258a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7437e931cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7437eab25bc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7437e931cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7437e931cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7437e931cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7437e9a4a5c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7437e9a49940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7437e931cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 20:54:45,122] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_10 =====\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,126] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:45,127] [5/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,128] [5/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,132] [5/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:45,132] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:45,132] [5/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:45,132] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127779758101328)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,133] [5/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,133] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:45,133] [5/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:45,134] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117686336)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:54:45,134] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,135] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117686336)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 20:54:45,135] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,136] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117686336)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:54:45,136] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,136] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117686336)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 20:54:45,136] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,137] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,137] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 20:54:45,138] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 20:54:45,138] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 20:54:45,138] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,138] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 20:54:45,139] [5/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,139] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,139] [5/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,140] [5/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 20:54:45,141] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:54:45,141] [5/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:54:45,142] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,142] [5/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,143] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,143] [5/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,144] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,144] [5/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,145] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,145] [5/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,146] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,147] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,147] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,148] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,148] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,186] torch._dynamo.eval_frame: [DEBUG] skipping __call__ /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-28 20:54:45,186] torch._dynamo.eval_frame: [DEBUG] skipping del_ten /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py\n",
      "[2024-12-28 20:54:45,186] torch._dynamo.eval_frame: [DEBUG] skipping pop /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-28 20:54:45,187] torch._dynamo.eval_frame: [DEBUG] skipping __hash__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/weak.py\n",
      "[2024-12-28 20:54:45,187] torch._dynamo.eval_frame: [DEBUG] skipping expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\n",
      "[2024-12-28 20:54:45,187] torch._dynamo.eval_frame: [DEBUG] skipping _expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/storage.py\n",
      "[2024-12-28 20:54:45,187] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:45,188] [6/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:45,189] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:45,189] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:45,189] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:45,190] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:45,191] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,192] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,193] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:54:45,193] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,193] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:54:45,193] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,193] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,194] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:54:45,194] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,194] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,195] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,196] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,196] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,196] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,197] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:54:45,197] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:45,197] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,197] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:45,199] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,199] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:45,200] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,200] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,200] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:45,200] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,200] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,201] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,202] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,203] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,204] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,205] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:45,206] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:45,207] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:45,207] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:45,207] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,207] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,207] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,208] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:45,209] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,209] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,209] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:45,209] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,209] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:45,210] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:45,210] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,210] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:45,210] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,210] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:45,211] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:45,211] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,211] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:45,212] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:45,212] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,212] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:45,212] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,213] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,213] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,213] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:45,213] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,213] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:45,214] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:45,216] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:45,216] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:45,216] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,216] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,217] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,217] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,217] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,217] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:45,217] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,218] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:45,219] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,219] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:45,219] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,219] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:45,220] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,220] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:45,220] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,220] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,221] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:45,221] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,221] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:45,221] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,222] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,222] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,223] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,223] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:45,223] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,224] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,224] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,224] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:45,224] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,225] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,226] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,226] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:45,226] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,227] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,227] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:45,228] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,228] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,229] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:45,229] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:45,229] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:45,233] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,233] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:45,233] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,236] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,237] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,237] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:45,237] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,238] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,238] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:45,239] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,239] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:45,239] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,239] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:54:45,239] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:54:45,240] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,240] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,241] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,242] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,243] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,244] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:54:45,244] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:54:45,244] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,244] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:45,247] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,247] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:45,248] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,248] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,248] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:45,248] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,249] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,249] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:45,250] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:45,250] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:45,250] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:45,251] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,251] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,251] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:45,251] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,251] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,252] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,252] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,252] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,252] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,253] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,253] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,253] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,253] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,254] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,255] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:45,256] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,257] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:45,258] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,258] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,258] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:45,258] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:45,259] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:45,259] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:45,259] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:45,259] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,259] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,260] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:45,261] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:45,261] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:45,261] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,261] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb18820, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:54:45,262] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,262] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 20:54:45,262] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 20:54:45,262] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 20:54:45,262] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:45,263] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,264] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,264] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,265] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,266] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,266] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,266] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,267] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,267] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,267] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,267] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,267] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,268] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,268] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,268] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:45,272] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,272] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,273] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,273] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,273] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,276] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,276] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,276] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,276] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,277] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,277] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,277] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,277] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:45,280] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,281] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,281] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,281] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,282] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,282] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,282] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,282] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,282] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,286] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 20:54:45,286] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 20:54:45,286] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 20:54:45,286] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 20:54:45,286] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,287] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb18820, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:54:45,287] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,287] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,288] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,289] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:54:45,289] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,289] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:45,289] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:45,290] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 20:54:45,290] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 20:54:45,290] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:45,290] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 20:54:45,290] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 20:54:45,291] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 20:54:45,292] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:45,293] [6/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:45,293] [6/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:45,293] [6/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_11 =====\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.181 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,294] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_11 <eval_with_key>.181 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7437e931cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 20:54:45,295] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_11 =====\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,297] [6/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,299] [6/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:45,300] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780049436176)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,300] [6/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,301] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,302] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:45,302] [6/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:45,303] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 20:54:45,303] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,304] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:54:45,304] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:54:45,305] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 20:54:45,305] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,306] [6/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,306] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,307] [6/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,308] [6/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:54:45,308] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,309] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,309] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,310] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,310] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,311] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,311] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,312] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:45,313] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,315] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,324] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:45,325] [7/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:45,327] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:45,327] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:45,327] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:45,329] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:45,329] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:45,330] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 20:54:45,330] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 20:54:45,330] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,331] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,331] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:37\n",
      "[2024-12-28 20:54:45,331] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:45,331] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:45,332] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:45,332] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:45,332] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_1823720/343866.py:37\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:45,333] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,335] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 20:54:45,335] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:40\n",
      "[2024-12-28 20:54:45,335] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:45,335] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,335] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_1823720/343866.py:40\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:45,336] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:45,339] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 20:54:45,339] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:43\n",
      "[2024-12-28 20:54:45,339] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:45,339] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:45,340] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,340] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:45,340] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,341] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:45,341] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_1823720/343866.py:43\n",
      "[2024-12-28 20:54:45,341] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:45,341] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:45\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:45,344] [7/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_12 =====\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.182 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:45,345] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_12 <eval_with_key>.182 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7437e931cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 20:54:45,346] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_12 =====\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,347] [7/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:54:45,348] [7/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:45,348] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780047764688)                   # logits = self.linear(pooled_output)  # mp/ipykernel_1823720/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 20:54:45,349] [7/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_1823720/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 20:54:45,349] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:45,350] [7/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:45,350] [7/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:45,351] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,352] [7/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,352] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,353] [7/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:45,353] [7/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_1823720/343866.py, line 34 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7437e931cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7437e931cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7437eab258a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7437e931cde0>\n",
      "    <function _exit_autocast at 0x7437eab25bc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7437e931cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7437e931cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7437e931cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7437e9a4a5c0>\n",
      "    <function dropout at 0x7437e9a49940>\n",
      "    <built-in method matmul of type object at 0x7437e931cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7437e931cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7437e931cde0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370bf0bc90; to 'Tensor' at 0x74370b15cef0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 6:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 7:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x74370bf0bc90; to 'Tensor' at 0x74370b15cef0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 10:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127780047764688)\"]\n",
      "    Object Weakref: <weakref at 0x743710b8dc60; to 'LLaMAFirstLayerModel' at 0x74371c5b3cd0>\n",
      "    Guarded Class Weakref: <weakref at 0x743710b68630; to 'type' at 0xb6e7e60 (LLaMAFirstLayerModel)>\n",
      "  Guard 11:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 12:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 17:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 18:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 19:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 21:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 22:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 24:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127780049436176)\"]\n",
      "    Object Weakref: <weakref at 0x74370ad64450; to 'LlamaDecoderLayer' at 0x74371c74be10>\n",
      "    Guarded Class Weakref: <weakref at 0x74370b1598a0; to 'type' at 0xbfbf1a0 (LlamaDecoderLayer)>\n",
      "  Guard 27:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f397b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 28:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 31:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 32:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4540; to 'Tensor' at 0x74371ea86ab0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 33:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f06e0a90; to 'type' at 0x7437e9319080 (dtype)>\n",
      "  Guard 34:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 35:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4540; to 'Tensor' at 0x74371ea86ab0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 41:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 48:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 49:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 50:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 51:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127779758101328)\"]\n",
      "    Object Weakref: <weakref at 0x743710b8c360; to 'LlamaAttention' at 0x74370b175350>\n",
      "    Guarded Class Weakref: <weakref at 0x74370bfea4d0; to 'type' at 0xbc42110 (LlamaAttention)>\n",
      "  Guard 52:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f397b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 53:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40240208)\"]\n",
      "    Object Weakref: <weakref at 0x743709f9ffb0; to 'Logger' at 0x743710d1ddd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437f784cb30; to 'type' at 0x2660450 (Logger)>\n",
      "  Guard 58:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709f8e7f0; to 'Tensor' at 0x74370b2c2d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 59:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 64:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x74370ad9ae80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 65:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 68:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 71:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x74370ad98810; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 73:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 76:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127779758101328)\"]\n",
      "    Object Weakref: <weakref at 0x743710b8c360; to 'LlamaAttention' at 0x74370b175350>\n",
      "    Guarded Class Weakref: <weakref at 0x74370bfea4d0; to 'type' at 0xbc42110 (LlamaAttention)>\n",
      "  Guard 78:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x74370ad762a0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 79:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709f8e7f0; to 'Tensor' at 0x74370b2c2d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 82:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f06e0a90; to 'type' at 0x7437e9319080 (dtype)>\n",
      "  Guard 83:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 84:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117686336)\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 85:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 86:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 88:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 91:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 93:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 99:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 101:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 102:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370ad9ae80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 103:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 104:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370ad98810; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 105:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 107:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 109:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370ad762a0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 112:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 117:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 118:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 119:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127780049436176)\"]\n",
      "    Object Weakref: <weakref at 0x74370ad64450; to 'LlamaDecoderLayer' at 0x74371c74be10>\n",
      "    Guarded Class Weakref: <weakref at 0x74370b1598a0; to 'type' at 0xbfbf1a0 (LlamaDecoderLayer)>\n",
      "  Guard 120:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 121:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x743709ff4540; to 'Tensor' at 0x74371ea86ab0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 123:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370a963a10; to 'Tensor' at 0x74370a9d54f0>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 124:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f06e0a90; to 'type' at 0x7437e9319080 (dtype)>\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 128:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 135:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 136:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 138:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 139:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 142:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f576a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 143:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 145:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 149:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7437f7f576a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 151:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 153:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 154:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74370ad869d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7437eb569cb0; to 'torch._C._TensorMeta' at 0x703c040 (Tensor)>\n",
      "  Guard 155:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 127780047764688)\"]\n",
      "    Object Weakref: <weakref at 0x743710b8dc60; to 'LLaMAFirstLayerModel' at 0x74371c5b3cd0>\n",
      "    Guarded Class Weakref: <weakref at 0x743710b68630; to 'type' at 0xb6e7e60 (LLaMAFirstLayerModel)>\n",
      "  Guard 160:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.3340, 0.1587, 0.0635, 0.2963, 0.1316, 0.0295\n",
      "OutputGraph.call_user_compiler   0.0009, 0.0004, 0.0004, 0.0006, 0.0004, 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use TorchDynamo's explain to capture the graph\n",
    "# Extract the input_ids tensor from BatchEncoding\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "explanation = torch._dynamo.explain(model, input_ids)\n",
    "\n",
    "# Print the explanation\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph break to Python `forward`\n",
    "\n",
    "Using `dynamo` explain to evaluate the graph and breaks generated by `torch._dynamo`, use `torch._dynamo.optimize`\n",
    "generate the Python `forward` function for each of these graph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:54:52,588] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:52,589] [8/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_1823720/343866.py:26\n",
      "[2024-12-28 20:54:52,590] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:26\n",
      "[2024-12-28 20:54:52,590] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-28 20:54:52,590] [8/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:52,591] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,591] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:28\n",
      "[2024-12-28 20:54:52,591] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:52,592] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,592] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,592] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,593] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,593] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,593] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_1823720/343866.py:28\n",
      "[2024-12-28 20:54:52,593] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:52,593] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,596] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 20:54:52,596] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:52,596] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:52,596] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,597] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,597] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:52,598] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,598] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:54:52,598] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,599] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,599] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,599] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,600] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:54:52,600] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:52,600] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:52,601] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7437e931cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:52,601] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:52,601] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:52,601] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,602] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_1823720/343866.py:31\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:52,603] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:52,604] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 20:54:52,605] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:52,605] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:52,605] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,605] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,606] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,606] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,606] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,606] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,607] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,607] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:52,607] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:52,607] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,608] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,612] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,612] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:52,612] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,613] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,613] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:52,613] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,614] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,614] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:52,615] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,615] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,615] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,616] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,616] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,616] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,617] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,617] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,617] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,617] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,618] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,618] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,618] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,619] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,619] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,619] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,620] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,620] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,620] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,620] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,621] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,622] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,623] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,624] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,625] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:52,625] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,625] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:52,625] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,625] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,626] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x74370b163380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,627] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,627] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,627] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,627] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371007a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:54:52,628] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,628] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:52,628] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,628] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,628] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:52,629] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,629] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:52,629] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,629] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:52,629] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,630] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,630] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,631] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,631] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,631] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,631] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:52,631] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,632] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,635] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,635] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:52,635] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,635] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,635] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:52,636] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,636] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,636] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:52,637] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,637] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,637] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,637] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,637] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,638] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,639] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,639] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,639] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,639] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,639] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,640] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,640] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,640] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,640] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,641] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,642] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,643] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,644] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,645] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,645] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,645] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,645] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,645] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,646] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:52,647] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,647] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,647] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:52,648] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,648] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:52,649] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:52,649] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,650] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:52,650] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:52,650] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,650] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:52,650] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,652] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,652] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,652] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,652] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,652] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,653] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:52,655] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:52,655] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,656] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,658] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:52,658] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,658] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,658] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,659] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:52,659] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,660] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:52,660] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,660] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,661] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:52,662] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,662] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,662] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,663] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,664] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,664] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,664] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,664] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,666] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,666] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,666] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,666] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,667] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,668] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,668] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,668] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,668] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,669] [8/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:52,670] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,670] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,671] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:52,671] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,671] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,672] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,672] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,672] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,673] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,674] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,674] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,674] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,676] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:52,676] [8/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:52,677] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:52,677] [8/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,677] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,677] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,677] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,678] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,678] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:54:52,678] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,679] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,679] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,679] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:52,680] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:52,680] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,680] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:52,680] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,681] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,681] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:54:52,681] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,682] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,682] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:52,682] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:52,683] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,683] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:52,684] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,685] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,685] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:54:52,685] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,685] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,685] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:54:52,686] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,687] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,687] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:52,687] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,688] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,688] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,688] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,688] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:52,689] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,689] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:54:52,689] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,689] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,689] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,690] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,690] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:54:52,691] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:54:52,692] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,696] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,696] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:52,697] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,698] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,698] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:52,698] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,699] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,700] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:52,701] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,701] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,702] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,702] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,702] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,703] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,703] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,703] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,704] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,704] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,704] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,707] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,708] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,709] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:52,711] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,711] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,711] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,713] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:54:52,713] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,713] [8/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,713] [8/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:52,715] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,715] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:52,715] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:52,716] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:52,716] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:52,716] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:52,716] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:52,716] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:52,717] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,717] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,717] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:52,717] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:52,717] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:52,718] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,718] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,719] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:52,719] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,719] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,720] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,720] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,720] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:52,720] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,720] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,721] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:52,722] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,722] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,723] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,723] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,723] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,723] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,724] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,725] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,725] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,725] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,730] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,730] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,731] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,732] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,732] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,736] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,736] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,736] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,736] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,738] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,738] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,738] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,738] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,738] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,742] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,742] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,742] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,742] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:52,743] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,743] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,744] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,744] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,744] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,746] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,746] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,748] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,749] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,749] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,749] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,750] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,750] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,750] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,750] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,752] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,752] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,752] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,752] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:52,752] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,753] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,753] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,753] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,753] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,754] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,754] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,755] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,755] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,756] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,756] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,756] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,757] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,758] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,758] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,758] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,758] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,759] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,759] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,759] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,760] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,761] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,761] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,761] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:52,761] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,761] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,762] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,762] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,762] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,763] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,763] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,764] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,764] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,765] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,765] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,765] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,766] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,767] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,767] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,767] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,767] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,768] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,768] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,768] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,769] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,770] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,770] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,770] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:52,770] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:52,770] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:52,771] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,771] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:52,771] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:52,771] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:54:52,771] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:52,772] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:52,772] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:52,772] [8/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,772] [8/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,773] [8/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x74371007a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:54:52,774] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:52,774] [8/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,774] [8/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,774] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:52,775] [8/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_1823720/343866.py\", line 34, in forward\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 20:54:52,776] [8/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 20:54:52,777] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:52,777] [8/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_13 =====\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.183 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_13 <eval_with_key>.183 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7437e931cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 20:54:52,778] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_13 =====\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:52,779] [8/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:52,782] [8/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:52,783] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780047764688)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1823720/343866.py:28 in forward\n",
      "[2024-12-28 20:54:52,783] [8/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1823720/343866.py:28 in forward\n",
      "[2024-12-28 20:54:52,784] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117686336)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_1823720/343866.py:31 in forward\n",
      "[2024-12-28 20:54:52,784] [8/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,785] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,785] [8/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,785] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,786] [8/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,786] [8/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,788] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:52,789] [9/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:54:52,789] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:54:52,789] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:52,790] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:52,791] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:52,792] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,792] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 20:54:52,792] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:52,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:52,793] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:54:52,793] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:52,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,794] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,794] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,794] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,795] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,795] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:54:52,795] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:52,795] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,795] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,798] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,798] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:52,798] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,799] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,799] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:52,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:52,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,802] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,802] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,804] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,804] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,804] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,805] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,805] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,805] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,807] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,808] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,808] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,808] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,808] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:52,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:52,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,812] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,812] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,812] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,812] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:52,813] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,813] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:52,813] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,814] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,814] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:52,814] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,814] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:52,816] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,816] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,816] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:52,817] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,817] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:52,817] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:52,818] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,819] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,820] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,820] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,820] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,820] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:52,821] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:52,821] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,821] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:52,823] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:52,824] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:52,824] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,824] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,825] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,825] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,826] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,826] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,826] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,827] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:52,828] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,828] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,828] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:52,828] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:52,828] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:52,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,831] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:52,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,832] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,833] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:52,833] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,833] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,833] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,834] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,835] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,835] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,835] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,835] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,836] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,836] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,837] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:52,837] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:52,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:52,839] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,839] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,839] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,839] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,840] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,840] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,840] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:52,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:52,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:52,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:52,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:54:52,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,843] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,843] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 20:54:52,843] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:52,843] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:52,844] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:54:52,845] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,846] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,847] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:54:52,848] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,853] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,853] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:52,853] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,853] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,853] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:52,854] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:52,854] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:52,854] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:52,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:52,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,856] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,856] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,856] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,856] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,857] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,857] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,857] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,857] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,857] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,858] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,858] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,858] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,858] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,859] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,859] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,859] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,860] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,861] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,862] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,862] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,862] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:52,862] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:52,863] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:52,864] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:52,864] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:54:52,864] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,864] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,865] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x74370b162fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:54:52,865] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:52,865] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:52,865] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,866] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:52,868] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,868] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:52,868] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:52,868] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:52,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:52,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:52,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:52,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:52,870] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:52,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:52,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,873] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,873] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,874] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,874] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,874] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,874] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,875] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,879] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,879] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,879] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,879] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,879] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,881] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,881] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,881] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,885] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,885] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,886] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,890] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,890] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:52,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,893] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,893] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,893] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,893] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,893] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,894] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,894] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,894] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,895] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,895] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,895] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,895] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,895] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,896] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,896] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:52,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,898] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,898] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,898] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,899] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,900] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,900] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,902] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,902] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,902] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,903] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,905] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:52,906] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,907] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,907] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,908] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,908] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,909] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,909] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,910] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,910] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,910] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,912] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,913] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,914] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,914] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,915] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,916] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,916] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,916] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,917] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,919] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,919] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:52,920] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:52,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:52,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,921] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,921] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:52,922] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:52,923] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:52,924] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,924] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:52,924] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:52,925] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:54:52,925] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:52,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:52,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:52,926] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,926] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb1b430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:54:52,927] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:54:52,928] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:54:52,928] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:52,928] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:52,928] [9/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:52,931] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:52,931] [9/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:52,933] [9/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_15 =====\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.184 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:52,934] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_15 <eval_with_key>.184 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7437e931cde0>  (add,)                                    {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 20:54:52,935] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_15 =====\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:52,936] [9/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:52,937] [9/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:52,941] [9/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:52,941] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780049436176)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,942] [9/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,942] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:52,943] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:52,943] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,943] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,944] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117686336)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 20:54:52,945] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,945] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,945] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,946] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,947] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,947] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:54:52,948] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,948] [9/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,949] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,950] [9/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:52,950] [9/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:54:52,951] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,951] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,951] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,952] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,952] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,953] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,953] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,953] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:52,954] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,954] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:52,959] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:52,961] [10/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:54:52,962] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:54:52,962] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:54:52,963] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:52,964] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:52,966] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:54:52,966] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:54:52,967] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:54:52,967] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:54:52,967] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:54:52,967] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:54:52,968] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:52,968] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 20:54:52,968] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:54:52,969] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:54:52,969] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:52,969] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,969] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:52,970] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:54:52,970] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,970] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,970] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,971] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 20:54:52,971] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:52,971] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,971] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,972] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:52,972] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,972] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,973] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:52,973] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:54:52,973] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,973] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,973] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,974] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,977] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,978] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:54:52,978] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,978] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,978] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,979] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,979] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,979] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_input_ids_ : torch.Tensor):\n",
      "    l_input_ids_ = L_input_ids_\n",
      "    l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "    arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "    unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "    return (l__self___embed_tokens, unsqueeze)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add);  add = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "    return (mul_1,)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:54:52,980] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:54:52,980] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,980] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,982] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,982] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:54:52,982] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,983] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:52,983] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,983] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,983] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,984] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:52,984] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:54:52,984] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:52,984] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,986] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,986] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:52,986] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,987] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:54:52,987] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,987] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,987] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,988] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,988] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,988] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,988] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,989] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,989] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,989] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:52,989] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,989] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,991] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,991] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,991] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,991] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,992] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,992] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:54:52,992] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,992] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,993] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:54:52,993] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:52,993] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,993] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:54:52,994] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:52,994] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:52,994] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,995] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,995] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,995] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,995] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:52,996] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,996] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,996] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:52,996] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,996] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:52,997] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:52,997] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:52,998] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:52,999] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,000] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:53,000] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,000] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:54:53,000] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:54:53,001] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:54:53,001] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,001] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,001] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,002] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,002] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,002] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,003] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,003] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:53,003] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,003] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,004] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:53,004] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:53,004] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,005] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,005] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,005] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:54:53,005] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,005] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:53,006] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,006] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 20:54:53,006] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:53,007] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:53,008] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:54:53,008] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:54:53,008] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 20:54:53,008] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,009] [10/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:54:53,010] [10/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:54:53,010] [10/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:54:53,011] [10/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_17 =====\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.185 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,012] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_17 <eval_with_key>.185 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 20:54:53,013] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_17 =====\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:53,014] [10/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:53,028] [10/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:53,028] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127779758101328)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:54:53,028] [10/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:54:53,029] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,029] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,030] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,030] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,030] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 20:54:53,031] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,032] [10/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,032] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,032] [10/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,033] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40240208)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 20:54:53,033] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,034] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,037] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:53,039] [11/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:53,040] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:54:53,040] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:54:53,041] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:54:53,042] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:53,044] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:53,045] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:54:53,046] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:53,047] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 20:54:53,047] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,047] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:53,048] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,048] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,048] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:54:53,048] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:54:53,048] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,049] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,049] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,050] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,050] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,050] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,051] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:54:53,051] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:54:53,051] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,051] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,054] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,054] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:53,054] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,054] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,054] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:53,055] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,055] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,055] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:53,056] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,056] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,056] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,056] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,057] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,057] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,057] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,057] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,057] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,058] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,058] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,058] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,059] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,059] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,060] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,060] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,061] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,061] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,062] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,063] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,063] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,063] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,064] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,065] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:53,065] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,065] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,066] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,066] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,066] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,067] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:53,068] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,068] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,068] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,068] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,068] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,069] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:53,069] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,069] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,069] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,070] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,070] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,070] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:53,070] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:53,070] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,071] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:53,071] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,071] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,072] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x74370b162a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,073] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,073] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,073] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,073] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7437e9f56670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:54:53,074] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:53,075] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 20:54:53,075] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:54:53,075] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:54:53,076] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 20:54:53,077] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,077] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,077] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,078] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,078] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 20:54:53,079] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,079] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,080] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,080] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,081] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,081] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,081] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,081] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,082] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb045c0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:54:53,084] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,084] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 20:54:53,086] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,091] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,091] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 20:54:53,092] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 20:54:53,094] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,094] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,095] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,096] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,096] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,096] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:53,096] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,096] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,097] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:53,099] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,099] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,099] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,099] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,100] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:53,100] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,100] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,101] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,101] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:53,101] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,102] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:54:53,103] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,103] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,103] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,103] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:53,103] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:53,104] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:53,105] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:53,105] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 20:54:53,107] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 20:54:53,108] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,108] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,109] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,109] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,109] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,110] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,110] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:53,110] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,111] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 20:54:53,111] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,111] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:53,112] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 20:54:53,112] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,112] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,112] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,113] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,113] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,113] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,114] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,114] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:53,114] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,115] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,115] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:53,115] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,116] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:54:53,117] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,117] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,118] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,118] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:53,118] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:53,119] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 20:54:53,120] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,120] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 20:54:53,120] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:53,120] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 20:54:53,121] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:54:53,121] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,121] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,121] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 20:54:53,121] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 20:54:53,122] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 20:54:53,122] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,122] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:54:53,123] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:54:53,123] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,123] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:54:53,124] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,124] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,124] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,124] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:54:53,125] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,125] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,125] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,125] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:54:53,125] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,126] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,126] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 20:54:53,126] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 20:54:53,126] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,127] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,127] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,127] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 20:54:53,128] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 20:54:53,128] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,128] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,128] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,128] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,129] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,129] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,129] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,129] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,129] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:53,130] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,131] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,131] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,131] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:54:53,132] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,132] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,132] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:53,133] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,133] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,133] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,133] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,135] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,136] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:53,136] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,136] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,137] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,137] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,137] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,137] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:53,138] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,139] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,139] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:53,139] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,139] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,139] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,140] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,140] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,140] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:53,140] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,141] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,141] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,141] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,141] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:53,141] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,143] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,143] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,143] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 20:54:53,143] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,143] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,144] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:54:53,144] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:54:53,144] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,144] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 20:54:53,144] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:54:53,146] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,146] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,146] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 20:54:53,146] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,146] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,147] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:54:53,147] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:54:53,147] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,147] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 20:54:53,147] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:54:53,149] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,149] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,149] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:54:53,149] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,149] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,150] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,150] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,150] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,150] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 20:54:53,151] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 20:54:53,151] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,151] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:53,151] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:53,151] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:54:53,152] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,152] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:53,152] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,152] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:53,152] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:54:53,154] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,155] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:53,155] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,155] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:53,155] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,156] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:53,157] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,157] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:53,157] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:53,157] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:53,158] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:53,158] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:53,159] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,159] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,160] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,160] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,160] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:53,160] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,161] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:53,161] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,162] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:53,162] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:53,163] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,163] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,163] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,164] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:54:53,164] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:53,164] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,165] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,165] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,165] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb045c0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:54:53,166] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,166] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:54:53,166] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,166] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 20:54:53,166] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,167] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,167] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,167] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,167] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,168] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,168] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7437e9f56670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:54:53,168] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,169] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,169] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:54:53,170] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 20:54:53,171] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,171] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,171] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,171] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,172] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,172] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,172] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:54:53,172] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:54:53,172] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,173] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7437100e44b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:54:53,173] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,173] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 20:54:53,174] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,174] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,174] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,174] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:54:53,174] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:53,175] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:53,175] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,176] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,176] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,176] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,176] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,177] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:53,177] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,177] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,177] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:54:53,177] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:54:53,178] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:54:53,178] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,178] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,179] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,179] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,179] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:53,180] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,181] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,181] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,181] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:54:53,182] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:54:53,182] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,182] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,183] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,183] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,183] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,183] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:53,183] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,184] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:53,185] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:53,185] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:53,185] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,185] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:53,187] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:54:53,187] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,187] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,188] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,188] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,189] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:53,189] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,190] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,190] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,190] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,191] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:53,192] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:54:53,193] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:54:53,194] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,194] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,194] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,194] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,194] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,195] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:53,195] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,195] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,195] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,195] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,196] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:54:53,197] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,197] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,197] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,197] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,197] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,198] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,198] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,198] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,198] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:54:53,199] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,199] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,199] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:53,200] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,200] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,200] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,201] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,201] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,201] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,203] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:53,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,207] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,208] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,208] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,208] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:54:53,209] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,211] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,212] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:54:53,213] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:54:53,214] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,214] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,214] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "    l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "    l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "    view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    return (transpose, transpose_1, transpose_2)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:54:53,215] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,215] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,215] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:53,215] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:53,217] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:53,217] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:53,218] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,218] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:53,219] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:54:53,220] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,220] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,221] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,221] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,221] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:53,221] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,222] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,222] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,222] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,224] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:54:53,224] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,224] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,224] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:54:53,224] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:54:53,225] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:54:53,225] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:54:53,226] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:54:53,226] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,227] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,227] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,227] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,228] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,228] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:54:53,228] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,229] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,229] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,229] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,230] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:54:53,231] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,231] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,231] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,232] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,232] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,232] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,233] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,233] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,233] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:54:53,234] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,234] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,234] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable()]\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7437e931cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,235] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,237] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,237] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7437101e9790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:54:53,237] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,237] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,238] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,238] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,238] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:54:53,239] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,239] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,239] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,239] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,240] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:53,240] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,240] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 20:54:53,240] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 20:54:53,241] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:54:53,241] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,241] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,241] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7437100e44b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 20:54:53,242] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 20:54:53,243] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,243] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,243] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,243] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:54:53,243] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:53,244] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:54:53,244] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,244] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:53,245] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,246] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:53,246] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,246] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:54:53,246] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,247] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,247] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:54:53,247] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,247] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:54:53,247] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:54:53,248] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,248] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,248] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,249] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,249] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,249] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:54:53,249] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:54:53,249] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,250] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,250] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,250] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,250] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,250] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,251] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,251] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,251] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,251] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,252] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,252] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,252] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,253] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,253] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,253] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,253] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:53,254] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,254] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,254] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,254] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,255] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,255] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,255] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,257] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:53,257] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:53,257] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,258] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,258] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,258] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,258] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,259] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,259] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,259] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,259] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,260] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,260] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,260] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,260] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,261] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:53,261] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:53,261] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,261] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,262] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,262] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,262] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,262] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,262] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,263] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,263] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,263] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,264] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,264] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:53,265] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,265] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:54:53,265] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:53,265] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:54:53,266] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:54:53,266] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,266] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,267] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,267] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,267] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:54:53,267] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:54:53,267] [11/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,268] [11/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:53,268] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,268] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:54:53,268] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,269] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,269] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:54:53,269] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,269] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:54:53,270] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:54:53,271] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,272] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,273] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,273] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,273] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,274] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,274] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,274] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,275] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,275] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,275] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,275] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,276] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:54:53,276] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,276] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,276] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:54:53,277] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,277] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,277] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,277] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,279] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:54:53,279] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:54:53,279] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,280] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,280] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,280] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,280] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,280] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,281] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,281] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,281] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,282] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,282] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,282] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,283] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,283] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:53,283] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:53,283] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,284] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,284] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,284] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,284] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,284] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,285] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,285] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,285] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,285] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,287] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,287] [11/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x74371003de60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:54:53,287] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,287] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:53,287] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:53,288] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,288] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,289] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,289] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,289] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,289] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:53,290] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:53,291] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,291] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,292] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:53,292] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:53,292] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,293] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 20:54:53,293] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:53,294] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 20:54:53,294] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,294] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,295] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,295] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:53,295] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:54:53,295] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:53,295] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,296] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:53,296] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 20:54:53,296] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 20:54:53,296] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 20:54:53,297] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,297] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,297] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,298] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:53,298] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:53,299] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:54:53,299] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,300] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:54:53,301] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>)]\n",
      "[2024-12-28 20:54:53,301] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,302] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,302] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,303] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:53,303] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:53,304] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7437e9a4a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:53,304] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:53,304] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:53,304] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,307] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:53,308] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:53,309] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:54:53,310] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,310] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,311] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:54:53,311] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:53,311] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,311] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:53,312] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:54:53,312] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:53,312] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:54:53,312] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,312] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:54:53,313] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>)]\n",
      "[2024-12-28 20:54:53,313] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,314] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,314] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:53,315] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,315] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,315] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,316] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7437e9a49940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,316] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:54:53,316] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:53,316] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,318] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:53,318] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:54:53,318] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:53,318] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,318] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,319] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,319] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,319] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,319] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7437e931cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,320] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:54:53,320] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:53,320] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,323] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,323] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 20:54:53,323] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 20:54:53,323] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:53,323] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:54:53,324] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:53,324] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:54:53,324] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 20:54:53,325] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,325] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,325] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,326] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,326] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,326] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,327] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 20:54:53,327] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,328] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:53,328] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:53,328] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:53,328] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:54:53,328] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:54:53,329] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,329] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,329] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,330] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:53,330] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:53,330] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:54:53,331] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 20:54:53,331] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:54:53,331] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:54:53,332] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:54:53,332] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:53,332] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:54:53,333] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,333] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:54:53,333] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:53,333] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:53,333] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:54:53,334] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:54:53,334] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,334] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,334] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,335] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,335] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:54:53,335] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:53,335] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,336] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,336] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 20:54:53,336] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:53,336] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,337] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,337] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:53,337] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,338] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:53,339] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,342] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,342] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 20:54:53,342] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 20:54:53,342] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:54:53,343] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,343] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 20:54:53,343] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 20:54:53,343] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 20:54:53,343] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,344] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,345] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,345] [11/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:53,345] [11/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:53,345] [11/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:53,347] [11/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_19 =====\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.186 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,349] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_19 <eval_with_key>.186 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7437eab258a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7437e931cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7437eab25bc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7437e931cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7437e931cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7437e931cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7437e9a4a5c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7437e9a49940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7437e931cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 20:54:53,351] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_19 =====\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:53,356] [11/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:53,360] [11/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:53,361] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:53,361] [11/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:53,361] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127779758101328)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,362] [11/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,362] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:53,362] [11/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:54:53,363] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117686336)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:54:53,363] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,364] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117686336)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 20:54:53,364] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,364] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117686336)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:54:53,365] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,365] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117686336)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 20:54:53,366] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,366] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,366] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 20:54:53,367] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 20:54:53,367] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 20:54:53,367] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,368] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 20:54:53,368] [11/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,369] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,369] [11/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,369] [11/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 20:54:53,370] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:54:53,370] [11/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:54:53,371] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,371] [11/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,371] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,372] [11/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,372] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,373] [11/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,373] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,374] [11/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,374] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,374] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,375] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,375] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,376] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,381] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:53,381] [12/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:53,382] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:54:53,382] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:54:53,382] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:53,384] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:53,385] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,385] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:53,385] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,386] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:54:53,387] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,387] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,387] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:54:53,387] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,387] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:54:53,388] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:53,389] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,389] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,389] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,389] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,389] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,390] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:54:53,390] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:54:53,390] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,390] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,392] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,392] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,393] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:53,394] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,394] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,394] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,394] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,394] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,395] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,395] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,395] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,395] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,395] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,396] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,396] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,396] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,396] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,396] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,397] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,397] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,397] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,398] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,398] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,398] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,398] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,399] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,400] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,401] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,402] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:53,403] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:53,403] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,403] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:53,403] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,404] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,404] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x74370b162520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,404] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,404] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,404] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,405] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:53,406] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,407] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:54:53,407] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:53,407] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,408] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:53,408] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:54:53,408] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,408] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:53,408] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,409] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,409] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,409] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:53,409] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,409] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:53,410] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:53,412] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:54:53,415] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:54:53,416] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,416] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,416] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,416] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,417] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,417] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:53,417] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:54:53,419] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,420] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,420] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,420] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,421] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:54:53,421] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,421] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:53,421] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,422] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,422] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,422] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,422] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:53,422] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,423] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,423] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,423] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:53,423] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,424] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,424] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,424] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:53,424] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,424] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,425] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:54:53,426] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,426] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,427] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:54:53,428] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,428] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:54:53,428] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,428] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:53,428] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,429] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,429] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,429] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:53,429] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,430] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,430] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74371011b870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:54:53,430] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,431] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,431] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,431] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:54:53,431] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:54:53,432] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,432] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,432] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,433] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,433] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,433] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:54:53,433] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:54:53,433] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,434] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,437] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,437] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:54:53,437] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,438] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,438] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:54:53,438] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,438] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,438] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:54:53,439] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,439] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7437ebf40150>)]\n",
      "[2024-12-28 20:54:53,439] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:54:53,440] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,440] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,440] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,440] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,440] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,441] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,441] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,441] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,442] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,442] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,442] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,442] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,442] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,443] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,443] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,443] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,444] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,444] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,444] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,445] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:54:53,445] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,445] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,445] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,446] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,447] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,447] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,447] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:54:53,447] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,447] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,448] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:54:53,449] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,449] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,449] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,450] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:54:53,450] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:54:53,450] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:54:53,450] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:54:53,451] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,451] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,452] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x74370b162de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:54:53,452] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:54:53,452] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:54:53,452] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,453] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb18820, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:54:53,454] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,454] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 20:54:53,454] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 20:54:53,454] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,455] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:54:53,456] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,456] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,456] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,457] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,458] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,458] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,458] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,459] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,459] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,459] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,459] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,459] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,460] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,460] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,460] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:53,464] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,464] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,464] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,464] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,464] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,467] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,467] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,468] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,468] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,468] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,469] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,469] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,469] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:54:53,472] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,472] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,472] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,472] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,473] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,473] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,474] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,474] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,474] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,477] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 20:54:53,477] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 20:54:53,477] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 20:54:53,477] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 20:54:53,478] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,478] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb18820, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:54:53,478] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,478] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x71f6f80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,479] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,480] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:54:53,480] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,480] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:54:53,481] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:54:53,482] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 20:54:53,482] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 20:54:53,482] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:54:53,482] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 20:54:53,483] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 20:54:53,483] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 20:54:53,483] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 20:54:53,483] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:54:53,484] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,484] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 20:54:53,484] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 20:54:53,484] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 20:54:53,485] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:54:53,485] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 20:54:53,485] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 20:54:53,485] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 20:54:53,485] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:54:53,486] [12/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:53,486] [12/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:53,486] [12/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_20 =====\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.187 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,488] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_20 <eval_with_key>.187 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7437e931cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 20:54:53,489] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_20 =====\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,490] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:53,491] [12/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:53,491] [12/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:53,494] [12/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:53,494] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780049436176)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,494] [12/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,495] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,495] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,496] [12/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,496] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 20:54:53,497] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,497] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:54:53,497] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:54:53,498] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 20:54:53,498] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,499] [12/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,499] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,499] [12/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,500] [12/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:54:53,500] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,500] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,501] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,501] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,501] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,501] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,502] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,502] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:54:53,502] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,503] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,506] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:54:53,506] [13/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:53,507] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:34\n",
      "[2024-12-28 20:54:53,507] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:54:53,507] [13/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:54:53,508] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:54:53,509] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:54:53,509] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,509] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 20:54:53,509] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:37\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:54:53,510] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>)]\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable()]\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7437e931cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_1823720/343866.py:37\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:53,511] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,512] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 20:54:53,512] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:40\n",
      "[2024-12-28 20:54:53,512] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:53,513] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,513] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,513] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,513] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,514] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,514] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_1823720/343866.py:40\n",
      "[2024-12-28 20:54:53,514] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:53,514] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:54:53,518] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 20:54:53,519] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:43\n",
      "[2024-12-28 20:54:53,519] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:53,519] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:54:53,519] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,519] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:54:53,520] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,520] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:54:53,520] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_1823720/343866.py:43\n",
      "[2024-12-28 20:54:53,520] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:53,520] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 20:54:53,523] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 20:54:53,523] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1823720/343866.py:45\n",
      "[2024-12-28 20:54:53,523] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 20:54:53,523] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 20:54:53,524] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:54:53,524] [13/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:54:53,524] [13/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:54:53,524] [13/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_21 =====\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.188 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:54:53,525] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_21 <eval_with_key>.188 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7437e931cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 20:54:53,526] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_21 =====\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 20:54:53,527] [13/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 20:54:53,529] [13/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:54:53,529] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 127780047764688)                   # logits = self.linear(pooled_output)  # mp/ipykernel_1823720/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 20:54:53,529] [13/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_1823720/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 20:54:53,530] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,530] [13/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:54:53,531] [13/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:54:53,531] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,532] [13/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,532] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,533] [13/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:54:53,533] [13/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "    l_position_ids_ = L_position_ids_\n",
      "    l_query_states_ = L_query_states_\n",
      "    l_key_states_ = L_key_states_\n",
      "    l_value_states_ = L_value_states_\n",
      "    _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "    l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "    getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "    float_1 = getitem.float();  getitem = None\n",
      "    expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "    getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "    float_2 = getitem_1.float();  getitem_1 = None\n",
      "    _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "    float_3 = expand.float();  expand = None\n",
      "    float_4 = float_2.float();  float_2 = None\n",
      "    matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "    transpose = matmul.transpose(1, 2);  matmul = None\n",
      "    cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "    cos = cat.cos()\n",
      "    sin = cat.sin();  cat = None\n",
      "    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "    mul = cos * 1.0;  cos = None\n",
      "    mul_1 = sin * 1.0;  sin = None\n",
      "    to = mul.to(dtype = torch.float32);  mul = None\n",
      "    to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "    _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "    unsqueeze = to.unsqueeze(1);  to = None\n",
      "    unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "    mul_2 = l_query_states_ * unsqueeze\n",
      "    getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "    neg = -getitem_3;  getitem_3 = None\n",
      "    cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "    mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "    getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "    neg_1 = -getitem_5;  getitem_5 = None\n",
      "    cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "    mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "    add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "    getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "    expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "    reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "    getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "    expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "    reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "    transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "    matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "    truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "    softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "    to_2 = softmax.to(torch.float32);  softmax = None\n",
      "    dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "    matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "    transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "    contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "    reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "    l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "    return (l__self___o_proj,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    l_residual_ = L_residual_\n",
      "    add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "    to = add.to(torch.float32)\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add_1 = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "    l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "    l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "    l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "    mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "    l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "    add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "    return (add_2,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "    l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "    l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "    return (l__self___softmax,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1028, 0.1019, 0.0966, 0.1090, 0.1036, 0.0967, 0.0988, 0.0959, 0.0949,\n",
       "         0.0998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Python code from the torch._dynamo graph\n",
    "def debug_callback(graph_module, example_inputs):\n",
    "    # Generate Python code for the traced graph\n",
    "    print(graph_module.code)\n",
    "    return graph_module\n",
    "\n",
    "# Wrap your model with the debug callback\n",
    "model_optimized = torch._dynamo.optimize(debug_callback)(model)\n",
    "\n",
    "# Run your model to trigger the tracing\n",
    "model_optimized(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps - Capturing `nn.Module` with Custom ops\n",
    "\n",
    "There are instances where PyTorch implementation can have custom ops - for instance where the programmer wants to force `kernel` fusion, they can define a custom op as such and would need `torch.compile` to respect that. And similarly in cases where there ops on `numpy` or `scipy` defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lib = torch.library.Library(\"scale_custom_op\", \"DEF\")\n",
    "\n",
    "# Step 2: Define the custom op schema\n",
    "my_lib.define(\"scale_by_max(Tensor input) -> Tensor\")\n",
    "\n",
    "def scale_by_max(input: torch.Tensor) -> torch.Tensor:\n",
    "    max_value = torch.max(input)\n",
    "    return input * max_value\n",
    "\n",
    "# Use IMPL to register the implementation\n",
    "impl_lib = torch.library.Library(\"scale_custom_op\", \"IMPL\")\n",
    "impl_lib.impl(\"scale_by_max\", scale_by_max, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::hardsigmoid.out\n",
      "aten::reflection_pad3d_backward\n",
      "aten::logical_and.out\n",
      "aten::quantized_lstm.input_legacy\n",
      "aten::linalg_eig.out\n",
      "aten::log_sigmoid_backward.grad_input\n",
      "prepacked::conv2d_transpose_clamp_run\n",
      "aten::leaky_relu.out\n",
      "aten::_log_softmax_backward_data\n",
      "aten::_foreach_pow_.ScalarList\n",
      "aten::atanh.out\n",
      "aten::sgn\n",
      "aten::_to_sparse_bsr\n",
      "aten::ge.Scalar\n",
      "aten::mean.out\n",
      "aten::geqrf.a\n",
      "aten::_foreach_pow_.Scalar\n",
      "aten::xlogy.Tensor\n",
      "aten::isin.Scalar_Tensor\n",
      "aten::_foreach_cos_\n",
      "aten::std.correction_out\n",
      "aten::silu_backward.grad_input\n",
      "aten::atan2\n",
      "aten::_foreach_sinh\n",
      "aten::_test_optional_filled_intlist\n",
      "aten::bucketize.Tensor\n",
      "aten::_foreach_log_\n",
      "aten::bitwise_and.Tensor_out\n",
      "aten::_foreach_acos\n",
      "aten::lt.Tensor\n",
      "aten::pow.Tensor_Scalar\n",
      "aten::_foreach_maximum_.Scalar\n",
      "aten::round\n",
      "aten::__irshift__.Scalar\n",
      "aten::special_laguerre_polynomial_l.out\n",
      "aten::pow.Scalar\n",
      "aten::sin.out\n",
      "aten::masked_fill_.Tensor\n",
      "aten::softplus_backward.grad_input\n",
      "aten::div.Tensor_mode\n",
      "aten::linalg_matrix_exp\n",
      "aten::atanh\n",
      "aten::_foreach_round\n",
      "aten::_foreach_addcdiv_.Scalar\n",
      "aten::asinh.out\n",
      "aten::complex.out\n",
      "aten::nanmedian\n",
      "aten::clamp_min.Tensor\n",
      "aten::_foreach_lgamma_\n",
      "c10d::monitored_barrier_\n",
      "aten::digamma_\n",
      "aten::index.Tensor\n",
      "aten::atan2.out\n",
      "aten::special_modified_bessel_i1.out\n",
      "aten::_foreach_copy_\n",
      "aten::igamma\n",
      "aten::special_i1\n",
      "aten::eq.Scalar_out\n",
      "c10d::reduce_scatter_\n",
      "aten::hardshrink.out\n",
      "aten::_cummin_helper\n",
      "aten::erf_\n",
      "aten::floor_divide\n",
      "aten::hardsigmoid_backward\n",
      "aten::_foreach_mul_.Scalar\n",
      "aten::lerp.Tensor\n",
      "aten::_upsample_nearest_exact2d\n",
      "aten::bitwise_left_shift.Tensor_out\n",
      "aten::max\n",
      "aten::pow_.Tensor\n",
      "aten::_linalg_svd.U\n",
      "aten::_standard_gamma_grad\n",
      "aten::_foreach_add.Scalar\n",
      "aten::_foreach_sqrt\n",
      "aten::hardtanh.out\n",
      "aten::cumprod_\n",
      "aten::special_shifted_chebyshev_polynomial_v.out\n",
      "aten::acosh_\n",
      "aten::hardtanh_backward.grad_input\n",
      "aten::_foobar\n",
      "aten::prod.dim_int\n",
      "aten::count_nonzero.dim_IntList\n",
      "aten::bernoulli_.Tensor\n",
      "c10d::reduce_scatter_tensor_coalesced_\n",
      "aten::upsample_trilinear3d\n",
      "aten::replication_pad3d.out\n",
      "aten::isposinf.out\n",
      "aten::_foreach_log2_\n",
      "aten::mse_loss\n",
      "aten::_add_relu.Scalar\n",
      "aten::histc.out\n",
      "aten::_make_per_tensor_quantized_tensor\n",
      "aten::_make_per_channel_quantized_tensor\n",
      "aten::_foreach_addcdiv.Scalar\n",
      "aten::acosh.out\n",
      "aten::eq_.Tensor\n",
      "aten::tril\n",
      "aten::replication_pad2d.out\n",
      "aten::tan\n",
      "aten::_weight_norm_interface\n",
      "aten::aminmax\n",
      "aten::conj_physical.out\n",
      "aten::renorm.out\n",
      "aten::log2.out\n",
      "aten::bitwise_or.Tensor\n",
      "mkldnn_prepacked::conv2d_run\n",
      "aten::upsample_bilinear2d_backward\n",
      "aten::norm.dtype_out\n",
      "aten::replication_pad3d\n",
      "aten::fill_.Scalar\n",
      "aten::ge_.Tensor\n",
      "aten::_upsample_bilinear2d_aa.out\n",
      "aten::_stack\n",
      "aten::_slow_conv2d_forward.output\n",
      "aten::_fft_r2c.out\n",
      "aten::_upsample_nearest_exact3d.out\n",
      "aten::sinc_\n",
      "aten::exp_\n",
      "aten::bernoulli.out\n",
      "c10d::allreduce_coalesced_\n",
      "aten::_upsample_bicubic2d_aa_backward\n",
      "aten::avg_pool2d_backward.grad_input\n",
      "aten::tanh_backward\n",
      "aten::special_chebyshev_polynomial_t\n",
      "aten::geqrf\n",
      "aten::huber_loss.out\n",
      "aten::pow.Tensor_Scalar_out\n",
      "aten::special_airy_ai.out\n",
      "aten::clamp\n",
      "aten::special_hermite_polynomial_h\n",
      "aten::elu_\n",
      "quantized::linear_prepack_fp16\n",
      "aten::masked_scatter_\n",
      "aten::_linalg_eigh\n",
      "aten::_foreach_sub.ScalarList\n",
      "aten::reflection_pad1d_backward.grad_input\n",
      "aten::nll_loss_forward.output\n",
      "aten::__lshift__.Scalar\n",
      "aten::_log_softmax_backward_data.out\n",
      "aten::_pdist_backward\n",
      "scale_custom_op::scale_by_max\n",
      "aten::polygamma.out\n",
      "aten::_pdist_forward\n",
      "aten::gt.Scalar_out\n",
      "aten::take.out\n",
      "aten::replication_pad3d_backward\n",
      "aten::repeat_interleave.Tensor\n",
      "aten::bitwise_or.Tensor_out\n",
      "aten::mse_loss_backward.grad_input\n",
      "aten::linalg_lstsq.out\n",
      "aten::_foreach_erfc_\n",
      "aten::gelu_backward.grad_input\n",
      "quantized::linear_with_input_q_dq_qweight_dq_relu_output_fp32\n",
      "aten::_upsample_bilinear2d_aa_backward\n",
      "aten::_foreach_maximum.List\n",
      "aten::ormqr.out\n",
      "aten::_logcumsumexp.out\n",
      "prepacked::conv2d_transpose_clamp_prepack\n",
      "aten::clamp_min_.Tensor\n",
      "aten::_foreach_clamp_min.Scalar\n",
      "aten::exp\n",
      "aten::upsample_nearest2d_backward\n",
      "aten::unique_dim_consecutive\n",
      "aten::rrelu_with_noise\n",
      "aten::asinh\n",
      "aten::bitwise_not_\n",
      "aten::asinh_\n",
      "aten::log_sigmoid_forward\n",
      "aten::add_.Tensor\n",
      "aten::special_scaled_modified_bessel_k0\n",
      "aten::lcm.out\n",
      "aten::_foreach_acos_\n",
      "aten::bitwise_left_shift.Tensor\n",
      "aten::_convert_indices_from_csr_to_coo.out\n",
      "aten::glu\n",
      "aten::lgamma.out\n",
      "aten::linalg_qr\n",
      "aten::upsample_bilinear2d.out\n",
      "aten::_scaled_dot_product_flash_attention\n",
      "aten::_foreach_pow.Scalar\n",
      "aten::tanh_backward.grad_input\n",
      "aten::quantized_lstm.data_legacy\n",
      "aten::binomial\n",
      "aten::max.unary_out\n",
      "aten::xlogy_.Tensor\n",
      "aten::_compute_linear_combination\n",
      "aten::linalg_cross.out\n",
      "aten::tan.out\n",
      "quantized::embedding_bag_2bit_rowwise_offsets\n",
      "aten::segment_reduce\n",
      "sparse::qlinear_dynamic\n",
      "aten::reflection_pad3d.out\n",
      "aten::quantize_per_tensor\n",
      "aten::_fake_quantize_per_tensor_affine_cachemask_tensor_qparams\n",
      "aten::lt_.Scalar\n",
      "aten::grid_sampler_3d_backward\n",
      "aten::linalg_solve_triangular.out\n",
      "aten::addmv.out\n",
      "aten::topk\n",
      "aten::baddbmm\n",
      "aten::masked_select.out\n",
      "aten::from_file\n",
      "aten::native_channel_shuffle\n",
      "aten::_foreach_frac\n",
      "aten::_foreach_sqrt_\n",
      "aten::quantized_gru.input_legacy\n",
      "aten::reflection_pad2d.out\n",
      "aten::_foreach_minimum.ScalarList\n",
      "aten::_cdist_backward\n",
      "c10d::_allgather_base_\n",
      "aten::_add_relu_.Scalar\n",
      "aten::hardsigmoid\n",
      "aten::copysign.Tensor\n",
      "aten::cumprod.out\n",
      "aten::_linalg_slogdet\n",
      "aten::le.Tensor_out\n",
      "aten::slow_conv3d_forward.output\n",
      "aten::_foreach_mul.List\n",
      "aten::gcd.out\n",
      "aten::_foreach_log10_\n",
      "aten::special_shifted_chebyshev_polynomial_v\n",
      "aten::special_modified_bessel_k0\n",
      "aten::_fft_c2r.out\n",
      "aten::_foreach_tanh\n",
      "aten::_foreach_sin_\n",
      "aten::mse_loss.out\n",
      "aten::mish.out\n",
      "aten::threshold\n",
      "aten::index_select.out\n",
      "aten::_foreach_mul.Scalar\n",
      "aten::expm1_\n",
      "aten::cumsum_\n",
      "aten::maximum\n",
      "aten::threshold.out\n",
      "aten::_ctc_loss.Tensor\n",
      "aten::_adaptive_avg_pool3d_backward\n",
      "aten::tanh.out\n",
      "aten::glu_backward_jvp\n",
      "aten::clamp.Tensor\n",
      "mkl::_mkl_linear\n",
      "aten::special_chebyshev_polynomial_w\n",
      "aten::median\n",
      "quantized::linear_dynamic_fp16\n",
      "aten::_adaptive_avg_pool2d\n",
      "aten::special_bessel_y0\n",
      "aten::triu.out\n",
      "aten::_foreach_log10\n",
      "aten::add.Tensor\n",
      "c10d::scatter_\n",
      "aten::index_copy.out\n",
      "aten::silu\n",
      "aten::__rshift__.Tensor\n",
      "aten::upsample_trilinear3d.out\n",
      "aten::signbit.out\n",
      "aten::mish_backward\n",
      "aten::_upsample_nearest_exact1d_backward\n",
      "aten::_foreach_asin_\n",
      "aten::max_pool3d_with_indices_backward.grad_input\n",
      "aten::index.Tensor_out\n",
      "aten::gt_.Tensor\n",
      "quantized::embedding_bag_4bit_prepack\n",
      "aten::pow.Scalar_out\n",
      "aten::_fft_r2c\n",
      "aten::mul_.Tensor\n",
      "aten::resize_\n",
      "aten::cosh_\n",
      "aten::poisson\n",
      "aten::grid_sampler_2d\n",
      "aten::reflection_pad2d_backward\n",
      "aten::_foreach_mul.ScalarList\n",
      "aten::ne.Scalar_out\n",
      "aten::special_erfcx\n",
      "aten::replication_pad1d\n",
      "aten::_to_sparse\n",
      "aten::fake_quantize_per_channel_affine_cachemask\n",
      "aten::multi_margin_loss_backward.grad_input\n",
      "aten::quantize_per_tensor.tensors\n",
      "aten::_assert_async.msg\n",
      "aten::logit_backward.grad_input\n",
      "aten::_foreach_minimum_.List\n",
      "aten::ge.Tensor_out\n",
      "aten::ge.Tensor\n",
      "aten::scatter.value\n",
      "aten::_foreach_norm.Scalar\n",
      "aten::bincount\n",
      "aten::_foreach_sub.List\n",
      "aten::index_reduce\n",
      "aten::special_spherical_bessel_j0.out\n",
      "aten::randperm.generator_out\n",
      "aten::scatter.value_out\n",
      "aten::upsample_nearest1d.out\n",
      "aten::leaky_relu_\n",
      "c10d::reduce_\n",
      "aten::batch_norm_update_stats\n",
      "aten::linalg_vector_norm.out\n",
      "aten::adaptive_max_pool2d_backward.grad_input\n",
      "aten::normal_\n",
      "aten::trunc_\n",
      "aten::asin.out\n",
      "aten::_fake_quantize_learnable_per_tensor_affine_backward\n",
      "aten::_foreach_div_.ScalarList\n",
      "aten::special_entr.out\n",
      "aten::_add_relu.out\n",
      "aten::addcdiv.out\n",
      "aten::_test_functorch_fallback\n",
      "aten::nansum.out\n",
      "aten::logaddexp2\n",
      "sparse::qlinear_relu_dynamic\n",
      "aten::_foreach_lerp_.List\n",
      "aten::isin.Tensor_Scalar\n",
      "aten::glu_backward\n",
      "aten::_foreach_log\n",
      "aten::round.decimals_out\n",
      "aten::gt.Tensor_out\n",
      "aten::linalg_ldl_factor_ex.out\n",
      "aten::eye.out\n",
      "aten::sum.dim_IntList\n",
      "aten::max_pool3d_with_indices\n",
      "aten::exp2.out\n",
      "aten::lgamma\n",
      "aten::_upsample_nearest_exact2d_backward\n",
      "aten::slow_conv_transpose2d\n",
      "aten::_native_multi_head_attention\n",
      "aten::zero_\n",
      "c10d::allgather_into_tensor_coalesced_\n",
      "aten::sign_\n",
      "aten::clamp_min.Tensor_out\n",
      "aten::channel_shuffle\n",
      "aten::special_i0e\n",
      "aten::hardtanh\n",
      "aten::_efficientzerotensor\n",
      "quantized::embedding_bag_byte_unpack\n",
      "aten::gcd_\n",
      "aten::max_pool2d_with_indices_backward\n",
      "quantized::embedding_byte\n",
      "aten::_foreach_abs\n",
      "aten::addmm\n",
      "aten::min.dim\n",
      "aten::binary_cross_entropy.out\n",
      "aten::_foreach_addcdiv.ScalarList\n",
      "aten::rrelu_with_noise_\n",
      "mkldnn::_convolution_pointwise\n",
      "aten::special_chebyshev_polynomial_t.out\n",
      "quantized::quantized_rnn_relu_cell_dynamic\n",
      "aten::cos.out\n",
      "aten::_unique2\n",
      "aten::_functional_assert_async.msg\n",
      "aten::hardswish.out\n",
      "aten::quantized_lstm.input\n",
      "aten::softshrink\n",
      "aten::clamp_\n",
      "aten::lerp_.Tensor\n",
      "aten::acos_\n",
      "aten::reflection_pad3d\n",
      "aten::fmod.Tensor\n",
      "aten::div.out\n",
      "aten::std_mean.correction\n",
      "aten::sinh.out\n",
      "aten::round_.decimals\n",
      "aten::sub.out\n",
      "aten::_upsample_nearest_exact3d\n",
      "aten::gelu\n",
      "aten::lu_unpack.out\n",
      "aten::addcdiv\n",
      "aten::_foreach_clamp_min.ScalarList\n",
      "quantized::embedding_bag_2bit_unpack\n",
      "aten::special_xlog1py.out\n",
      "aten::_fft_c2c\n",
      "aten::_foreach_sin\n",
      "quantized::conv2d_dynamic\n",
      "aten::max_pool3d_with_indices_backward\n",
      "aten::hardswish_backward\n",
      "aten::narrow_copy.out\n",
      "aten::gt_.Scalar\n",
      "aten::le.Tensor\n",
      "aten::leaky_relu_backward.grad_input\n",
      "aten::_cdist_forward\n",
      "quantized::conv_transpose2d_dynamic\n",
      "aten::_foreach_tanh_\n",
      "aten::acosh\n",
      "c10d::_reduce_scatter_base_\n",
      "aten::index_select\n",
      "aten::_nested_tensor_from_mask_left_aligned\n",
      "mkldnn_prepacked::conv2d_prepack\n",
      "quantized::embedding_bag_byte_prepack\n",
      "aten::hardswish_\n",
      "aten::frac.out\n",
      "aten::_empty_affine_quantized\n",
      "aten::cholesky\n",
      "aten::random_.to\n",
      "aten::reflection_pad2d\n",
      "aten::_foreach_maximum.Scalar\n",
      "aten::isin.Tensor_Tensor\n",
      "aten::fmod.Tensor_out\n",
      "aten::remainder.Scalar_Tensor\n",
      "aten::tril_\n",
      "aten::_transform_bias_rescale_qkv\n",
      "aten::quantized_gru.data_legacy\n",
      "aten::triangular_solve.X\n",
      "aten::linalg_ldl_solve\n",
      "aten::triu_\n",
      "aten::remainder.Tensor_out\n",
      "aten::argmax.out\n",
      "aten::aminmax.out\n",
      "aten::addmm_\n",
      "aten::logit.out\n",
      "aten::_foreach_lgamma\n",
      "aten::exp.out\n",
      "aten::scatter_add.out\n",
      "aten::linalg_ldl_solve.out\n",
      "aten::_upsample_bilinear2d_aa_backward.grad_input\n",
      "aten::lgamma_\n",
      "aten::gcd\n",
      "aten::_foreach_reciprocal\n",
      "aten::amax\n",
      "aten::avg_pool3d.out\n",
      "aten::_fake_quantize_learnable_per_channel_affine\n",
      "aten::sign\n",
      "aten::im2col\n",
      "aten::_foreach_div_.List\n",
      "aten::lt_.Tensor\n",
      "aten::lt.Scalar_out\n",
      "aten::floor_divide_.Tensor\n",
      "aten::slow_conv_dilated2d\n",
      "aten::__irshift__.Tensor\n",
      "aten::sqrt.out\n",
      "aten::reciprocal_\n",
      "aten::nextafter_\n",
      "aten::nll_loss2d_forward.output\n",
      "aten::special_ndtri.out\n",
      "aten::sin_\n",
      "aten::any\n",
      "aten::_nested_from_padded\n",
      "aten::_foreach_clamp_min.List\n",
      "aten::clamp_max_\n",
      "quantized::conv_transpose1d_dynamic\n",
      "aten::special_shifted_chebyshev_polynomial_u\n",
      "_quantized::linear_prepack_fp16\n",
      "aten::sinh_\n",
      "aten::view_as_complex\n",
      "aten::_foreach_sign_\n",
      "aten::scatter_reduce.two_out\n",
      "aten::upsample_bicubic2d.out\n",
      "aten::hardshrink\n",
      "aten::_foreach_floor\n",
      "aten::triu_indices\n",
      "aten::igammac\n",
      "aten::addbmm.out\n",
      "aten::native_layer_norm\n",
      "aten::lt.Tensor_out\n",
      "aten::_foreach_minimum.Scalar\n",
      "aten::norm.ScalarOpt_dim_dtype\n",
      "aten::_foreach_mul_.Tensor\n",
      "aten::clamp_.Tensor\n",
      "aten::special_modified_bessel_i0.out\n",
      "aten::scatter_add_\n",
      "aten::_upsample_bicubic2d_aa\n",
      "aten::log_sigmoid_forward.output\n",
      "aten::upsample_nearest2d\n",
      "aten::_segment_reduce_backward\n",
      "aten::rrelu_with_noise.out\n",
      "aten::scatter.value_reduce\n",
      "aten::erfinv\n",
      "aten::fractional_max_pool3d_backward.grad_input\n",
      "aten::atan2_\n",
      "aten::trunc.out\n",
      "aten::frexp.Tensor_out\n",
      "mkldnn::_convolution_pointwise.binary\n",
      "aten::amin\n",
      "aten::dequantize.self\n",
      "aten::min.unary_out\n",
      "aten::cholesky_inverse\n",
      "aten::index_copy_\n",
      "aten::special_entr\n",
      "aten::polygamma\n",
      "aten::upsample_nearest3d.out\n",
      "aten::_adaptive_avg_pool2d_backward\n",
      "aten::isin.Scalar_Tensor_out\n",
      "aten::_foreach_clamp_min_.Scalar\n",
      "aten::dot\n",
      "aten::mul.Tensor\n",
      "aten::_linalg_solve_ex\n",
      "aten::sparse_dim\n",
      "aten::_embedding_bag_forward_only\n",
      "quantized::quantized_gru_cell_dynamic\n",
      "aten::adaptive_max_pool2d.out\n",
      "aten::quantize_per_channel\n",
      "aten::pow.Tensor_Tensor_out\n",
      "aten::nll_loss_backward.grad_input\n",
      "aten::_fft_c2c.out\n",
      "aten::linalg_lu_factor_ex\n",
      "aten::copysign.out\n",
      "aten::polar.out\n",
      "aten::special_modified_bessel_i1\n",
      "aten::bitwise_and_.Tensor\n",
      "mkldnn::_linear_pointwise.binary\n",
      "aten::narrow_copy\n",
      "aten::_foreach_sub_.List\n",
      "aten::mul.out\n",
      "aten::i0.out\n",
      "aten::mkldnn_rnn_layer_backward\n",
      "aten::upsample_nearest1d_backward.grad_input\n",
      "aten::linalg_solve_triangular\n",
      "aten::scatter.reduce\n",
      "aten::slow_conv_transpose2d.out\n",
      "aten::scatter_.value_reduce\n",
      "aten::index_add.out\n",
      "aten::_softmax\n",
      "aten::min.dim_min\n",
      "aten::log\n",
      "aten::adaptive_avg_pool3d.out\n",
      "aten::random_\n",
      "aten::native_dropout\n",
      "aten::bitwise_xor_.Tensor\n",
      "aten::linalg_cholesky_ex\n",
      "aten::scatter_add\n",
      "aten::multilabel_margin_loss_forward\n",
      "aten::max_pool2d_with_indices\n",
      "quantized::conv3d_dynamic\n",
      "aten::_foreach_maximum.ScalarList\n",
      "aten::as_strided\n",
      "aten::neg.out\n",
      "aten::sin\n",
      "aten::threshold_backward\n",
      "aten::native_batch_norm\n",
      "aten::addcmul\n",
      "aten::baddbmm_\n",
      "mkldnn::_reorder_mkldnn_rnn_layer_weight\n",
      "aten::upsample_trilinear3d_backward.grad_input\n",
      "aten::adaptive_max_pool3d_backward\n",
      "aten::huber_loss_backward.out\n",
      "aten::_softmax_backward_data\n",
      "aten::_foreach_zero_\n",
      "aten::huber_loss\n",
      "aten::upsample_linear1d\n",
      "aten::div_.Tensor\n",
      "aten::is_set_to\n",
      "aten::erfc.out\n",
      "aten::special_scaled_modified_bessel_k1\n",
      "aten::digamma\n",
      "quantized::linear_prepack_fp16_legacy\n",
      "aten::all.dim\n",
      "aten::_foreach_floor_\n",
      "aten::lerp.Scalar\n",
      "aten::_prelu_kernel_backward\n",
      "aten::index_fill_.int_Tensor\n",
      "aten::special_chebyshev_polynomial_w.out\n",
      "aten::digamma.out\n",
      "aten::_foreach_pow.ScalarAndTensor\n",
      "aten::special_bessel_y1\n",
      "aten::multinomial\n",
      "aten::reflection_pad1d.out\n",
      "aten::reflection_pad2d_backward.grad_input\n",
      "aten::floor.out\n",
      "aten::special_shifted_chebyshev_polynomial_t.out\n",
      "aten::erfc\n",
      "aten::_foreach_atan_\n",
      "aten::le_.Tensor\n",
      "aten::linalg_inv_ex\n",
      "aten::lerp.Scalar_out\n",
      "aten::special_airy_ai\n",
      "aten::_foreach_expm1\n",
      "aten::_aminmax.dim\n",
      "aten::_foreach_lerp_.Scalar\n",
      "aten::_to_sparse_csc\n",
      "aten::eq_.Scalar\n",
      "aten::relu_\n",
      "aten::logit_backward\n",
      "aten::_foreach_pow.ScalarList\n",
      "aten::rsub.Tensor\n",
      "aten::log_\n",
      "aten::special_bessel_y1.out\n",
      "aten::multi_margin_loss_backward\n",
      "aten::_histogramdd_from_bin_cts\n",
      "aten::__rshift__.Scalar\n",
      "aten::col2im.out\n",
      "aten::special_spherical_bessel_j0\n",
      "aten::round_\n",
      "aten::atan\n",
      "aten::logit_\n",
      "aten::cos\n",
      "aten::special_hermite_polynomial_h.out\n",
      "aten::avg_pool3d\n",
      "aten::div_.Tensor_mode\n",
      "aten::_foreach_log1p_\n",
      "aten::mish\n",
      "aten::smooth_l1_loss_backward.grad_input\n",
      "aten::log2\n",
      "aten::quantized_gru.data\n",
      "aten::special_zeta.out\n",
      "aten::sgn.out\n",
      "aten::normal.Tensor_Tensor_out\n",
      "aten::i0_\n",
      "aten::heaviside\n",
      "aten::max_pool3d_with_indices.out\n",
      "aten::addbmm_\n",
      "aten::_stack.out\n",
      "aten::_reshape_alias\n",
      "aten::_ctc_loss_backward\n",
      "aten::upsample_nearest2d_backward.grad_input\n",
      "aten::_foreach_reciprocal_\n",
      "aten::replication_pad1d_backward.grad_input\n",
      "aten::max_pool2d_with_indices.out\n",
      "aten::_embedding_bag_dense_backward\n",
      "aten::var.correction\n",
      "aten::fmin\n",
      "aten::hardsigmoid_backward.grad_input\n",
      "quantized::linear_relu_dynamic\n",
      "aten::nan_to_num.out\n",
      "aten::renorm\n",
      "aten::multi_margin_loss.out\n",
      "aten::_masked_softmax_backward\n",
      "aten::quantize_per_tensor_dynamic\n",
      "aten::elu\n",
      "aten::special_chebyshev_polynomial_u.out\n",
      "aten::searchsorted.Tensor\n",
      "aten::ceil.out\n",
      "aten::_foreach_clamp_min_.List\n",
      "aten::_foreach_addcmul_.Tensor\n",
      "aten::clamp_max.Tensor\n",
      "mkldnn::_linear_pointwise\n",
      "aten::linalg_lu_factor_ex.out\n",
      "aten::addcmul.out\n",
      "aten::scatter.src\n",
      "aten::prod\n",
      "aten::log_sigmoid_backward\n",
      "aten::mish_\n",
      "aten::_foreach_minimum_.ScalarList\n",
      "aten::ne.Scalar\n",
      "aten::_cummax_helper\n",
      "aten::frac_\n",
      "aten::sigmoid_backward\n",
      "aten::rsqrt\n",
      "aten::_foreach_asin\n",
      "aten::special_chebyshev_polynomial_u\n",
      "aten::_foreach_clamp_min_.ScalarList\n",
      "aten::_fused_moving_avg_obs_fq_helper\n",
      "aten::igammac.out\n",
      "aten::nansum\n",
      "aten::fractional_max_pool3d.output\n",
      "aten::max_unpool3d.out\n",
      "aten::_sample_dirichlet\n",
      "aten::leaky_relu_backward\n",
      "aten::addr\n",
      "aten::_fake_quantize_learnable_per_channel_affine_backward\n",
      "aten::lu_unpack\n",
      "aten::adaptive_max_pool3d_backward.grad_input\n",
      "aten::linspace.out\n",
      "aten::sigmoid\n",
      "aten::sign.out\n",
      "quantized::quantized_rnn_tanh_cell_dynamic\n",
      "aten::to_mkldnn\n",
      "aten::special_i1e\n",
      "aten::_foreach_frac_\n",
      "aten::searchsorted.Tensor_out\n",
      "aten::signbit\n",
      "aten::avg_pool3d_backward.grad_input\n",
      "aten::linalg_inv_ex.inverse\n",
      "aten::_compute_linear_combination.out\n",
      "aten::erfinv.out\n",
      "aten::ormqr\n",
      "aten::special_bessel_j1.out\n",
      "aten::_foreach_sub_.Scalar\n",
      "aten::eye.m_out\n",
      "aten::replication_pad2d_backward\n",
      "aten::lt.Scalar\n",
      "aten::addcdiv_\n",
      "aten::gather\n",
      "aten::log2_\n",
      "aten::avg_pool2d\n",
      "aten::linalg_cholesky_ex.L\n",
      "aten::linalg_lu\n",
      "aten::var_mean.correction\n",
      "aten::multilabel_margin_loss_backward.grad_input\n",
      "aten::log10\n",
      "aten::_log_softmax.out\n",
      "aten::_upsample_bicubic2d_aa_backward.grad_input\n",
      "aten::nonzero.out\n",
      "quantized::make_quantized_cell_params_dynamic\n",
      "aten::exp2\n",
      "mkldnn::_convolution_pointwise_.binary\n",
      "aten::isneginf.out\n",
      "aten::_foreach_pow_.List\n",
      "aten::_foreach_neg\n",
      "aten::upsample_nearest3d\n",
      "aten::searchsorted.Scalar\n",
      "aten::_foreach_erf_\n",
      "aten::_validate_compressed_sparse_indices\n",
      "aten::isneginf\n",
      "aten::_fake_quantize_learnable_per_tensor_affine\n",
      "aten::scatter_.value\n",
      "aten::linalg_ldl_factor_ex\n",
      "aten::gt.Tensor\n",
      "aten::igammac_\n",
      "aten::angle\n",
      "aten::amin.out\n",
      "aten::native_batch_norm_backward\n",
      "aten::_linalg_det\n",
      "aten::_foreach_maximum_.List\n",
      "aten::softplus\n",
      "aten::bitwise_and.Tensor\n",
      "aten::silu.out\n",
      "aten::_foreach_add.List\n",
      "aten::_foreach_sigmoid\n",
      "aten::_foreach_addcmul.ScalarList\n",
      "aten::_foreach_minimum_.Scalar\n",
      "aten::_linalg_solve_ex.result\n",
      "aten::erfc_\n",
      "aten::_foreach_erfc\n",
      "aten::_native_batch_norm_legit.no_stats_out\n",
      "aten::fractional_max_pool3d\n",
      "aten::replication_pad2d\n",
      "aten::hypot\n",
      "aten::upsample_bicubic2d\n",
      "aten::_foreach_div_.Scalar\n",
      "aten::_slow_conv2d_backward.grad_input\n",
      "aten::empty_strided\n",
      "aten::gelu.out\n",
      "aten::nonzero\n",
      "aten::exponential_\n",
      "aten::special_shifted_chebyshev_polynomial_t\n",
      "aten::var.correction_out\n",
      "aten::_nested_tensor_from_mask\n",
      "quantized::embedding_bag_byte_rowwise_offsets\n",
      "aten::special_modified_bessel_i0\n",
      "aten::normal.float_Tensor_out\n",
      "aten::atanh_\n",
      "aten::_add_relu_.Tensor\n",
      "aten::_addmm_activation\n",
      "aten::adaptive_max_pool2d_backward\n",
      "aten::lcm_\n",
      "aten::binary_cross_entropy_backward\n",
      "aten::ne_.Scalar\n",
      "aten::mse_loss_backward\n",
      "aten::leaky_relu\n",
      "aten::_foreach_div.ScalarList\n",
      "aten::special_i1e.out\n",
      "aten::fmax\n",
      "aten::sum.IntList_out\n",
      "aten::clamp_min_\n",
      "aten::_foreach_pow.List\n",
      "aten::any.dim\n",
      "aten::masked_select\n",
      "aten::trace\n",
      "aten::_foreach_ceil\n",
      "aten::norm.out\n",
      "aten::minimum\n",
      "aten::_foreach_mul_.List\n",
      "aten::elu.out\n",
      "aten::_aminmax\n",
      "aten::any.all_out\n",
      "quantized::conv_transpose3d_dynamic\n",
      "aten::__lshift__.Tensor\n",
      "aten::igamma_\n",
      "aten::lcm\n",
      "aten::cholesky_inverse.out\n",
      "aten::ceil_\n",
      "aten::pixel_unshuffle\n",
      "aten::_foreach_cosh_\n",
      "aten::nextafter.out\n",
      "aten::upsample_bicubic2d_backward.grad_input\n",
      "aten::_logcumsumexp\n",
      "aten::_foreach_add_.List\n",
      "aten::ne_.Tensor\n",
      "aten::unfold_backward\n",
      "aten::tril_indices\n",
      "prepacked::conv2d_clamp_run\n",
      "aten::native_group_norm\n",
      "aten::_foreach_clamp_max.ScalarList\n",
      "quantized::embedding_bag_byte\n",
      "aten::unique_dim\n",
      "aten::silu_\n",
      "aten::upsample_bilinear2d\n",
      "aten::_to_sparse.sparse_dim\n",
      "aten::normal.Tensor_float_out\n",
      "aten::all\n",
      "aten::masked_fill_.Scalar\n",
      "aten::_foreach_add.ScalarList\n",
      "aten::normal.float_Tensor\n",
      "aten::all.out\n",
      "aten::empty.memory_format\n",
      "aten::special_shifted_chebyshev_polynomial_w\n",
      "aten::_adaptive_avg_pool3d\n",
      "aten::pow.Tensor_Tensor\n",
      "aten::_foreach_trunc\n",
      "aten::std.correction\n",
      "aten::_foreach_div.List\n",
      "aten::_linalg_svd\n",
      "aten::_foreach_add_.Scalar\n",
      "aten::equal\n",
      "aten::special_scaled_modified_bessel_k1.out\n",
      "aten::slow_conv_transpose3d\n",
      "c10d::gather_\n",
      "aten::logical_or.out\n",
      "aten::norm.ScalarOpt_dim\n",
      "aten::nextafter\n",
      "aten::sqrt_\n",
      "aten::baddbmm.out\n",
      "aten::lerp.Tensor_out\n",
      "aten::_upsample_nearest_exact1d.out\n",
      "aten::neg_\n",
      "aten::triu\n",
      "aten::_native_batch_norm_legit.out\n",
      "aten::special_xlog1py\n",
      "aten::reflection_pad1d_backward\n",
      "aten::renorm_\n",
      "aten::special_ndtri\n",
      "aten::sub.Tensor\n",
      "aten::where.self\n",
      "aten::special_log_ndtr.out\n",
      "aten::_ctc_loss_backward.Tensor\n",
      "aten::quantized_lstm.data\n",
      "aten::_foreach_addcmul_.Scalar\n",
      "aten::log1p\n",
      "aten::adaptive_max_pool3d\n",
      "aten::hardtanh_backward\n",
      "aten::special_hermite_polynomial_he\n",
      "aten::_test_optional_intlist\n",
      "aten::exp2_\n",
      "aten::__ilshift__.Scalar\n",
      "aten::any.out\n",
      "aten::take\n",
      "aten::addmv_\n",
      "aten::special_zeta\n",
      "aten::adaptive_max_pool2d\n",
      "aten::cat.out\n",
      "aten::reflection_pad3d_backward.grad_input\n",
      "aten::special_scaled_modified_bessel_k0.out\n",
      "aten::argmin\n",
      "aten::slow_conv3d_forward\n",
      "aten::eq.Tensor\n",
      "aten::fmod_.Tensor\n",
      "aten::glu_backward.grad_input\n",
      "aten::_upsample_nearest_exact3d_backward\n",
      "aten::_transformer_encoder_layer_fwd\n",
      "aten::max_unpool2d.out\n",
      "aten::native_dropout_backward\n",
      "aten::_add_relu.Tensor\n",
      "aten::fmax.out\n",
      "aten::index_fill_.int_Scalar\n",
      "aten::geometric_\n",
      "aten::index_copy\n",
      "aten::ne.Tensor_out\n",
      "aten::_test_optional_floatlist\n",
      "aten::_to_sparse_bsc\n",
      "aten::pixel_shuffle\n",
      "aten::fractional_max_pool2d\n",
      "aten::_embedding_bag_per_sample_weights_backward\n",
      "quantization::_FloatToBfloat16Quantized\n",
      "aten::_convert_indices_from_coo_to_csr.out\n",
      "aten::scatter_.src\n",
      "aten::index_add_\n",
      "aten::special_bessel_j0\n",
      "aten::sinc\n",
      "aten::igamma.out\n",
      "aten::_foreach_exp_\n",
      "aten::nll_loss_backward\n",
      "aten::clamp_max\n",
      "aten::col2im\n",
      "aten::_linalg_slogdet.sign\n",
      "aten::_foreach_ceil_\n",
      "aten::linalg_vector_norm\n",
      "aten::_upsample_nearest_exact3d_backward.grad_input\n",
      "aten::xlogy.OutTensor\n",
      "aten::upsample_nearest1d\n",
      "aten::_empty_per_channel_affine_quantized\n",
      "aten::_convert_indices_from_csr_to_coo\n",
      "aten::threshold_\n",
      "aten::_foreach_sign\n",
      "aten::cholesky.out\n",
      "aten::elu_backward.grad_input\n",
      "aten::_embedding_bag\n",
      "aten::hypot_\n",
      "aten::min\n",
      "aten::addcmul_\n",
      "aten::angle.out\n",
      "aten::sigmoid_backward.grad_input\n",
      "mkldnn::_reorder_convolution_weight\n",
      "aten::_foreach_addcdiv.Tensor\n",
      "aten::range.out\n",
      "aten::trunc\n",
      "aten::clamp.Tensor_out\n",
      "aten::set_\n",
      "aten::_upsample_nearest_exact1d\n",
      "aten::mode\n",
      "aten::scatter_reduce.two\n",
      "quantized::embedding_bag_4bit\n",
      "aten::_unique\n",
      "aten::addr.out\n",
      "aten::adaptive_avg_pool3d_backward.grad_input\n",
      "aten::dense_dim\n",
      "quantized::embedding_4bit\n",
      "aten::silu_backward\n",
      "aten::maximum.out\n",
      "aten::grid_sampler_2d_backward\n",
      "aten::triangular_solve\n",
      "aten::_foreach_sub_.ScalarList\n",
      "c10d::recv_\n",
      "aten::cosh\n",
      "aten::sort.stable\n",
      "aten::special_shifted_chebyshev_polynomial_w.out\n",
      "aten::_index_put_impl_\n",
      "aten::logaddexp\n",
      "aten::_fused_sdp_choice\n",
      "aten::softshrink_backward.grad_input\n",
      "aten::nll_loss2d_backward\n",
      "aten::grid_sampler_3d\n",
      "aten::roll\n",
      "aten::fill_.Tensor\n",
      "aten::embedding_renorm_\n",
      "aten::bitwise_right_shift.Tensor\n",
      "aten::upsample_nearest1d_backward\n",
      "aten::_foreach_log1p\n",
      "aten::upsample_nearest3d_backward\n",
      "aten::logaddexp2.out\n",
      "aten::erfinv_\n",
      "aten::le.Scalar\n",
      "aten::special_log_ndtr\n",
      "aten::round.decimals\n",
      "aten::addmm.out\n",
      "aten::hardsigmoid_\n",
      "aten::gt.Scalar\n",
      "_quantized::linear_prepack_fp16_legacy\n",
      "aten::argmin.out\n",
      "aten::_foreach_addcdiv_.Tensor\n",
      "aten::nonzero_static\n",
      "c10d::alltoall_base_\n",
      "aten::ge_.Scalar\n",
      "aten::ne.Tensor\n",
      "aten::_cholesky_solve_helper\n",
      "aten::bitwise_right_shift_.Tensor\n",
      "aten::le.Scalar_out\n",
      "quantized::make_quantized_cell_params\n",
      "mkldnn::_reorder_convolution_transpose_weight\n",
      "aten::max.dim_max\n",
      "aten::acos.out\n",
      "aten::replication_pad1d_backward\n",
      "aten::special_chebyshev_polynomial_v\n",
      "aten::log.out\n",
      "c10d::broadcast_\n",
      "aten::log1p.out\n",
      "aten::searchsorted.Scalar_out\n",
      "aten::remainder.Tensor\n",
      "aten::sort.values_stable\n",
      "c10d::alltoall_\n",
      "aten::_make_dep_token\n",
      "aten::cosh.out\n",
      "aten::amax.out\n",
      "aten::_foreach_cos\n",
      "aten::mvlgamma.out\n",
      "aten::atan.out\n",
      "aten::special_hermite_polynomial_he.out\n",
      "aten::_foreach_minimum.List\n",
      "aten::_foreach_sigmoid_\n",
      "aten::normal.Tensor_float\n",
      "aten::nll_loss2d_forward\n",
      "aten::cauchy_\n",
      "aten::upsample_trilinear3d_backward\n",
      "aten::bitwise_right_shift.Tensor_out\n",
      "aten::median.dim_values\n",
      "aten::linalg_householder_product\n",
      "aten::ceil\n",
      "aten::_foreach_neg_\n",
      "aten::upsample_linear1d_backward.grad_input\n",
      "quantized::linear_dynamic\n",
      "aten::flip\n",
      "onednn::qconv_prepack\n",
      "quantized::embedding_bag_4bit_unpack\n",
      "aten::special_modified_bessel_k1.out\n",
      "aten::acos\n",
      "aten::add.out\n",
      "aten::nll_loss_forward\n",
      "aten::special_chebyshev_polynomial_v.out\n",
      "aten::asin\n",
      "aten::argsort.stable\n",
      "aten::slow_conv_dilated3d\n",
      "aten::_foreach_log2\n",
      "aten::isnan\n",
      "aten::i0\n",
      "aten::softshrink_backward\n",
      "aten::_foreach_clamp_max.List\n",
      "aten::_foreach_tan_\n",
      "aten::cos_\n",
      "aten::hardswish\n",
      "aten::neg\n",
      "aten::_foreach_abs_\n",
      "aten::upsample_nearest3d_backward.grad_input\n",
      "aten::multinomial.out\n",
      "aten::round.out\n",
      "aten::adaptive_max_pool3d.out\n",
      "aten::cumprod\n",
      "aten::linalg_qr.out\n",
      "aten::sinh\n",
      "aten::sspaddmm.out\n",
      "aten::_native_batch_norm_legit\n",
      "c10d::allgather_\n",
      "aten::nonzero_static.out\n",
      "aten::max_unpool3d\n",
      "aten::logical_not.out\n",
      "aten::set_.source_Storage_storage_offset\n",
      "aten::multilabel_margin_loss_forward.output\n",
      "aten::addmv\n",
      "aten::isin.Tensor_Tensor_out\n",
      "aten::div.Tensor\n",
      "c10d::allreduce_\n",
      "aten::replication_pad2d_backward.grad_input\n",
      "aten::uniform_\n",
      "aten::upsample_linear1d_backward\n",
      "aten::set_.source_Tensor\n",
      "aten::tanh_\n",
      "aten::clamp_min.out\n",
      "aten::random_.from\n",
      "aten::_slow_conv2d_forward\n",
      "aten::_linalg_det.result\n",
      "aten::_foreach_mul.Tensor\n",
      "aten::index_reduce.out\n",
      "aten::quantize_per_tensor.tensor_qparams\n",
      "aten::_foreach_round_\n",
      "aten::ge.Scalar_out\n",
      "aten::eq.Scalar\n",
      "aten::_upsample_bicubic2d_aa.out\n",
      "aten::_spdiags\n",
      "aten::tan_\n",
      "aten::_foreach_lerp.Scalar\n",
      "aten::relu\n",
      "aten::glu_jvp\n",
      "aten::_upsample_bilinear2d_aa\n",
      "aten::clamp_max_.Tensor\n",
      "aten::fractional_max_pool3d_backward\n",
      "aten::smooth_l1_loss\n",
      "aten::_softmax.out\n",
      "aten::avg_pool2d_backward\n",
      "prepacked::linear_clamp_prepack\n",
      "aten::_masked_softmax\n",
      "aten::mkldnn_rnn_layer\n",
      "aten::fractional_max_pool2d_backward\n",
      "aten::erf\n",
      "_quantized::linear_dynamic\n",
      "aten::gelu_backward\n",
      "aten::_native_batch_norm_legit.no_stats\n",
      "aten::sinc.out\n",
      "aten::scatter_.reduce\n",
      "aten::hardshrink_backward\n",
      "aten::abs.out\n",
      "aten::glu.out\n",
      "aten::fmin.out\n",
      "aten::binary_cross_entropy\n",
      "aten::avg_pool2d.out\n",
      "aten::sgn_\n",
      "aten::reflection_pad1d\n",
      "aten::special_bessel_j1\n",
      "aten::minimum.out\n",
      "aten::atan_\n",
      "aten::floor_\n",
      "aten::lerp_.Scalar\n",
      "aten::mean.dim\n",
      "aten::gather.out\n",
      "aten::max_unpool2d\n",
      "aten::_foreach_addcdiv_.ScalarList\n",
      "aten::logspace.out\n",
      "aten::fractional_max_pool2d_backward.grad_input\n",
      "aten::special_i0e.out\n",
      "aten::special_modified_bessel_k1\n",
      "aten::softplus_backward\n",
      "aten::_histogramdd_bin_edges\n",
      "aten::avg_pool3d_backward\n",
      "aten::softshrink.out\n",
      "aten::elu_backward\n",
      "aten::unique_consecutive\n",
      "prepacked::linear_clamp_run\n",
      "aten::embedding_dense_backward\n",
      "aten::prod.int_out\n",
      "aten::put_\n",
      "aten::argmax\n",
      "aten::_local_scalar_dense\n",
      "aten::upsample_nearest2d.out\n",
      "aten::log1p_\n",
      "aten::slow_conv_transpose3d.out\n",
      "aten::multi_margin_loss\n",
      "aten::eq.Tensor_out\n",
      "aten::pow_.Scalar\n",
      "aten::_scaled_dot_product_flash_attention_backward\n",
      "aten::sub_.Tensor\n",
      "aten::nll_loss2d_backward.grad_input\n",
      "aten::erf.out\n",
      "aten::upsample_linear1d.out\n",
      "aten::frac\n",
      "aten::_assert_async\n",
      "aten::log10_\n",
      "aten::_foreach_add_.ScalarList\n",
      "aten::arange.start_out\n",
      "aten::_ctc_loss\n",
      "aten::reciprocal\n",
      "aten::rsqrt_\n",
      "aten::linalg_lu_solve.out\n",
      "c10d::recv_any_source_\n",
      "aten::fake_quantize_per_tensor_affine_cachemask\n",
      "aten::copysign_.Tensor\n",
      "aten::multilabel_margin_loss_backward\n",
      "aten::_foreach_atan\n",
      "aten::_foreach_cosh\n",
      "aten::scatter.src_out\n",
      "aten::bucketize.Scalar\n",
      "aten::tanh\n",
      "aten::linalg_householder_product.out\n",
      "aten::linalg_lu_solve\n",
      "aten::isin.Tensor_Scalar_out\n",
      "aten::heaviside_\n",
      "aten::view_as_real\n",
      "aten::view\n",
      "aten::_foreach_mul_.ScalarList\n",
      "aten::bitwise_xor.Tensor_out\n",
      "aten::log10.out\n",
      "aten::nanmedian.dim_values\n",
      "aten::special_bessel_y0.out\n",
      "aten::bucketize.Tensor_out\n",
      "aten::max.dim\n",
      "aten::_nested_view_from_buffer\n",
      "aten::_slow_conv2d_backward.output_mask\n",
      "aten::linalg_eig\n",
      "aten::_foreach_clamp_max_.List\n",
      "aten::special_erfcx.out\n",
      "aten::_weight_norm_interface_backward\n",
      "aten::hardtanh_\n",
      "aten::_upsample_nearest_exact2d_backward.grad_input\n",
      "aten::bitwise_not\n",
      "aten::isposinf\n",
      "aten::smooth_l1_loss.out\n",
      "aten::sigmoid.out\n",
      "quantized::linear_relu_dynamic_fp16\n",
      "aten::le_.Scalar\n",
      "c10d::allgather_coalesced_\n",
      "aten::special_modified_bessel_k0.out\n",
      "mkldnn::_reorder_linear_weight\n",
      "aten::replication_pad1d.out\n",
      "quantized::embedding_bag_4bit_rowwise_offsets\n",
      "aten::set_.source_Storage\n",
      "aten::_foreach_clamp_max.Scalar\n",
      "aten::reciprocal.out\n",
      "c10d::barrier\n",
      "aten::scatter.value_reduce_out\n",
      "aten::_addmm_activation.out\n",
      "aten::clamp_max.Tensor_out\n",
      "aten::histogram.bin_ct\n",
      "aten::floor\n",
      "quantized::max_pool2d\n",
      "aten::_unsafe_index.Tensor\n",
      "aten::_foreach_exp\n",
      "aten::quantized_gru.input\n",
      "aten::clamp.out\n",
      "_inductor_test::realize\n",
      "aten::_fft_c2r\n",
      "aten::_softmax_backward_data.out\n",
      "aten::mm\n",
      "mkldnn::_convolution_transpose_pointwise\n",
      "aten::_convert_indices_from_coo_to_csr\n",
      "aten::_foreach_sub.Scalar\n",
      "aten::threshold_backward.grad_input\n",
      "aten::adaptive_avg_pool2d.out\n",
      "c10d::send\n",
      "aten::bitwise_left_shift_.Tensor\n",
      "aten::_foreach_expm1_\n",
      "aten::clamp_max.out\n",
      "aten::special_bessel_j0.out\n",
      "aten::__ilshift__.Tensor\n",
      "quantization::_Bfloat16QuantizedToFloat\n",
      "aten::cumsum\n",
      "aten::_upsample_nearest_exact1d_backward.grad_input\n",
      "aten::cat\n",
      "quantized::embedding_bag_2bit_prepack\n",
      "aten::native_layer_norm_backward\n",
      "aten::where.self_out\n",
      "aten::_foreach_clamp_max_.Scalar\n",
      "aten::softplus.out\n",
      "aten::bitwise_not.out\n",
      "aten::rsqrt.out\n",
      "aten::fractional_max_pool2d.output\n",
      "aten::_foreach_addcmul.Tensor\n",
      "aten::_dirichlet_grad\n",
      "aten::_foreach_erf\n",
      "aten::_prelu_kernel\n",
      "aten::histogram.bin_ct_out\n",
      "aten::expm1.out\n",
      "aten::bitwise_xor.Tensor\n",
      "aten::_linalg_eigh.eigenvalues\n",
      "aten::histogram.bins_tensor_out\n",
      "aten::_foreach_trunc_\n",
      "aten::bernoulli_.float\n",
      "aten::clamp_min\n",
      "aten::_foreach_sinh_\n",
      "aten::scatter.reduce_out\n",
      "aten::histc\n",
      "aten::special_shifted_chebyshev_polynomial_u.out\n",
      "aten::_foreach_addcmul_.ScalarList\n",
      "aten::heaviside.out\n",
      "aten::tril.out\n",
      "aten::_foreach_addcmul.Scalar\n",
      "aten::native_batch_norm.out\n",
      "aten::normal.Tensor_Tensor\n",
      "aten::log_normal_\n",
      "aten::cumsum.out\n",
      "quantized::linear_unpack.legacy\n",
      "aten::kthvalue.values\n",
      "aten::topk.values\n",
      "aten::_to_sparse_csr\n",
      "aten::upsample_bilinear2d_backward.grad_input\n",
      "aten::floor_divide.out\n",
      "aten::_foreach_lerp.List\n",
      "aten::hardshrink_backward.grad_input\n",
      "aten::_foreach_maximum_.ScalarList\n",
      "aten::linalg_cross\n",
      "aten::replication_pad3d_backward.grad_input\n",
      "aten::_foreach_div.Scalar\n",
      "aten::sqrt\n",
      "aten::index_reduce_\n",
      "aten::logaddexp.out\n",
      "aten::sigmoid_\n",
      "quantized::linear_unpack_fp16.legacy\n",
      "aten::_foreach_clamp_max_.ScalarList\n",
      "aten::expm1\n",
      "aten::addbmm\n",
      "aten::binary_cross_entropy_backward.grad_input\n",
      "aten::special_i1.out\n",
      "aten::div.out_mode\n",
      "aten::special_laguerre_polynomial_l\n",
      "aten::_log_softmax\n",
      "aten::asin_\n",
      "aten::logical_xor.out\n",
      "aten::_standard_gamma\n",
      "aten::upsample_bicubic2d_backward\n",
      "aten::histogram.bins_tensor\n",
      "aten::gelu_\n",
      "aten::mm.out\n",
      "aten::bmm.out\n",
      "mkl::_mkl_reorder_linear_weight\n",
      "aten::special_legendre_polynomial_p.out\n",
      "aten::bmm\n",
      "onednn::qlinear_prepack\n",
      "aten::native_group_norm_backward\n",
      "aten::special_legendre_polynomial_p\n",
      "aten::bitwise_or_.Tensor\n",
      "aten::_upsample_nearest_exact2d.out\n",
      "aten::linalg_lu.out\n",
      "quantized::linear_with_input_q_dq_qweight_dq_output_fp32\n",
      "quantized::conv1d_dynamic\n",
      "aten::unfold\n",
      "aten::hypot.out\n",
      "quantized::quantized_lstm_cell_dynamic\n",
      "aten::logit\n",
      "aten::max_pool2d_with_indices_backward.grad_input\n",
      "prepacked::conv2d_clamp_prepack\n",
      "aten::vdot\n",
      "aten::_histogramdd_from_bin_tensors\n",
      "aten::_foreach_tan\n",
      "aten::remainder_.Tensor\n",
      "aten::index_add\n",
      "aten::all.all_out\n",
      "aten::scatter_reduce_.two\n",
      "aten::im2col.out\n"
     ]
    }
   ],
   "source": [
    "# Verify if the op was successfully registered - \n",
    "# List all registered operators for the CPU backend\n",
    "torch._C._dispatch_print_registrations_for_dispatch_key(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Test your custom operator\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "result = torch.ops.scale_custom_op.scale_by_max(x)\n",
    "print(result)  # Output: tensor([3.0, 6.0, 9.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very cool way to see what happens during tracing in Torch Dynamo\n",
    "\n",
    "Some decorators to keep in mind - `torch._dynamo.allow_in_graph`, `torch._dynamo.disable`\n",
    "\n",
    "`torch._dynamo.allow_in_graph` - https://pytorch.org/docs/stable/generated/torch.compiler.allow_in_graph.html\n",
    "`torch._dynamo.disable` - https://pytorch.org/docs/stable/torch.compiler_fine_grain_apis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function with Custom op which treats the function opaque in the graph\n",
    "# NOTE - Feel free to change `allow_in_graph` to `disable`\n",
    "# When `disable`, we can see torch._dynamo inserts Graph Breaks\n",
    "@torch._dynamo.disable\n",
    "def scale_by_max_disable(input: torch.Tensor) -> torch.Tensor:\n",
    "    max_value = torch.max(input)\n",
    "    return input * max_value\n",
    "\n",
    "def fn(x, n):\n",
    "    y = x ** 2\n",
    "    scaled_out = scale_by_max_disable(y)\n",
    "    return (n + 1) * scaled_out\n",
    "\n",
    "# Create a 2D tensor of shape [8, 12]\n",
    "x = torch.randn(8, 12)\n",
    "\n",
    "fn_optimized = torch._dynamo.optimize(debug_callback)(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 21:39:15,587] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 21:39:15,588] [22/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_1823720/2973355815.py:9\n",
      "[2024-12-28 21:39:15,588] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2973355815.py:9\n",
      "[2024-12-28 21:39:15,588] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def fn(x, n):\n",
      "[2024-12-28 21:39:15,589] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (8, 12) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 21:39:15,590] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 21:39:15,590] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2973355815.py:10\n",
      "[2024-12-28 21:39:15,590] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 21:39:15,590] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 21:39:15,590] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 21:39:15,591] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 21:39:15,591] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_1823720/2973355815.py:10\n",
      "[2024-12-28 21:39:15,591] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 21:39:15,591] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 21:39:15,592] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 21:39:15,592] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_1823720/2973355815.py:11\n",
      "[2024-12-28 21:39:15,592] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         scaled_out = scale_by_max_disable(y)\n",
      "[2024-12-28 21:39:15,592] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL scale_by_max_disable []\n",
      "[2024-12-28 21:39:15,593] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [NullVariable, SkipFilesVariable()]\n",
      "[2024-12-28 21:39:15,593] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 21:39:15,593] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 21:39:15,593] [22/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call torch._dynamo.disable() wrapped function <function scale_by_max_disable at 0x74370a159e40> from user code at:\n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_1823720/2973355815.py\", line 11, in fn\n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     scaled_out = scale_by_max_disable(y)\n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 21:39:15,594] [22/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call torch._dynamo.disable() wrapped function <function scale_by_max_disable at 0x74370a159e40>', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/2973355815.py, line 11 in fn>], graph_break=True)\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_32 =====\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.197 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2973355815.py:10, code: y = x ** 2\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (pow_1,)\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_32 <eval_with_key>.197 opcode         name    target                   args         kwargs\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  -----------  --------\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()           {}\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1   <built-in function pow>  (l_x_, 2)    {}\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((pow_1,),)  {}\n",
      "[2024-12-28 21:39:15,595] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_32 =====\n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (8, 12)\n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (8, 12)\n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 21:39:15,596] [22/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 21:39:15,598] [22/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 21:39:15,598] [22/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 21:39:15,598] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,599] [22/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,599] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,599] [22/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,600] [22/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[8, 12], stride=[12, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 21:39:15,601] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 21:39:15,601] [23/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in fn> /tmp/ipykernel_1823720/2973355815.py:11\n",
      "[2024-12-28 21:39:15,602] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in fn> /tmp/ipykernel_1823720/2973355815.py:11\n",
      "[2024-12-28 21:39:15,602] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         scaled_out = scale_by_max_disable(y)\n",
      "[2024-12-28 21:39:15,602] [23/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'] (8, 12) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 46 [TensorVariable()]\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST scaled_out [TensorVariable()]\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in fn> /tmp/ipykernel_1823720/2973355815.py:12\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return (n + 1) * scaled_out\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 21:39:15,603] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST scaled_out [ConstantVariable(int)]\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from <resume in fn> /tmp/ipykernel_1823720/2973355815.py:12\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return (n + 1) * scaled_out\n",
      "[2024-12-28 21:39:15,604] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~^~~~~~~~~~~~\n",
      "[2024-12-28 21:39:15,605] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 21:39:15,605] [23/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in fn> (RETURN_VALUE)\n",
      "[2024-12-28 21:39:15,606] [23/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 21:39:15,606] [23/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1823720/2973355815.py, line 12 in <resume in fn>>], graph_break=False)\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_34 =====\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.198 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_ : torch.Tensor):\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_ = L_stack0_\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1823720/2973355815.py:12, code: return (n + 1) * scaled_out\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = 11 * l_stack0_;  l_stack0_ = None\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul,)\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_34 <eval_with_key>.198 opcode         name       target                   args             kwargs\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ---------  -----------------------  ---------------  --------\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_  L_stack0_                ()               {}\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul        <built-in function mul>  (11, l_stack0_)  {}\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output     output                   ((mul,),)        {}\n",
      "[2024-12-28 21:39:15,607] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 21:39:15,608] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 21:39:15,608] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_34 =====\n",
      "[2024-12-28 21:39:15,608] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_: (8, 12)\n",
      "[2024-12-28 21:39:15,608] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (8, 12)\n",
      "[2024-12-28 21:39:15,608] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 21:39:15,609] [23/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 21:39:15,609] [23/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 21:39:15,610] [23/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 21:39:15,610] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # return (n + 1) * scaled_out  # mp/ipykernel_1823720/2973355815.py:12 in <resume in fn>\n",
      "[2024-12-28 21:39:15,611] [23/0] torch._dynamo.guards.__guards: [DEBUG] L['n'] == 10                                                  # return (n + 1) * scaled_out  # mp/ipykernel_1823720/2973355815.py:12 in <resume in fn>\n",
      "[2024-12-28 21:39:15,611] [23/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 21:39:15,611] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,612] [23/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,612] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,612] [23/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 21:39:15,613] [23/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[8, 12], stride=[12, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_x_ : torch.Tensor):\n",
      "    l_x_ = L_x_\n",
      "    pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "    return (pow_1,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_ : torch.Tensor):\n",
      "    l_stack0_ = L_stack0_\n",
      "    mul = 11 * l_stack0_;  l_stack0_ = None\n",
      "    return (mul,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.6816e+02, 8.8991e+01, 8.3288e+00, 7.8264e+01, 4.8526e+02, 2.0099e+02,\n",
       "         1.5638e+02, 7.9788e+01, 1.7875e+00, 2.1475e+02, 3.3856e+02, 5.0690e+01],\n",
       "        [3.3107e+00, 4.8355e+02, 6.9774e+02, 1.7692e+03, 3.3361e-01, 3.3363e-01,\n",
       "         8.2016e+00, 1.4130e+01, 3.6216e+01, 9.9916e+00, 2.4171e+02, 5.1062e+02],\n",
       "        [6.5912e+00, 2.0415e+02, 7.1961e+00, 1.0481e-01, 4.8566e+01, 1.8002e+00,\n",
       "         3.0583e+01, 1.3076e+00, 2.5707e-01, 2.5313e+01, 1.6161e-01, 2.2411e+02],\n",
       "        [2.1959e+01, 1.8195e+02, 3.4877e+02, 5.6309e+01, 3.7395e+02, 1.5310e+02,\n",
       "         1.0064e+02, 3.1950e+00, 2.5059e+01, 4.5118e+01, 6.8103e+01, 2.8782e+02],\n",
       "        [1.3931e+02, 1.4041e+02, 1.4435e+02, 4.5509e+02, 5.5842e+01, 1.8447e+01,\n",
       "         2.0515e+01, 7.7866e+01, 1.5829e+02, 1.9011e+01, 1.1486e+03, 3.8148e+01],\n",
       "        [7.4403e+01, 2.9473e+02, 1.1278e-01, 2.0259e+02, 3.5902e+02, 3.3594e+02,\n",
       "         3.5972e+02, 1.3227e+02, 6.1379e-01, 1.8703e+00, 8.8691e+01, 3.9799e+01],\n",
       "        [2.2081e+02, 5.2756e+01, 3.2421e+02, 7.2112e+01, 3.6023e+02, 3.9442e+02,\n",
       "         6.0547e-01, 5.7193e+01, 4.0512e+00, 3.0154e+02, 2.0695e+02, 4.0301e+01],\n",
       "        [7.4527e-01, 6.6325e+01, 6.9035e+01, 3.6313e+01, 3.0314e+01, 1.8156e+02,\n",
       "         6.9475e+02, 8.3420e+01, 3.7075e+02, 5.1905e+01, 8.6054e+01, 7.9059e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_optimized(x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaWithCustomOp(nn.Module):\n",
    "    def __init__(self, llama_model_name: str, output_dim: int):\n",
    "        super(LlamaWithCustomOp, self).__init__()\n",
    "\n",
    "        # Load the LLaMA model\n",
    "        full_llama = AutoModel.from_pretrained(llama_model_name)\n",
    "\n",
    "        # Extract and store the embedding layer\n",
    "        self.embed_tokens = full_llama.embed_tokens\n",
    "\n",
    "        # Extract and store the first decoder layer\n",
    "        self.first_layer = full_llama.layers[0]\n",
    "\n",
    "        # Linear layer to map to output dimensions\n",
    "        llama_hidden_dim = full_llama.config.hidden_size\n",
    "        self.linear = nn.Linear(llama_hidden_dim, output_dim)\n",
    "\n",
    "        # Softmax for output probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Explicit typing of input_ids and attention_mask for TorchScript\n",
    "    def forward(self, input_ids, custom_forward_fn=None):\n",
    "        # Generate embeddings\n",
    "        embeddings = self.embed_tokens(input_ids)\n",
    "\n",
    "        # Check if position_ids need to be explicitly handled\n",
    "        position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Pass through the first layer with position_ids\n",
    "        layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
    "\n",
    "        # Pool the output (mean along sequence dimension)\n",
    "        pooled_output = torch.mean(layer_output, dim=1)\n",
    "\n",
    "        # Map to output dimension\n",
    "        logits = self.linear(pooled_output)\n",
    "\n",
    "        if custom_forward_fn is not None:\n",
    "            # Apply the custom operation\n",
    "            custom_logits = custom_forward_fn(logits)\n",
    "        else:\n",
    "            custom_logits = logits\n",
    "\n",
    "        # Apply softmax\n",
    "        probs = self.softmax(custom_logits)\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:46:33,029] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,030] [15/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_1813942/1905900009.py:22\n",
      "[2024-12-28 20:46:33,031] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1813942/1905900009.py:22\n",
      "[2024-12-28 20:46:33,031] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 20:46:33,031] [15/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:46:33,032] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,032] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1813942/1905900009.py:24\n",
      "[2024-12-28 20:46:33,032] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:46:33,032] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,032] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,033] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,033] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,033] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,034] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_1813942/1905900009.py:24\n",
      "[2024-12-28 20:46:33,034] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:46:33,034] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,036] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 20:46:33,036] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1813942/1905900009.py:27\n",
      "[2024-12-28 20:46:33,036] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:46:33,036] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,036] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,037] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,037] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,037] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:46:33,037] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,037] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,038] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,038] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,038] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 20:46:33,038] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:46:33,039] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:46:33,039] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x77e02131cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:46:33,039] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_1813942/1905900009.py:27\n",
      "[2024-12-28 20:46:33,039] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:46:33,039] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,040] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:46:33,040] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:46:33,040] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,040] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_1813942/1905900009.py:27\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1813942/1905900009.py:30\n",
      "[2024-12-28 20:46:33,041] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:46:33,042] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,042] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,043] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,043] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,043] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,043] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,043] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,044] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_1813942/1905900009.py:30\n",
      "[2024-12-28 20:46:33,044] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:46:33,044] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,044] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,047] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,048] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,048] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,049] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,049] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,049] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,049] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,050] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,051] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,051] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,051] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,051] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,052] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,052] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,052] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,052] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,053] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,053] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,053] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,053] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,053] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,054] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,055] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,056] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,057] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,057] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,057] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,057] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,057] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,058] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x77df42f43380>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,058] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,058] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,058] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x77df4872a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:46:33,059] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,060] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:46:33,060] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,060] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,060] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,060] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,061] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,062] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,065] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,066] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,066] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,066] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,066] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,067] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,067] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,067] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,068] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,068] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,068] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,068] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,069] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,069] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,070] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,070] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,070] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,071] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,071] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,071] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,071] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,072] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,072] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,073] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,073] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,073] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,074] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,074] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,074] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,074] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,074] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,075] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,075] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,075] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,075] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,076] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,076] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,076] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,077] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,077] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,077] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,079] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,080] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,080] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,081] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,081] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,081] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,084] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,085] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,085] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,086] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,086] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,086] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,086] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,087] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,087] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,087] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:46:33,088] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,088] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,088] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:46:33,089] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,089] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:46:33,090] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,090] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,090] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,090] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,091] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:46:33,092] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,092] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,093] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,093] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,094] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,094] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,094] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,095] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,095] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,095] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,095] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,095] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:46:33,096] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:46:33,096] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,097] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,097] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,097] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,097] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,098] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:46:33,099] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:46:33,099] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,100] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:46:33,102] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,103] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,103] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,103] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,103] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,104] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,104] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,104] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,105] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,105] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,106] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,106] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,106] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,107] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,107] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,107] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,107] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,108] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,108] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,108] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,109] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,109] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,109] [15/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:46:33,110] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,110] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,111] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,112] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,112] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,112] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,112] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,114] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,114] [15/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,114] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,114] [15/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,114] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,115] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,115] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,115] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,115] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:46:33,115] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,116] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,116] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,116] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:46:33,116] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,117] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,117] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:46:33,117] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,117] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,117] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,118] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,119] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:46:33,120] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,121] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,121] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:46:33,121] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,121] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,121] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,122] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:46:33,123] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:46:33,124] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,126] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,126] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,126] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,126] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,126] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,127] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,127] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,127] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,128] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,128] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,128] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,128] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,129] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,129] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,129] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,129] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,130] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,130] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,130] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,131] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,131] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,131] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,132] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,132] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,132] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,132] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,133] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,133] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,134] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,135] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,136] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,136] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,136] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,136] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,136] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,137] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,138] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,138] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,138] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:46:33,138] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,139] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,139] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,141] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,141] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,141] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,141] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xa5e7e30, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:46:33,143] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,143] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:46:33,143] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:46:33,143] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:46:33,144] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:46:33,144] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:46:33,144] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:46:33,144] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:46:33,145] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,145] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,145] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:46:33,145] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:46:33,145] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:46:33,146] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,146] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,147] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:46:33,147] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,147] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,147] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,148] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,148] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:46:33,148] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,148] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,148] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,149] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,150] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,150] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,150] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,151] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,151] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,151] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,153] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,153] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,153] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,154] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,154] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,154] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,155] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,155] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,155] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,155] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,155] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,157] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,158] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,158] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,158] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,158] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,158] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,159] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,159] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,159] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,159] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,159] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,161] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,161] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,161] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,162] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:46:33,162] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,162] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,163] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,163] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,163] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,163] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,164] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,164] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,164] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,165] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,165] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,165] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,166] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,166] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,167] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,167] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,167] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,168] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,168] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,168] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,169] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,170] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,170] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,170] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:46:33,170] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,171] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,171] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,171] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,172] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,172] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,172] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,173] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,173] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,174] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,174] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,174] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,175] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,176] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,177] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,178] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,178] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,178] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:46:33,178] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,179] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,179] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,179] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,179] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,180] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,180] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,180] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,180] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,181] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,181] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,181] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,182] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,182] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,182] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,182] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,183] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,183] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,183] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,183] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,184] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,184] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,184] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:46:33,184] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:46:33,184] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,185] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,185] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,185] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,185] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,185] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:46:33,186] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:46:33,186] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,186] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:46:33,187] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:46:33,187] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 20:46:33,187] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,187] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,187] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,188] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,188] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xa5e7e30, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:46:33,188] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:46:33,188] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,189] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,190] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,191] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,192] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x77df4872a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 20:46:33,193] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:46:33,193] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,196] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,198] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,199] [15/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_1813942/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 20:46:33,202] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 20:46:33,203] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,203] [15/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_1813942/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_23 =====\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.190 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1813942/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1813942/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_23 <eval_with_key>.190 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x77e02131cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 20:46:33,205] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_23 =====\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,206] [15/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,207] [15/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,210] [15/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,211] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800784744016)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1813942/1905900009.py:24 in forward\n",
      "[2024-12-28 20:46:33,211] [15/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1813942/1905900009.py:24 in forward\n",
      "[2024-12-28 20:46:33,212] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 95329072)                    # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_1813942/1905900009.py:27 in forward\n",
      "[2024-12-28 20:46:33,213] [15/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,214] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,214] [15/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,215] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,215] [15/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,216] [15/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,218] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,219] [16/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:46:33,220] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 20:46:33,220] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:46:33,221] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,222] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:46:33,223] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,223] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 20:46:33,223] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:46:33,223] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,224] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:46:33,224] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:46:33,224] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,224] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,224] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,225] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,225] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,225] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,226] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 20:46:33,226] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,226] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,226] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,229] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,229] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Explanation for custom_forward_fn=None ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 20:46:33,229] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,229] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,229] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,230] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,230] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,231] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,232] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,232] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,233] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,233] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,233] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,234] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,234] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,234] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,234] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,235] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,235] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,235] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,235] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,236] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,236] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,236] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,237] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,237] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,238] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,238] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,238] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,238] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,238] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,239] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,240] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,241] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,242] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,243] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,243] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,243] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,243] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,244] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,244] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,244] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,244] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,245] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,245] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,245] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:46:33,246] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,246] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,246] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:46:33,246] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,246] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:46:33,247] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,247] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,247] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,247] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,248] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:46:33,248] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,248] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,248] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,249] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,249] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,249] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,249] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,249] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:46:33,250] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,251] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,251] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,251] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,251] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,252] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:46:33,252] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:46:33,252] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,253] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,254] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:46:33,254] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,254] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,254] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,254] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:46:33,255] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,255] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,255] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,255] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,256] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,256] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,256] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,256] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,257] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,257] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,258] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,258] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,258] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,259] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,259] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,259] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,259] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,260] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,260] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,260] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,260] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,261] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,261] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:46:33,262] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,263] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,263] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,263] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,263] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,264] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,265] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,265] [16/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,266] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,266] [16/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,266] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,266] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,266] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 20:46:33,267] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 20:46:33,268] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 20:46:33,269] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,270] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 20:46:33,271] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 20:46:33,272] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,274] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,274] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,274] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,275] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,275] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,275] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,275] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,275] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,276] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,276] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,276] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,276] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,276] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,277] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,278] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,278] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,278] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,279] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,279] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,279] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,279] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,280] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,280] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,280] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,281] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,284] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,284] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,284] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,285] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,287] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,287] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,287] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,287] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,287] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,288] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,289] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 20:46:33,290] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,291] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,292] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x77df42f42fc0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,298] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,298] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,298] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,298] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xa5e7e30, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:46:33,301] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,301] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:46:33,301] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:46:33,302] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:46:33,302] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:46:33,303] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:46:33,303] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:46:33,303] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:46:33,303] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,304] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,304] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:46:33,304] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:46:33,305] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:46:33,305] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,305] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,306] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:46:33,306] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,307] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,307] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,307] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,307] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:46:33,308] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,308] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,309] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:46:33,310] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,310] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,311] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,312] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,312] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,312] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,313] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,314] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,314] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,315] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,315] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,315] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,315] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,321] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,322] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,322] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,322] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,322] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,323] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,328] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,328] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,328] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,329] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,329] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,330] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,330] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,330] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,331] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,331] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,331] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,335] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,335] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,335] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,335] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:46:33,335] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,336] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,337] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,337] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,337] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,337] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,337] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,338] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,338] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,338] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,339] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,339] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,339] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,339] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,339] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,340] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,341] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,341] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,341] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,341] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,341] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,342] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,342] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,342] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,342] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,343] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,343] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,343] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,344] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,344] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,344] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,344] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,344] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,345] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,345] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,345] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,345] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:46:33,345] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,346] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,346] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,346] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,346] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,346] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,347] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,349] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,350] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,351] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,351] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,351] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:46:33,351] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:46:33,352] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,352] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,352] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,352] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,352] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,353] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:46:33,353] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:46:33,353] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,353] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:46:33,353] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,354] [16/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xa5e7e30, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 20:46:33,355] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 20:46:33,355] [16/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 20:46:33,355] [16/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,355] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,355] [16/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:46:33,357] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,357] [16/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:46:33,358] [16/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_25 =====\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.191 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_25 <eval_with_key>.191 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x77e02131cde0>  (add,)                                    {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 20:46:33,359] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_25 =====\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,360] [16/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,364] [16/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,364] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800765877520)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,365] [16/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,365] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,366] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,366] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,366] [16/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,367] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 95329072)                # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 20:46:33,367] [16/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,367] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,368] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,368] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,368] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,369] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 20:46:33,369] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,369] [16/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,369] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,370] [16/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,370] [16/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:46:33,370] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,371] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,371] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,371] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,372] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,373] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,374] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,377] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,378] [16/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,379] [16/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,385] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,388] [17/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:46:33,389] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 20:46:33,389] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 20:46:33,390] [17/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,392] [17/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:46:33,395] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 20:46:33,395] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 20:46:33,396] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 20:46:33,396] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 20:46:33,396] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 20:46:33,397] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 20:46:33,397] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,398] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 20:46:33,398] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 20:46:33,398] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 20:46:33,398] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:46:33,399] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,399] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,400] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 20:46:33,400] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,401] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,401] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,401] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 20:46:33,401] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:46:33,401] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,402] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,402] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:46:33,403] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,403] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,403] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,403] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:46:33,403] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,404] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,404] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,404] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,404] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,404] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,405] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 20:46:33,405] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,405] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,407] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,407] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:46:33,407] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,407] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,408] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,408] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,409] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,409] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,409] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 20:46:33,409] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,409] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,412] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,412] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:46:33,412] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,412] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,413] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,413] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,413] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,414] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,414] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 20:46:33,414] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,414] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,416] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,417] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:46:33,417] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,417] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 20:46:33,417] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,417] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,418] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,418] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,418] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,418] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,419] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,421] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,421] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,421] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,421] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,422] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,422] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 20:46:33,422] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,422] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,423] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,423] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:46:33,423] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,423] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 20:46:33,423] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,424] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,424] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,424] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,424] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,424] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,425] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,425] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,425] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,426] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:46:33,426] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,426] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,427] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,427] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,428] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,429] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,430] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:46:33,430] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,430] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 20:46:33,430] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 20:46:33,431] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 20:46:33,431] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,431] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,432] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,432] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,432] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,433] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,433] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,433] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:46:33,433] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,433] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,434] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,435] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,435] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,435] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,436] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,436] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 20:46:33,436] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,436] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,437] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,437] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 20:46:33,437] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 20:46:33,437] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 20:46:33,437] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,438] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,438] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,438] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:46:33,438] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,438] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 20:46:33,439] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,440] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,441] [17/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 20:46:33,442] [17/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 20:46:33,442] [17/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 20:46:33,443] [17/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_27 =====\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.192 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,444] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_27 <eval_with_key>.192 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 20:46:33,445] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_27 =====\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,446] [17/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,447] [17/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,463] [17/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,463] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800882320656)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:46:33,464] [17/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 20:46:33,464] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,465] [17/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,465] [17/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,466] [17/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,466] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 20:46:33,467] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,467] [17/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,468] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,468] [17/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,468] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 17880144)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 20:46:33,469] [17/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,469] [17/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,473] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,475] [18/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:46:33,476] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 20:46:33,476] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 20:46:33,477] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 20:46:33,479] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:46:33,481] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:46:33,483] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 20:46:33,484] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,485] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 20:46:33,485] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,485] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:46:33,485] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,485] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,486] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:46:33,486] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:46:33,486] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,486] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,486] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 20:46:33,487] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,488] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,492] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,492] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,493] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,493] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,493] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,493] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,494] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,494] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,494] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,494] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,495] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,495] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,495] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,495] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,496] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,496] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,496] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,496] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,496] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,497] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,497] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,497] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,497] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,498] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,498] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,498] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,498] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,499] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,500] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,501] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,502] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,503] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,504] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x77df42f42a20>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,504] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,504] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,504] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,505] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x77e021a32670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:46:33,505] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,505] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 20:46:33,505] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:46:33,506] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 20:46:33,507] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 20:46:33,507] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,507] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,507] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,507] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,508] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 20:46:33,508] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,508] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,508] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,508] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,509] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,509] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,509] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,509] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,509] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xa5d0fc0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:46:33,510] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,510] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 20:46:33,511] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,511] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,511] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 20:46:33,511] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 20:46:33,511] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,512] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,512] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,512] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,513] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,513] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:46:33,513] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,513] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,514] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:46:33,514] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,515] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,515] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,515] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,516] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:46:33,520] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,520] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,521] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,521] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:46:33,521] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,522] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:46:33,523] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,523] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,524] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,524] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:46:33,524] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:46:33,525] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:46:33,526] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:46:33,526] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 20:46:33,528] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 20:46:33,528] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,528] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:46:33,529] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,531] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 20:46:33,531] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,531] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:46:33,531] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 20:46:33,531] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,532] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,532] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,532] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,532] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,533] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,533] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,533] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:46:33,534] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,534] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,534] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:46:33,534] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,536] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 20:46:33,540] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,540] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,541] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,541] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:46:33,541] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:46:33,543] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 20:46:33,543] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,543] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 20:46:33,544] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:46:33,544] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 20:46:33,544] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 20:46:33,545] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,545] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,545] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 20:46:33,545] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 20:46:33,546] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 20:46:33,546] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,547] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:46:33,547] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 20:46:33,548] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,549] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:46:33,549] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,550] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,550] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,550] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 20:46:33,550] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,551] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,551] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,551] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:46:33,552] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,552] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,553] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 20:46:33,553] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 20:46:33,553] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,554] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,554] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,555] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 20:46:33,555] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 20:46:33,556] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,556] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,556] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,556] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,557] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,557] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,557] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,557] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,557] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:46:33,558] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,559] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,560] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,561] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 20:46:33,561] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,561] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,561] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:46:33,562] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,563] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,563] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,563] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,566] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,568] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,568] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,569] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,569] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,569] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,569] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,569] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,570] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,570] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,570] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:46:33,571] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,571] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,571] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,572] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,572] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,572] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable()]\n",
      "[2024-12-28 20:46:33,572] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,573] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,573] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,573] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,573] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:46:33,573] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,574] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,574] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,574] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 20:46:33,575] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,575] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,575] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:46:33,576] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 20:46:33,576] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,576] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 20:46:33,576] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:46:33,577] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,578] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,578] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 20:46:33,578] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,580] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,580] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:46:33,581] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 20:46:33,581] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,581] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 20:46:33,581] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 20:46:33,582] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,583] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,583] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 20:46:33,583] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,583] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,583] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,584] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,584] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,584] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 20:46:33,584] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 20:46:33,585] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,585] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:46:33,585] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:46:33,585] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:46:33,585] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,586] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,586] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,586] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:46:33,586] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,587] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:46:33,588] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,588] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:46:33,588] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:46:33,588] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 20:46:33,588] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,589] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,589] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,589] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:46:33,589] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,590] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:46:33,591] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,591] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:46:33,591] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:46:33,591] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:46:33,591] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,592] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:46:33,593] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,593] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,594] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,594] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,594] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:46:33,594] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,595] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:46:33,595] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,596] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,596] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:46:33,597] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,597] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,597] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,598] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 20:46:33,598] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:46:33,598] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,599] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,599] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,599] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xa5d0fc0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 20:46:33,599] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,599] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 20:46:33,600] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,600] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 20:46:33,600] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,600] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,600] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,601] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,601] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,601] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,601] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x77e021a32670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 20:46:33,601] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,602] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,602] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,602] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,602] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,603] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 20:46:33,605] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x77df487944b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,606] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,607] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 20:46:33,607] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:46:33,607] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:46:33,607] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,608] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,608] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,608] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,608] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,609] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:46:33,610] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,610] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,610] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 20:46:33,610] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 20:46:33,610] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 20:46:33,611] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,611] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,611] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,611] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,611] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,612] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 20:46:33,612] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,612] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,613] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:46:33,614] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:46:33,615] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,615] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,615] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x77df48899790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:46:33,616] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:46:33,617] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,618] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:46:33,619] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:46:33,619] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,620] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,620] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,620] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,620] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:46:33,621] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,621] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,621] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,621] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,622] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:46:33,622] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,622] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,623] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:46:33,623] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:46:33,623] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:46:33,623] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:46:33,624] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:46:33,625] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,625] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,625] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,625] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,626] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,626] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:46:33,627] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,627] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,627] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,627] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,628] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:46:33,628] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,628] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,629] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,629] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,629] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,629] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,630] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,630] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,630] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:46:33,631] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,631] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,631] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable()]\n",
      "[2024-12-28 20:46:33,632] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,632] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,632] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,633] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,633] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,633] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,634] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,635] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x77df48899790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:46:33,635] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,635] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,636] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,636] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,636] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:46:33,637] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,637] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,637] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,637] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 20:46:33,638] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,639] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,639] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,639] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 20:46:33,640] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 20:46:33,640] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,640] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,641] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,641] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,641] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,641] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,641] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x77df48899790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,642] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:46:33,643] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:46:33,643] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:46:33,643] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,643] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:46:33,645] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 20:46:33,645] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,646] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,646] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,646] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,647] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:46:33,647] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,647] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,647] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,647] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 20:46:33,649] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 20:46:33,650] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 20:46:33,651] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 20:46:33,651] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,652] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,652] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,652] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,652] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,652] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 20:46:33,653] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,653] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,653] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,653] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,654] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 20:46:33,654] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,654] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,655] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,655] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,655] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,655] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,656] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,656] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,656] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 20:46:33,656] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,657] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,657] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable()]\n",
      "[2024-12-28 20:46:33,657] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,657] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,657] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x77e02131cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,658] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,658] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,658] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,659] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x77df48899790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,660] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 20:46:33,661] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,661] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,661] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,661] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,662] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:46:33,663] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,663] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 20:46:33,663] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 20:46:33,663] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 20:46:33,663] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,664] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,664] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x77df487944b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 20:46:33,664] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,664] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,665] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,666] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,666] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:46:33,666] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:46:33,666] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:46:33,667] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,667] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,667] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,667] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,668] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,668] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 20:46:33,668] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:46:33,668] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,668] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x77df486ede60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:46:33,669] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,670] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:46:33,670] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:46:33,670] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:46:33,671] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,672] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,673] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,673] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,673] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,673] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,673] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,674] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,674] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,674] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,674] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:46:33,674] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,675] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,675] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,675] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,677] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,677] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,677] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,679] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:46:33,679] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:46:33,679] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,680] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,680] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,680] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,680] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,680] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,681] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,681] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,681] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:46:33,682] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,683] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,684] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,684] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,684] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,684] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,685] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,685] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x77df486ede60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:46:33,686] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,686] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:46:33,686] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:46:33,686] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 20:46:33,686] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 20:46:33,687] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,687] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,687] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,688] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,688] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 20:46:33,688] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 20:46:33,688] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x77df486ede60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,689] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 20:46:33,690] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,690] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 20:46:33,691] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 20:46:33,691] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,691] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,692] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,693] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,693] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,693] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,693] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,694] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,694] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,694] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,695] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,695] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,695] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,696] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,696] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,696] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,696] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,697] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 20:46:33,697] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,697] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,697] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 20:46:33,697] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,698] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,698] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,698] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,701] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 20:46:33,702] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 20:46:33,702] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,702] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,702] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,702] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,703] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,703] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,703] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,703] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,703] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,704] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,704] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,704] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,704] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,705] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:46:33,705] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:46:33,705] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,705] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,705] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,706] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,708] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,708] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x77df486ede60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 20:46:33,708] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,708] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:46:33,708] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:46:33,709] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,709] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,709] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,709] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,710] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,710] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,710] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,710] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,711] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,711] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:46:33,711] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:46:33,711] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,712] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,712] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,712] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:46:33,712] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:46:33,712] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,714] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 20:46:33,715] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,715] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 20:46:33,715] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,715] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,715] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,716] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,716] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 20:46:33,716] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:46:33,716] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,717] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:46:33,717] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 20:46:33,717] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 20:46:33,717] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:46:33,718] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:46:33,719] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,719] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:46:33,719] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>)]\n",
      "[2024-12-28 20:46:33,720] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,720] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,720] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,720] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,721] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,721] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x77e02152a5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,721] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:46:33,721] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:46:33,721] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,724] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:46:33,724] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,724] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 20:46:33,725] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,725] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,725] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 20:46:33,725] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:46:33,725] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,726] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:46:33,726] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:46:33,726] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:46:33,726] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 20:46:33,727] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,727] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 20:46:33,727] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x77e021529940>)]\n",
      "[2024-12-28 20:46:33,728] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,728] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,728] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,728] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,729] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,729] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,729] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x77e021529940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,730] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 20:46:33,730] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:46:33,730] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,730] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:46:33,731] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:46:33,731] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:46:33,731] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,731] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,731] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x77e02131cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:46:33,732] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,734] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,734] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 20:46:33,734] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 20:46:33,734] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:46:33,734] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 20:46:33,735] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,735] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 20:46:33,735] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 20:46:33,736] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,740] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,740] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,741] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,741] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,741] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,742] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 20:46:33,742] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,742] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:46:33,742] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:46:33,743] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:46:33,743] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 20:46:33,743] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 20:46:33,743] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,744] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,744] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,744] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:46:33,744] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:46:33,744] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 20:46:33,749] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 20:46:33,750] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:46:33,750] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 20:46:33,751] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 20:46:33,751] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:46:33,751] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 20:46:33,752] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,752] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:46:33,752] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:46:33,753] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:46:33,753] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 20:46:33,753] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 20:46:33,754] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,754] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,754] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,754] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,755] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 20:46:33,755] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:46:33,755] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,756] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,756] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 20:46:33,756] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:46:33,757] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,757] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,758] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:46:33,758] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,759] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,759] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,760] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:46:33,760] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:46:33,761] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,761] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,762] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,763] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,763] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,764] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 20:46:33,764] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:46:33,764] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,767] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,768] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 20:46:33,768] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 20:46:33,768] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:46:33,769] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,769] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 20:46:33,769] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 20:46:33,769] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 20:46:33,773] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,773] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 20:46:33,773] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 20:46:33,774] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 20:46:33,774] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 20:46:33,774] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,774] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,775] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,775] [18/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:46:33,776] [18/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:46:33,776] [18/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:46:33,777] [18/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_29 =====\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.193 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,780] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_29 <eval_with_key>.193 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x77e0220058a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x77e02131cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x77e022005bc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x77e02131cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x77e02131cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x77e02131cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x77e02152a5c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x77e021529940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x77e02131cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 20:46:33,782] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_29 =====\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,787] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,788] [18/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,788] [18/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,793] [18/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,793] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:46:33,793] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:46:33,794] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800882320656)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,794] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,794] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:46:33,795] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 20:46:33,795] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 95329072)                   # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:46:33,795] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,796] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 95329072)                 # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 20:46:33,796] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,797] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 95329072)                 # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 20:46:33,797] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,797] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 95329072)                 # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 20:46:33,798] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,798] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,798] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 20:46:33,799] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 20:46:33,799] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 20:46:33,799] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,800] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 20:46:33,800] [18/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,801] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,801] [18/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,801] [18/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 20:46:33,802] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:46:33,802] [18/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 20:46:33,802] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,802] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,803] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,803] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,804] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,804] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,804] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,805] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,805] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,805] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,806] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,806] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,807] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,811] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,812] [19/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,812] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 20:46:33,812] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 20:46:33,813] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,814] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,815] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,815] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:46:33,815] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,815] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,816] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 20:46:33,816] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,816] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,816] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:46:33,816] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,817] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,818] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,818] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 20:46:33,818] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 20:46:33,818] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,818] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 20:46:33,819] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:46:33,819] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,819] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,819] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,820] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,820] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,820] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,821] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 20:46:33,821] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 20:46:33,821] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,821] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,824] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,825] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,825] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,825] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,825] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,826] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,826] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,826] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,827] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,828] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,828] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,828] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,828] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,828] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,829] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,829] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,829] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,830] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,831] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,832] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x77df42f42520>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,833] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 20:46:33,834] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,835] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,836] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,836] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 20:46:33,836] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,836] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,836] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,837] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,837] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,837] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,837] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,837] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,838] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,839] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,840] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 20:46:33,842] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,843] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,843] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,843] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,843] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 20:46:33,844] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,844] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,844] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,844] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,845] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,845] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,845] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,845] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,846] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,846] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,846] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,846] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,847] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,847] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,847] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,847] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,847] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,848] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 20:46:33,848] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,849] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,850] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,850] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,850] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,850] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,851] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,851] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x77df489cf870, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 20:46:33,851] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,852] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,853] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,853] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,853] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,854] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 20:46:33,854] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 20:46:33,854] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,854] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,856] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,856] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 20:46:33,856] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,857] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,857] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 20:46:33,857] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,857] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,858] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 20:46:33,858] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,858] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x77e022b20150>)]\n",
      "[2024-12-28 20:46:33,859] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,859] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,859] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,860] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,861] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,861] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,861] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,862] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,862] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,862] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,862] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,863] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,863] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,863] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,863] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,864] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,865] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 20:46:33,866] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable())]\n",
      "[2024-12-28 20:46:33,867] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 20:46:33,867] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,867] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,867] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x77df42f42de0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 20:46:33,868] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 20:46:33,868] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 20:46:33,868] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,868] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xa5e5220, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:46:33,870] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,870] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 20:46:33,870] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 20:46:33,870] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 20:46:33,870] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,871] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,872] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 20:46:33,872] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,872] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,872] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,873] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,873] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,873] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,873] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,873] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,874] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,874] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,874] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,875] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,879] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,880] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,880] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,880] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,880] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,882] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,882] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,883] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 20:46:33,887] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,887] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,887] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,887] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,890] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,890] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,890] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,890] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,890] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,894] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xa5e5220, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 20:46:33,895] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,896] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x5ca5640, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 20:46:33,896] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,896] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:46:33,896] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,897] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 20:46:33,898] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 20:46:33,898] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 20:46:33,898] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 20:46:33,899] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:46:33,900] [19/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:46:33,901] [19/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_30 =====\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.194 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_30 <eval_with_key>.194 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x77e02131cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 20:46:33,902] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_30 =====\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,904] [19/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,906] [19/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,907] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800765877520)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,907] [19/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,907] [19/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,908] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,908] [19/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,908] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 20:46:33,909] [19/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,909] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:46:33,910] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 20:46:33,910] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 20:46:33,910] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,911] [19/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,911] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,912] [19/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,912] [19/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 20:46:33,912] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,913] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,913] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,913] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,914] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,914] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,915] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,915] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 20:46:33,916] [19/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,916] [19/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,920] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 20:46:33,920] [20/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_1813942/1905900009.py:30\n",
      "[2024-12-28 20:46:33,921] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:30\n",
      "[2024-12-28 20:46:33,921] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 20:46:33,921] [20/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 20:46:33,922] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 20:46:33,923] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 20:46:33,923] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,923] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 20:46:33,923] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,924] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,924] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:33\n",
      "[2024-12-28 20:46:33,924] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:46:33,924] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 20:46:33,925] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 20:46:33,925] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x77e02131cde0>)]\n",
      "[2024-12-28 20:46:33,925] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x77e02131cde0>), TensorVariable()]\n",
      "[2024-12-28 20:46:33,925] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,926] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,926] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x77e02131cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 20:46:33,926] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_1813942/1905900009.py:33\n",
      "[2024-12-28 20:46:33,926] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:46:33,926] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,927] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 20:46:33,928] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:36\n",
      "[2024-12-28 20:46:33,928] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:46:33,928] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,928] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,928] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,929] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,929] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,929] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_1813942/1905900009.py:36\n",
      "[2024-12-28 20:46:33,929] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:46:33,929] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,932] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 20:46:33,932] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:38\n",
      "[2024-12-28 20:46:33,932] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 20:46:33,932] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:42\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = logits\n",
      "[2024-12-28 20:46:33,933] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits []\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:45\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,934] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 20:46:33,935] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,935] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 20:46:33,936] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_1813942/1905900009.py:45\n",
      "[2024-12-28 20:46:33,936] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 20:46:33,936] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 20:46:33,937] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1813942/1905900009.py:47\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 20:46:33,938] [20/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1813942/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_31 =====\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.195 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1813942/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1813942/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1813942/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 20:46:33,939] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_31 <eval_with_key>.195 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x77e02131cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_31 =====\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 20:46:33,940] [20/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,941] [20/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 20:46:33,942] [20/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 20:46:33,942] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 131800784744016)                   # logits = self.linear(pooled_output)  # mp/ipykernel_1813942/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 20:46:33,943] [20/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_1813942/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 20:46:33,943] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,944] [20/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 20:46:33,944] [20/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 20:46:33,944] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 8820832)              # if custom_forward_fn is not None:  # mp/ipykernel_1813942/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 20:46:33,945] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,945] [20/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,946] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,946] [20/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 20:46:33,947] [20/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_1813942/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x77e02131cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x77e02131cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x77e0220058a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x77e02131cde0>\n",
      "    <function _exit_autocast at 0x77e022005bc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x77e02131cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x77e02131cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x77e02131cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x77e02152a5c0>\n",
      "    <function dropout at 0x77e021529940>\n",
      "    <built-in method matmul of type object at 0x77e02131cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x77e02131cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x77e02131cde0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800784744016)\"]\n",
      "    Object Weakref: <weakref at 0x77df42395f80; to 'LlamaWithCustomOp' at 0x77df42f4ae50>\n",
      "    Guarded Class Weakref: <weakref at 0x77df608b6110; to 'type' at 0x2a7f8030 (LlamaWithCustomOp)>\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df48932a70; to 'Tensor' at 0x77df42f44f50>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 9:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df48932a70; to 'Tensor' at 0x77df42f44f50>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 10:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 12:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 13:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df42303c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 17:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 18:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 21:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 22:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 23:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e0284c8c70; to 'type' at 0x77e021319080 (dtype)>\n",
      "  Guard 24:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 27:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df42303970; to 'Tensor' at 0x77df41f21130>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 29:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 30:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 31:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 32:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800765877520)\"]\n",
      "    Object Weakref: <weakref at 0x77df42330b80; to 'LlamaDecoderLayer' at 0x77df41d4cd10>\n",
      "    Guarded Class Weakref: <weakref at 0x77df42f39670; to 'type' at 0xa711060 (LlamaDecoderLayer)>\n",
      "  Guard 33:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 35:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 36:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df42303970; to 'Tensor' at 0x77df41f21130>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 41:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd397b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 43:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df423ca520; to 'Tensor' at 0x77df41f3e5d0>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 48:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 17880144)\"]\n",
      "    Object Weakref: <weakref at 0x77df42b34720; to 'Logger' at 0x77df48cf0690>\n",
      "    Guarded Class Weakref: <weakref at 0x77e02f688a40; to 'type' at 0x110d450 (Logger)>\n",
      "  Guard 49:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df42303c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 50:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 54:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800882320656)\"]\n",
      "    Object Weakref: <weakref at 0x77df41f3b240; to 'LlamaAttention' at 0x77df48c59510>\n",
      "    Guarded Class Weakref: <weakref at 0x77df4869e070; to 'type' at 0xa70fbc0 (LlamaAttention)>\n",
      "  Guard 59:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd397b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 61:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 62:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 64:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 68:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 69:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df41fba660; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 70:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 73:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df41fba660; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 78:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 79:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df423ca520; to 'Tensor' at 0x77df41f3e5d0>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 86:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 88:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df41f3ae30; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 92:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df41f9a4d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 93:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df41f9a4d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 94:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd4a7a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 95:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df42303c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 96:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 97:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 99:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df42303c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 101:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e0284c8c70; to 'type' at 0x77e021319080 (dtype)>\n",
      "  Guard 102:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 104:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800882320656)\"]\n",
      "    Object Weakref: <weakref at 0x77df41f3b240; to 'LlamaAttention' at 0x77df48c59510>\n",
      "    Guarded Class Weakref: <weakref at 0x77df4869e070; to 'type' at 0xa70fbc0 (LlamaAttention)>\n",
      "  Guard 109:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 95329072)\"]\n",
      "    Object Weakref: <weakref at 0x77df41f3ae30; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 112:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 115:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 123:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 124:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 125:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 127:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 128:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df42303970; to 'Tensor' at 0x77df41f21130>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 131:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd576a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 132:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 135:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 138:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 139:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 140:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e0284c8c70; to 'type' at 0x77e021319080 (dtype)>\n",
      "  Guard 141:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df41fb8450; to 'Tensor' at 0x77df41e776b0>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 144:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 145:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd6fce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800765877520)\"]\n",
      "    Object Weakref: <weakref at 0x77df42330b80; to 'LlamaDecoderLayer' at 0x77df41d4cd10>\n",
      "    Guarded Class Weakref: <weakref at 0x77df42f39670; to 'type' at 0xa711060 (LlamaDecoderLayer)>\n",
      "  Guard 149:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd74950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 150:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 151:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 131800784744016)\"]\n",
      "    Object Weakref: <weakref at 0x77df42395f80; to 'LlamaWithCustomOp' at 0x77df42f4ae50>\n",
      "    Guarded Class Weakref: <weakref at 0x77df608b6110; to 'type' at 0x2a7f8030 (LlamaWithCustomOp)>\n",
      "  Guard 153:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 154:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 155:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x77e02fd576a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 159:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x77df41e45350; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x77e022149a80; to 'torch._C._TensorMeta' at 0x5ae9b30 (Tensor)>\n",
      "  Guard 161:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.1876, 0.1646, 0.0858, 0.3371, 0.1072, 0.0287\n",
      "OutputGraph.call_user_compiler   0.0004, 0.0003, 0.0004, 0.0007, 0.0002, 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "torch._dynamo.reset()\n",
    "model_w_custom_op = LlamaWithCustomOp(llama_model_name, output_dim).to(\"cuda\")\n",
    "\n",
    "# Step 1: Analyze with custom_forward_fn=None\n",
    "print(\"=== Explanation for custom_forward_fn=None ===\")\n",
    "explanation_none = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=None)\n",
    "print(explanation_none)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:43,456] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,457] [21/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,460] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,460] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,463] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,468] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,476] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,476] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,503] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,503] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,504] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,505] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,505] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,512] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,512] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,514] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,514] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,516] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,519] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,519] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:43,522] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,522] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,524] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,524] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,527] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,527] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,533] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:43,534] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:43,534] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,537] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:43,539] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,539] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,548] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,548] [21/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:43,549] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,549] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,553] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,553] [21/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,567] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,567] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,569] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,570] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,570] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,584] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,585] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,585] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,591] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,591] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,605] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,614] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,614] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,616] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,621] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,621] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,623] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,627] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,627] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,631] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:43,631] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,633] [21/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:23:43,635] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,635] [21/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_34 =====\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.219 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_34 <eval_with_key>.219 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_34 =====\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,641] [21/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,642] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:43,642] [21/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:43,643] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:23:43,643] [21/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,645] [21/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,645] [21/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Explanation for custom_forward_fn=custom_scale_fn ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:43,657] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,658] [22/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,660] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,661] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,664] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,664] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,671] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,671] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,672] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,672] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,673] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,677] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,677] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,678] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,679] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,686] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:43,696] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,698] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,698] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,704] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:43,704] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,711] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,711] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,715] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:43,721] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,721] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:43,728] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,730] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,730] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,733] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,734] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,734] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,736] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,736] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,745] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,772] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,786] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,786] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,788] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,799] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,806] [22/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,806] [22/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,809] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,809] [22/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_36 =====\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.220 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_36 <eval_with_key>.220 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_36 =====\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,814] [22/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,818] [22/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,818] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,819] [22/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,819] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,821] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:23:43,821] [22/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,828] [22/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,832] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,834] [23/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:43,835] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:43,835] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,836] [23/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,837] [23/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,838] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,841] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,841] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,843] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,843] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,872] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,872] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,879] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,879] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,880] [23/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,881] [23/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,881] [23/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,883] [23/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_38 =====\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.221 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_38 <eval_with_key>.221 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_38 =====\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,887] [23/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,887] [23/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,905] [23/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,906] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:43,906] [23/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,908] [23/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,908] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,911] [23/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,914] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,917] [24/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,918] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,918] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,919] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,921] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,923] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,925] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,927] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,928] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:23:43,928] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,932] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,068] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,068] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,088] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,092] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,093] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,095] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,095] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,099] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:44,099] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,101] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,102] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,102] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:23:44,104] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,104] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,107] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,111] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,111] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,114] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,118] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:23:44,118] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:44,121] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,121] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,125] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,125] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,136] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,152] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,155] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,172] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,172] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,179] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,183] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,191] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,191] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,192] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,193] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,193] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,196] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:44,198] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,223] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,223] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:44,233] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,233] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,241] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,246] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,246] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,251] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,261] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,277] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:23:44,277] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,281] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,292] [24/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_40 =====\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.222 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_40 <eval_with_key>.222 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_40 =====\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,301] [24/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,305] [24/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,305] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,306] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,306] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,322] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:44,323] [25/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,326] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,357] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,359] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,359] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,366] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,366] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,379] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,388] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,391] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,391] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_41 =====\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.223 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_41 <eval_with_key>.223 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_41 =====\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,412] [25/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,412] [25/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,414] [25/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,414] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,417] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:44,417] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:44,418] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:23:44,418] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,419] [25/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,420] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,421] [25/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,424] [25/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:44,425] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,426] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,426] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,427] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,427] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,428] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,428] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,429] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,429] [25/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,430] [25/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,435] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:44,436] [26/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,439] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,440] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:44,440] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [UserFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn [NullVariable]\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call scale_by_max from <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 16:23:44,455] [26/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object scale_by_max at 0x7bf4c5d5f130, file \"/tmp/ipykernel_414314/2274816616.py\", line 6>\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:6 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def scale_by_max(input: torch.Tensor) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:7 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,457] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD max [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,457] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call max_1 from scale_by_max /tmp/ipykernel_414314/2274816616.py:7 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~^^^^^^^\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST max_value [TensorVariable()]\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:8 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return input * max_value\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input []\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST max_value [TensorVariable()]\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from scale_by_max /tmp/ipykernel_414314/2274816616.py:8 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return input * max_value\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~^~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object scale_by_max at 0x7bf4c5d5f130, file \"/tmp/ipykernel_414314/2274816616.py\", line 6>\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 386 []\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_42 =====\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.224 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2274816616.py:7, code: max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         max_1 = torch.max(l__self___linear)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2274816616.py:8, code: return input * max_value\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = l__self___linear * max_1;  l__self___linear = max_1 = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(mul);  mul = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_42 <eval_with_key>.224 opcode         name               target                                                   args                       kwargs\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -------------------------  ----------\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                         {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)             {'dim': 1}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                    {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  max_1              <built-in method max of type object at 0x7bf5a531cde0>   (l__self___linear,)        {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                <built-in function mul>                                  (l__self___linear, max_1)  {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (mul,)                     {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)    {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_42 =====\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] max_1: ()\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 136291731076128)      # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 46\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "    <built-in method max of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 12:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 13:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 17:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 21:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 22:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 24:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 32:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 41:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 42:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 48:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 49:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5915c60; to 'Tensor' at 0x7bf4c5f63e30>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 50:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3f830; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 69:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 75:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e7bc90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 76:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 78:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 79:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 85:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3e750; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 86:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 88:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 89:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e7bc90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 91:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 99:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 100:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 101:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 102:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 104:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5915c60; to 'Tensor' at 0x7bf4c5f63e30>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 105:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3f830; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3e750; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 123:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 124:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 125:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67375b0; to 'Tensor' at 0x7bf4c5983d70>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 128:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 135:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 138:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 136291731076128)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b4467a10; to 'type' at 0x86f540 (function)>\n",
      "  Guard 151:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 153:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 154:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c63cad40; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 155:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 161:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.1902, 0.1733, 0.0812, 0.4060, 0.1112, 0.0400\n",
      "OutputGraph.call_user_compiler   0.0005, 0.0004, 0.0008, 0.0004, 0.0004, 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Analyze with custom_forward_fn=custom_scale_fn (no reset here)\n",
    "print(\"\\n=== Explanation for custom_forward_fn=custom_scale_fn ===\")\n",
    "explanation_custom = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=scale_by_max)\n",
    "print(explanation_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:48,605] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:48,606] [27/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:48,608] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,612] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,618] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:48,618] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,623] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,629] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,631] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,631] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,633] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,633] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,646] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,656] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,656] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,667] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,670] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,673] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:48,683] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,683] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:48,695] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,710] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,712] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:48,716] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,717] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,717] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:48,718] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,718] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:48,720] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,720] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,721] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:48,722] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,722] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,727] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,727] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,728] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,728] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,735] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,742] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,742] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,749] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,749] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,752] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,755] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,758] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,758] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,759] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,759] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,761] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,766] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,766] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,770] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,770] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,777] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,777] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,783] [27/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_43 =====\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.225 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_43 <eval_with_key>.225 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_43 =====\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:48,786] [27/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:48,790] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:23:48,790] [27/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,791] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,791] [27/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,792] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,793] [27/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,793] [27/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,796] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:48,796] [28/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:48,797] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:48,797] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,798] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:48,799] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,803] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,803] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,808] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,808] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,810] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,810] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,823] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,823] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,826] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:48,829] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,829] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,830] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,830] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,835] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:48,835] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,842] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,844] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,847] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:48,848] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,848] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,851] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,854] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:48,854] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,861] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,866] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,866] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,870] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,871] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,872] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,873] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,873] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,877] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,877] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,879] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,879] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,881] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,882] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,882] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,884] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,885] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,885] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,886] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,892] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,892] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,904] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,904] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,905] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:48,905] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:48,908] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,908] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,911] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,913] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,913] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,918] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,927] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,928] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,928] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,935] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:48,935] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,936] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,936] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,939] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,941] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,941] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,943] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,950] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,950] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,956] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,964] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,964] [28/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,965] [28/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,965] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,966] [28/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:48,968] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,968] [28/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_45 =====\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.226 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_45 <eval_with_key>.226 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_45 =====\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:48,973] [28/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:48,973] [28/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:48,977] [28/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:48,977] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,978] [28/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,978] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:48,979] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:48,979] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,980] [28/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,980] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:23:48,981] [28/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,981] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,982] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,982] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,983] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,984] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,984] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,985] [28/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,985] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,986] [28/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_input_ids_ : torch.Tensor):\n",
      "    l_input_ids_ = L_input_ids_\n",
      "    l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "    arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "    unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "    return (l__self___embed_tokens, unsqueeze)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add);  add = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "    return (mul_1,)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:48,987] [28/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:48,988] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,988] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,989] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,990] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,991] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,992] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,992] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,993] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,994] [28/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,995] [28/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,001] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,005] [29/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:49,007] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:49,007] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:49,008] [29/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,010] [29/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,024] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,033] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:49,033] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,037] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,043] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,043] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,048] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,048] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,056] [29/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:49,056] [29/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:49,057] [29/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:49,058] [29/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_47 =====\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.227 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_47 <eval_with_key>.227 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_47 =====\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,081] [29/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,081] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:49,082] [29/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:49,082] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,083] [29/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,083] [29/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,084] [29/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,084] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:23:49,085] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,086] [29/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,087] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,087] [29/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,088] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:23:49,089] [29/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,090] [29/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,093] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,095] [30/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,096] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,096] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,097] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:49,098] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,100] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,101] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,103] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,103] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,107] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,109] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,109] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,112] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,112] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,113] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,114] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,114] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,116] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,116] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,126] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:49,133] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,133] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,136] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,136] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,138] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,138] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,139] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,139] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,144] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:49,144] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,146] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,147] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,147] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:23:49,149] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,149] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,157] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,157] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,158] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,158] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,159] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,159] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,162] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,165] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,175] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,175] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,177] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,184] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,184] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,191] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:49,191] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:49,196] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,198] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:49,200] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,200] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,203] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,203] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,207] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,207] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,208] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,208] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,209] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,209] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,211] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,211] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:49,224] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,229] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,229] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,234] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,238] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,252] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,252] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,257] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:49,258] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,258] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,261] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "    l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "    l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "    view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    return (transpose, transpose_1, transpose_2)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,266] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,266] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,275] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,275] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,282] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,292] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,300] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,313] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,319] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,324] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,326] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,326] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,329] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,331] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:49,332] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:23:49,332] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,337] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,337] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,348] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:23:49,348] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,354] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,354] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,364] [30/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_49 =====\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.228 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_49 <eval_with_key>.228 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_49 =====\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,376] [30/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,376] [30/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,382] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,382] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,383] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,383] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,384] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:49,384] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,385] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:23:49,385] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,386] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:49,386] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,387] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:23:49,387] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,388] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,388] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,391] [30/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,391] [30/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,393] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,393] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,394] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,394] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,397] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,397] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,401] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,402] [31/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,405] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,415] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,415] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,420] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,420] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,435] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:49,435] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,444] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:49,444] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,451] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,451] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,477] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,477] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_50 =====\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.229 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_50 <eval_with_key>.229 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_50 =====\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,498] [31/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,498] [31/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,500] [31/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,500] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,504] [31/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,504] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,508] [31/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,508] [31/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,512] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,513] [32/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:49,514] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:49,514] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:49,515] [32/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:42\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = logits\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits []\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,534] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_51 =====\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.230 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_51 <eval_with_key>.230 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_51 =====\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,538] [32/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,539] [32/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,539] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:49,540] [32/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:49,540] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,541] [32/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,541] [32/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,542] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 8820832)              # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:23:49,542] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "    l_position_ids_ = L_position_ids_\n",
      "    l_query_states_ = L_query_states_\n",
      "    l_key_states_ = L_key_states_\n",
      "    l_value_states_ = L_value_states_\n",
      "    _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "    l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "    getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "    float_1 = getitem.float();  getitem = None\n",
      "    expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "    getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "    float_2 = getitem_1.float();  getitem_1 = None\n",
      "    _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "    float_3 = expand.float();  expand = None\n",
      "    float_4 = float_2.float();  float_2 = None\n",
      "    matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "    transpose = matmul.transpose(1, 2);  matmul = None\n",
      "    cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "    cos = cat.cos()\n",
      "    sin = cat.sin();  cat = None\n",
      "    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "    mul = cos * 1.0;  cos = None\n",
      "    mul_1 = sin * 1.0;  sin = None\n",
      "    to = mul.to(dtype = torch.float32);  mul = None\n",
      "    to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "    _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "    unsqueeze = to.unsqueeze(1);  to = None\n",
      "    unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "    mul_2 = l_query_states_ * unsqueeze\n",
      "    getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "    neg = -getitem_3;  getitem_3 = None\n",
      "    cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "    mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "    getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "    neg_1 = -getitem_5;  getitem_5 = None\n",
      "    cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "    mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "    add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "    getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "    expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "    reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "    getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "    expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "    reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "    transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "    matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "    truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "    softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "    to_2 = softmax.to(torch.float32);  softmax = None\n",
      "    dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "    matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "    transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "    contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "    reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "    l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "    return (l__self___o_proj,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    l_residual_ = L_residual_\n",
      "    add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "    to = add.to(torch.float32)\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add_1 = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "    l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "    l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "    l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "    mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "    l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "    add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "    return (add_2,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "    l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "    l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "    return (l__self___softmax,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0991, 0.0959, 0.1000, 0.0948, 0.1064, 0.0984, 0.0997, 0.1023, 0.1015,\n",
       "         0.1020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap your model with the debug callback\n",
    "model_custom_optimized = torch._dynamo.optimize(debug_callback)(model_w_custom_op)\n",
    "\n",
    "# Run your model to trigger the tracing\n",
    "model_custom_optimized(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the TorchDynamo behavior further\n",
    "\n",
    "As seen in the implementation for the custom op - `scale_by_max`, it is defined for the CPU backend.\n",
    "\n",
    "So obviously, the next thing I wanted to understand was what happens if I move the model to a CUDA device, i.e. Nvidia GPU, and `TorchDynamo` encounters a custom-op with only a CPU backend.\n",
    "\n",
    "The next few cells talk about this in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TorchDynamo captures graphs instead of executing operations directly:\n",
    "# When we wrap the model with torch._dynamo.optimize(debug_callback), TorchDynamo intercepts the Python bytecode and traces the computation graph.\n",
    "# During this tracing phase, TorchDynamo does not execute operations immediately. Instead, it records the operations (including any custom operator) into an FX graph.\n",
    "# Since the actual execution of scale_by_max was deferred, no error was triggered at this stage.\n",
    "#\n",
    "# Using decorators like `@torch._dynamo.disable`, we can force TorchDynamo to insert a GraphBreak for the `custom_forward_fn` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable only graph breaks in TORCH LOGS\n",
    "os.environ[\"TORCH_LOGS\"] = \"+graph_breaks\"\n",
    "\n",
    "custom_lib = torch.library.Library(\"scale_op_eager\", \"DEF\")\n",
    "\n",
    "# Step 2: Define the custom op schema\n",
    "custom_lib.define(\"scale_by_max_eager(Tensor input) -> Tensor\")\n",
    "\n",
    "@torch._dynamo.disable\n",
    "def scale_by_max_eager(input: torch.Tensor) -> torch.Tensor:\n",
    "    max_value = torch.max(input)\n",
    "    return input * max_value\n",
    "\n",
    "# Use IMPL to register the implementation\n",
    "impl_lib = torch.library.Library(\"scale_op_eager\", \"IMPL\")\n",
    "impl_lib.impl(\"scale_by_max_eager\", scale_by_max_eager, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:24:08,899] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:08,900] [33/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,908] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,908] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,913] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:08,913] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:08,915] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:08,923] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,923] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,946] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,946] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,956] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:08,960] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,960] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,964] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:08,965] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:08,966] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,966] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,968] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,970] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:08,971] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:08,971] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:08,974] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:08,975] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:08,988] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,988] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,992] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:08,992] [33/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,995] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,002] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,007] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,007] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,008] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,012] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,012] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,023] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,026] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,026] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,030] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,030] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,032] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,032] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,040] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,040] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,046] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,046] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,049] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,060] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,060] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,061] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,064] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,064] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,065] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,065] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,067] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,069] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,069] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,070] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,070] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,071] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,071] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,072] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,072] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,074] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,075] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,080] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,081] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,081] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,083] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,085] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,088] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,088] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:24:09,095] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,095] [33/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_52 =====\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.231 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_52 <eval_with_key>.231 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_52 =====\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,098] [33/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,098] [33/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,101] [33/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,101] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,104] [33/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,104] [33/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,114] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,115] [34/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,117] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,121] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,121] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,122] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,122] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,124] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,129] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,129] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,141] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,141] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:09,144] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,146] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,146] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,152] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:09,152] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,158] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,158] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,163] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,174] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,174] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,189] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,192] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,192] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,197] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,197] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,204] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,212] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,219] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,225] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,238] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,247] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,248] [34/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,249] [34/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_54 =====\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.232 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_54 <eval_with_key>.232 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_54 =====\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,253] [34/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,253] [34/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,259] [34/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,260] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,261] [34/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,261] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,262] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,262] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,263] [34/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,263] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:24:09,264] [34/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,264] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,266] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,266] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,267] [34/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,267] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,270] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,270] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,271] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,271] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,272] [34/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,273] [34/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,279] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,282] [35/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:24:09,283] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:24:09,283] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,284] [35/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,285] [35/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,287] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,287] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,290] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,290] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,291] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,295] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,295] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,296] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,296] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,299] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,299] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,317] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,318] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,318] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,319] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,319] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,331] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,331] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,333] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,340] [35/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,340] [35/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_56 =====\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.233 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_56 <eval_with_key>.233 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_56 =====\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,345] [35/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:24:09,358] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,358] [35/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,359] [35/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,359] [35/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:24:09,362] [35/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,362] [35/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,365] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,368] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,370] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,372] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,373] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,374] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,375] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:24:09,375] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,383] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,383] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,385] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,385] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,395] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,395] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,401] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,405] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,405] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,406] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,411] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:24:09,411] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,413] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,413] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,414] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:24:09,415] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,415] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,422] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,434] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,434] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,436] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,436] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,442] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,443] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,443] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,447] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,447] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,450] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,450] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,454] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,473] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,474] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,474] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,475] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,482] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,482] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:24:09,492] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,496] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:24:09,501] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,501] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:24:09,506] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,506] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,509] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,509] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,530] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,544] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,547] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,550] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,558] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,565] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,578] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:24:09,578] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,586] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,591] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,593] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,598] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,604] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,607] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,611] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,612] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,613] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:24:09,613] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,616] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,620] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:24:09,620] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,627] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,627] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,633] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,633] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,636] [36/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_58 =====\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.234 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_58 <eval_with_key>.234 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_58 =====\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,648] [36/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,650] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,650] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:24:09,653] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,653] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,658] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,661] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,661] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,662] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,662] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,663] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,668] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,669] [37/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,671] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,697] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,705] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,705] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,712] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_59 =====\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.235 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_59 <eval_with_key>.235 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_59 =====\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,761] [37/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,761] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,762] [37/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,762] [37/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,769] [37/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,772] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,772] [38/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,780] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,781] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,781] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,782] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,782] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [SkipFilesVariable()]\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [SkipFilesVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,791] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn [NullVariable]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, SkipFilesVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0> from user code at:\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 40, in <resume in forward>\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>], graph_break=True)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_60 =====\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.236 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___linear,)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_60 <eval_with_key>.236 opcode         name              target                                                   args                    kwargs\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------  -------------------------------------------------------  ----------------------  ----------\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_       L_stack0_0_                                              ()                      {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean              <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)          {'dim': 1}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear  L__self___linear                                         (mean,)                 {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output            output                                                   ((l__self___linear,),)  {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_60 =====\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,803] [38/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,804] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:24:09,804] [38/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:24:09,805] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,805] [38/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,806] [38/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,806] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 136291217694912)      # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,808] [38/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,808] [38/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,811] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,811] [39/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'] (1, 10) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 378 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 386 []\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,818] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_62 =====\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.237 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_ = L_stack0_\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l_stack0_);  l_stack0_ = None\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_62 <eval_with_key>.237 opcode       name               target             args                     kwargs\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  -----------------  -----------------  -----------------------  --------\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_stack0_          L_stack0_          ()                       {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___softmax  L__self___softmax  (l_stack0_,)             {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output             output             ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_62 =====\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_: (1, 10)\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # probs = self.softmax(custom_logits)  # mp/ipykernel_414314/1905900009.py:45 in <resume in forward>\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # probs = self.softmax(custom_logits)  # mp/ipykernel_414314/1905900009.py:45 in <resume in forward>\n",
      "[2024-12-28 16:24:09,824] [39/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,824] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,826] [39/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 10], stride=[10, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 7\n",
      "Graph Break Count: 6\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 4:\n",
      "    Reason: call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "  Ops 7:\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 12:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 17:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 21:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 22:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 24:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 32:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 41:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55be520; to 'Tensor' at 0x7bf4c5563c50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 45:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 48:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 49:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 50:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 72:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3fb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 78:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 79:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55be520; to 'Tensor' at 0x7bf4c5563c50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b5cb80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 82:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 86:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 88:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c639eac0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 90:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 98:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 99:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c639eac0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 101:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 102:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 104:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3fb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b5cb80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 123:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 124:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 128:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6736930; to 'Tensor' at 0x7bf4c5175490>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 130:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 134:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 135:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 137:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 138:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 144:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 136291217694912)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b4467a10; to 'type' at 0x86f540 (function)>\n",
      "  Guard 151:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55df5b0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 153:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 154:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 155:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 161:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 162:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c514e9d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 163:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 164:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 165:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 166:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 167:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 168:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ------------------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.2056, 0.1625, 0.0845, 0.3021, 0.1022, 0.0381, 0.0155\n",
      "OutputGraph.call_user_compiler   0.0003, 0.0005, 0.0004, 0.0005, 0.0005, 0.0004, 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom op eager\n",
    "explanation_custom = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=scale_by_max_eager)\n",
    "print(explanation_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Capturing expected output for Graph break at `custom_forward_fn`\n",
    "\n",
    "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>], graph_break=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
