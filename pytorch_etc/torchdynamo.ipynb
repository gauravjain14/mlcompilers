{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Before we delve into trying to `jit` compile a pytorch module, it is important\n",
    "to understand what `Pytorch 2.0` brings with `torch.compile` and why `torch.jit.script`\n",
    "or `FX tracing` weren't good enough and what were the limitations.\n",
    "\n",
    "Refer to: https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html#comparison-to-torchscript-and-fx-tracing\n",
    "\n",
    "Essentially, scripting or tracing either error out or only capture the activated path in control\n",
    "flow instructions thus being erroneous or non-functional.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "We use `torch.dynamo` here to capture the graphs generated for the corresponding `nn.Module` and understand\n",
    "the number of `graph-breaks` in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/gaurav/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "access_token = os.environ[\"HF_ACCESS_TOKEN\"]\n",
    "login(token=access_token)\n",
    "\n",
    "os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"  # Dumps files in `torch_compile_debug/`\n",
    "\n",
    "# Choose which logs to enable\n",
    "# os.environ[\"TORCH_LOGS\"] = \"+dynamo,+aot_graphs,+inductor,+guards,+graph\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"+dynamo,guards,bytecode,graph_code\"\n",
    "os.environ[\"TORCH_LOGS\"] = \"+dynamo,graph_code\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch._dynamo import optimize\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First things first - \n",
    "\n",
    "The TorchDynamo deep-dive resource https://pytorch.org/docs/stable/torch.compiler_dynamo_deepdive.html#torch-compiler-dynamo-deepdive\n",
    "\n",
    "![TorchDynamo Guards](https://i.imgur.com/Pvq65gt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:21:29,599] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:29,600] [1/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,601] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,601] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 16:21:29,601] [1/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:29,602] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:29,602] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,602] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 16:21:29,602] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:29,603] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 16:21:29,603] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,603] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,603] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 16:21:29,603] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 16:21:29,604] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 16:21:29,605] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:16\n",
      "[2024-12-28 16:21:29,605] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 16:21:29,605] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 16:21:29,605] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,605] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:17\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return (n + 1) * y\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,606] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,607] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,607] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:21:29,607] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_414314/2999559549.py:17\n",
      "[2024-12-28 16:21:29,607] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 16:21:29,607] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~^~~\n",
      "[2024-12-28 16:21:29,608] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:29,608] [1/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 16:21:29,608] [1/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/2999559549.py, line 17 in fn>], graph_break=False)\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_3 =====\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.169 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:17, code: return (n + 1) * y\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = 3 * pow_1;  pow_1 = None\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul,)\n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,609] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_3 <eval_with_key>.169 opcode         name    target                   args        kwargs\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ----------  --------\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()          {}\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1   <built-in function pow>  (l_x_, 2)   {}\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (3, pow_1)  {}\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((mul,),)   {}\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_3 =====\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (200,)\n",
      "[2024-12-28 16:21:29,610] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:29,611] [1/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 16:21:29,629] [1/0] torch._inductor.debug: [WARNING] model__21_inference_57 debug trace: /tmp/torchinductor_gaurav/ey/ceyso437ujvadsmwtcpdjwqr5oibtz6v4tzy4jmeunspjeplpybs.debug\n",
      "[2024-12-28 16:21:29,631] [1/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 16:21:29,632] [1/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:29,633] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # if n >= 0:  # mp/ipykernel_414314/2999559549.py:16 in fn\n",
      "[2024-12-28 16:21:29,633] [1/0] torch._dynamo.guards.__guards: [DEBUG] L['n'] == 2                                                   # if n >= 0:  # mp/ipykernel_414314/2999559549.py:16 in fn\n",
      "[2024-12-28 16:21:29,633] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,634] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,635] [1/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,636] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,637] [1/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,637] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,639] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:29,641] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function fn in /tmp/ipykernel_414314/2999559549.py:13', 'set env var TORCHDYNAMO_REPORT_GUARD_FAILURES=1 to debug further')\n",
      "[2024-12-28 16:21:29,642] [1/1] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,643] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,643] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 16:21:29,643] [1/1] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:29,644] [1/1] torch._dynamo.variables.builder: [DEBUG] automatic dynamic int L['n'] val 3 != 2\n",
      "[2024-12-28 16:21:29,645] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:29,645] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,645] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 16:21:29,646] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:29,646] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 16:21:29,646] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,647] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,647] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 16:21:29,647] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 16:21:29,648] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 16:21:29,648] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:16\n",
      "[2024-12-28 16:21:29,648] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 16:21:29,648] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 16:21:29,649] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,649] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,650] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call ge from fn /tmp/ipykernel_414314/2999559549.py:16\n",
      "[2024-12-28 16:21:29,650] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]     if n >= 0:\n",
      "[2024-12-28 16:21:29,650] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^\n",
      "[2024-12-28 16:21:29,650] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,652] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:17\n",
      "[2024-12-28 16:21:29,652] [1/1] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return (n + 1) * y\n",
      "[2024-12-28 16:21:29,652] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 16:21:29,652] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,653] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,656] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from fn /tmp/ipykernel_414314/2999559549.py:17\n",
      "[2024-12-28 16:21:29,656] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 16:21:29,656] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~^~~\n",
      "[2024-12-28 16:21:29,657] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,657] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [SymNodeVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:29,657] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_414314/2999559549.py:17\n",
      "[2024-12-28 16:21:29,657] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]         return (n + 1) * y\n",
      "[2024-12-28 16:21:29,657] [1/1] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~^~~\n",
      "[2024-12-28 16:21:29,658] [1/1] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:29,659] [1/1] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 16:21:29,659] [1/1] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:29,659] [1/1] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/2999559549.py, line 17 in fn>], graph_break=False)\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_4 =====\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.177 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor, L_n_ : torch.SymInt):\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_n_ = L_n_\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:16, code: if n >= 0:\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         ge = l_n_ >= 0\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:17, code: return (n + 1) * y\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_n_ + 1;  l_n_ = None\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = add * pow_1;  add = pow_1 = None\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul,)\n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,661] [1/1] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_4 <eval_with_key>.177 opcode         name    target                   args          kwargs\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ------  -----------------------  ------------  --------\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_    L_x_                     ()            {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_n_    L_n_                     ()            {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1   <built-in function pow>  (l_x_, 2)     {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  ge      <built-in function ge>   (l_n_, 0)     {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add     <built-in function add>  (l_n_, 1)     {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul     <built-in function mul>  (add, pow_1)  {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] output         output  output                   ((mul,),)     {}\n",
      "[2024-12-28 16:21:29,662] [1/1] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_4 =====\n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (200,)\n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:29,663] [1/1] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 16:21:29,687] [1/1] torch._inductor.debug: [WARNING] model__22_inference_58 debug trace: /tmp/torchinductor_gaurav/zj/czjxff7ejgernmy4f3baz7dnktoajbccc4mqrcgjeny6kniat26o.debug\n",
      "[2024-12-28 16:21:29,690] [1/1] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 16:21:29,692] [1/1] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:29,692] [1/1] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,693] [1/1] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,693] [1/1] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,694] [1/1] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,695] [1/1] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,695] [1/1] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,696] [1/1] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,696] [1/1] torch._dynamo.guards.__guards: [DEBUG] L['n'] >= 0                                                   # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,698] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:29,698] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function fn in /tmp/ipykernel_414314/2999559549.py:13', 'set env var TORCHDYNAMO_REPORT_GUARD_FAILURES=1 to debug further')\n",
      "[2024-12-28 16:21:29,699] [1/2] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,699] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:13\n",
      "[2024-12-28 16:21:29,699] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile\n",
      "[2024-12-28 16:21:29,699] [1/2] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (200,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:29,700] [1/2] torch._dynamo.variables.builder: [DEBUG] automatic dynamic int L['n'] val -2 != None\n",
      "[2024-12-28 16:21:29,700] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         y = x ** 2\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 8 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from fn /tmp/ipykernel_414314/2999559549.py:15\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]     y = x ** 2\n",
      "[2024-12-28 16:21:29,701] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]         ~~^^~~\n",
      "[2024-12-28 16:21:29,702] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:16\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n >= 0:\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n []\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP >= [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call ge from fn /tmp/ipykernel_414314/2999559549.py:16\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]     if n >= 0:\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^\n",
      "[2024-12-28 16:21:29,703] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 40 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,704] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/2999559549.py:19\n",
      "[2024-12-28 16:21:29,704] [1/2] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return y / n\n",
      "[2024-12-28 16:21:29,704] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2024-12-28 16:21:29,704] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n [TensorVariable()]\n",
      "[2024-12-28 16:21:29,705] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), SymNodeVariable()]\n",
      "[2024-12-28 16:21:29,705] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from fn /tmp/ipykernel_414314/2999559549.py:19\n",
      "[2024-12-28 16:21:29,705] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]         return y / n\n",
      "[2024-12-28 16:21:29,705] [1/2] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~\n",
      "[2024-12-28 16:21:29,705] [1/2] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:29,706] [1/2] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 16:21:29,706] [1/2] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:29,706] [1/2] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/2999559549.py, line 19 in fn>], graph_break=False)\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_5 =====\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.185 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor, L_n_ : torch.SymInt):\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_n_ = L_n_\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:15, code: y = x ** 2\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = l_x_ ** 2;  l_x_ = None\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:16, code: if n >= 0:\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         ge = l_n_ >= 0\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2999559549.py:19, code: return y / n\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = pow_1 / l_n_;  pow_1 = l_n_ = None\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (truediv,)\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_5 <eval_with_key>.185 opcode         name     target                       args           kwargs\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------  ---------------------------  -------------  --------\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_     L_x_                         ()             {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_n_     L_n_                         ()             {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  pow_1    <built-in function pow>      (l_x_, 2)      {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  ge       <built-in function ge>       (l_n_, 0)      {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv  <built-in function truediv>  (pow_1, l_n_)  {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] output         output   output                       ((truediv,),)  {}\n",
      "[2024-12-28 16:21:29,707] [1/2] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_5 =====\n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (200,)\n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (200,)\n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (200,)\n",
      "[2024-12-28 16:21:29,708] [1/2] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:29,709] [1/2] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 16:21:29,727] [1/2] torch._inductor.debug: [WARNING] model__23_inference_59 debug trace: /tmp/torchinductor_gaurav/6o/c6oai42bsq4si3ohtop4mz5hghunk6krbrn2gprgcvcdk2yrty2q.debug\n",
      "[2024-12-28 16:21:29,729] [1/2] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 16:21:29,731] [1/2] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:29,731] [1/2] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['n'], 8837664)                             # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,732] [1/2] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,732] [1/2] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,733] [1/2] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,733] [1/2] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,734] [1/2] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,734] [1/2] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[200], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:29,735] [1/2] torch._dynamo.guards.__guards: [DEBUG] L['n'] < 0                                                    # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,736] [1/2] torch._dynamo.guards.__guards: [DEBUG] -9223372036854775808 <= L['n']                                # _dynamo/output_graph.py:339 in init_ambient_guards\n",
      "[2024-12-28 16:21:29,736] [1/2] torch._dynamo.guards.__guards: [DEBUG] -9223372036854775808 <= L['n']                                # _dynamo/output_graph.py:339 in init_ambient_guards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-6.6696e-01, -1.0884e-01, -3.6186e-02, -1.1740e+00, -9.0413e-01,\n",
       "        -5.6791e-01, -1.9477e-01, -3.4753e-01, -1.9683e-02, -1.7803e-01,\n",
       "        -3.9002e-01, -3.0301e-01, -1.3585e+00, -5.2352e-02, -2.9549e+00,\n",
       "        -1.2119e-02, -6.8487e-02, -1.2304e-01, -4.4547e-04, -2.8063e-02,\n",
       "        -1.9392e-01, -2.5780e-01, -4.5149e-01, -5.4279e-01, -2.1302e-01,\n",
       "        -1.2001e-01, -1.3565e-01, -3.5765e-02, -3.9820e-02, -1.5678e+00,\n",
       "        -1.0912e-01, -6.2852e-01, -3.2199e-01, -3.4568e-01, -4.8182e-01,\n",
       "        -1.0612e+00, -5.6914e-01, -6.5895e-03, -4.0533e-01, -5.1158e-01,\n",
       "        -1.7885e+00, -1.0898e-02, -4.7453e-01, -4.7165e-02, -1.4123e+00,\n",
       "        -3.1337e-02, -1.8508e+00, -2.6575e-02, -6.9351e-01, -6.3217e-03,\n",
       "        -3.2985e-02, -1.2599e-02, -7.2915e-02, -2.5334e-01, -8.3970e-02,\n",
       "        -2.8962e-01, -8.3909e-01, -5.3914e-02, -7.5858e-01, -2.8807e-02,\n",
       "        -9.1632e-05, -9.2425e-02, -9.5559e-02, -6.1646e-01, -5.6891e-01,\n",
       "        -2.3647e+00, -4.0835e-02, -2.0778e-01, -1.3151e-01, -5.8579e-01,\n",
       "        -2.9485e-01, -1.7142e+00, -5.9911e-01, -2.3771e+00, -2.8860e-03,\n",
       "        -8.5063e-02, -1.4557e-04, -1.6005e-01, -7.4211e-01, -2.0364e-01,\n",
       "        -7.8299e-01, -6.9639e-01, -9.5696e-02, -2.1677e+00, -6.0294e-02,\n",
       "        -5.9552e-04, -9.6883e-02, -1.5019e-02, -2.0420e-02, -7.0998e-01,\n",
       "        -2.0873e-01, -3.3536e-01, -1.2896e-01, -5.6890e-01, -1.6428e-02,\n",
       "        -5.1040e-01, -2.6354e-01, -1.4095e+00, -1.9641e+00, -1.6757e-02,\n",
       "        -4.4175e-02, -5.7224e-01, -2.0296e+00, -5.0866e-03, -9.0674e-01,\n",
       "        -4.8143e-02, -7.1391e-02, -1.6425e-04, -7.4822e-02, -4.3519e-02,\n",
       "        -4.6739e-02, -4.2120e-02, -2.8921e-01, -2.3493e-03, -1.4412e-01,\n",
       "        -8.8767e-01, -1.6159e+00, -1.8288e-01, -8.7991e-02, -2.1116e+00,\n",
       "        -2.5735e-02, -1.1996e+00, -2.5712e+00, -1.0337e-01, -6.3359e-01,\n",
       "        -1.6549e-01, -1.9956e-04, -5.0450e-01, -1.7789e+00, -5.8657e-02,\n",
       "        -1.9416e+00, -3.1407e-01, -7.0885e-01, -1.4393e+00, -2.7300e-02,\n",
       "        -7.0202e-01, -4.0205e-01, -7.6429e-01, -8.4080e-01, -8.7008e-01,\n",
       "        -8.8630e-01, -2.2253e+00, -1.9898e-01, -7.4024e-02, -2.0212e-01,\n",
       "        -4.2895e-02, -2.6150e-02, -1.2475e-01, -7.8382e-02, -2.4601e-01,\n",
       "        -6.9086e-01, -1.5510e+00, -8.2032e-02, -2.5209e-01, -3.9584e-02,\n",
       "        -2.1150e-04, -1.8465e-01, -3.7535e-01, -8.7970e-01, -1.1905e-01,\n",
       "        -6.2197e-03, -2.4045e-01, -4.2409e-01, -2.1459e+00, -5.7480e-02,\n",
       "        -1.3685e-01, -8.4393e-03, -2.4668e-01, -5.5564e-01, -5.6660e-01,\n",
       "        -1.5667e-02, -2.4869e-01, -2.3235e-01, -1.9943e+00, -6.1870e-01,\n",
       "        -4.4304e-03, -5.0522e-02, -6.7763e-01, -5.3856e-01, -5.5064e-01,\n",
       "        -7.1386e-01, -3.3846e+00, -3.6235e-01, -4.5742e-01, -2.7617e-01,\n",
       "        -2.2611e-01, -1.1648e+00, -2.7046e-01, -1.0718e+00, -4.8218e-01,\n",
       "        -1.5258e+00, -5.3286e-01, -2.9106e-03, -2.1634e+00, -2.2410e-01,\n",
       "        -5.0876e-01, -4.4486e-01, -6.6165e-02, -3.8327e-02, -9.4963e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Set the environment variable\n",
    "# os.environ[\"TORCHDYNAMO_REPORT_GUARD_FAILURES\"] = \"1\"\n",
    "\n",
    "# The other interesting thing to note here is that Dynamo removed the second argument to the function. \n",
    "# Instead, it treated it as a constant and recorded the result of the operation n + 1 in the graph. \n",
    "# This is another feature of Dynamo: Dynamo will treat as constant any non-tensor value… other than ints.\n",
    "\n",
    "# The last defining property of Dynamo is that it knows how to handle dynamic shapes. Symbolic shapes refer to \n",
    "# Dynamo’s ability of tracing shapes, and more generally, integers, rather than leaving them as constants. \n",
    "# This allows for avoiding recompilations and deploying generic models that work for any size in production.\n",
    "\n",
    "@torch.compile\n",
    "def fn(x, n):\n",
    "    y = x ** 2\n",
    "    if n >= 0:\n",
    "        return (n + 1) * y\n",
    "    else:\n",
    "        return y / n\n",
    "\n",
    "x = torch.randn(200)\n",
    "fn(x, 2)\n",
    "fn(x, 3)\n",
    "fn(x, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:412: UserWarning: changing options to `torch.compile()` may require calling `torch._dynamo.reset()` to take effect\n",
      "  warnings.warn(\n",
      "[2024-12-28 16:21:32,072] torch._dynamo.eval_frame: [DEBUG] skipping patch /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 16:21:32,072] torch._dynamo.eval_frame: [DEBUG] skipping ConfigPatch /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 16:21:32,073] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/config_utils.py\n",
      "[2024-12-28 16:21:32,073] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:32,074] [2/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn /tmp/ipykernel_414314/1791670339.py:3\n",
      "[2024-12-28 16:21:32,074] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/1791670339.py:3\n",
      "[2024-12-28 16:21:32,074] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     @torch.compile(dynamic=True)\n",
      "[2024-12-28 16:21:32,075] [2/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['a'] (8,) [<DimDynamic.DUCK: 1>] [None]\n",
      "[2024-12-28 16:21:32,080] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:32,081] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/1791670339.py:5\n",
      "[2024-12-28 16:21:32,081] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 16:21:32,081] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2024-12-28 16:21:32,081] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:21:32,082] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call size from fn /tmp/ipykernel_414314/1791670339.py:5\n",
      "[2024-12-28 16:21:32,082] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 16:21:32,082] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^^\n",
      "[2024-12-28 16:21:32,083] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [SizeVariable()]\n",
      "[2024-12-28 16:21:32,083] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:32,084] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:32,084] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:32,084] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from fn /tmp/ipykernel_414314/1791670339.py:5\n",
      "[2024-12-28 16:21:32,084] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 16:21:32,084] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ~~~~~~~~~~~^~~\n",
      "[2024-12-28 16:21:32,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 16 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:32,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP < [SymNodeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:32,086] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call lt from fn /tmp/ipykernel_414314/1791670339.py:5\n",
      "[2024-12-28 16:21:32,086] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 16:21:32,086] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]        ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:32,088] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 46 [SymNodeVariable()]\n",
      "[2024-12-28 16:21:32,091] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line fn /tmp/ipykernel_414314/1791670339.py:8\n",
      "[2024-12-28 16:21:32,091] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return a + 1\n",
      "[2024-12-28 16:21:32,091] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2024-12-28 16:21:32,092] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2024-12-28 16:21:32,092] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:32,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from fn /tmp/ipykernel_414314/1791670339.py:8\n",
      "[2024-12-28 16:21:32,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return a + 1\n",
      "[2024-12-28 16:21:32,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~\n",
      "[2024-12-28 16:21:32,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:32,095] [2/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2024-12-28 16:21:32,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:32,095] [2/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1791670339.py, line 8 in fn>], graph_break=False)\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_6 =====\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.193 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, s0 : torch.SymInt, L_a_ : torch.Tensor):\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_a_ = L_a_\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1791670339.py:5, code: if a.shape[0] * 2 < 16:\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         size = l_a_.size()\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = size[0];  size = None\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = getitem * 2;  getitem = None\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         lt = mul < 16;  mul = None\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1791670339.py:8, code: return a + 1\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_a_ + 1;  l_a_ = None\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add,)\n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:32,096] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_6 <eval_with_key>.193 opcode         name     target                       args          kwargs\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------  ---------------------------  ------------  --------\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    s0       s0                           ()            {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_a_     L_a_                         ()            {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    size     size                         (l_a_,)       {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem  <built-in function getitem>  (size, 0)     {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul      <built-in function mul>      (getitem, 2)  {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  lt       <built-in function lt>       (mul, 16)     {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add      <built-in function add>      (l_a_, 1)     {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output   output                       ((add,),)     {}\n",
      "[2024-12-28 16:21:32,097] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_6 =====\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_a_: (s0,)\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_a_ (concrete): (8,)\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (s0,)\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add (concrete): (8,)\n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:32,098] [2/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2024-12-28 16:21:32,121] [2/0] torch._inductor.debug: [WARNING] model__24_inference_60 debug trace: /tmp/torchinductor_gaurav/fa/cfalodpsums5vhxbcetidoq4q2z4loklyqys5glcdrgqa3vclbts.debug\n",
      "[2024-12-28 16:21:32,123] [2/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2024-12-28 16:21:32,125] [2/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:32,125] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['a'], 117923504)                           # if a.shape[0] * 2 < 16:  # mp/ipykernel_414314/1791670339.py:5 in fn\n",
      "[2024-12-28 16:21:32,126] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['a'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:32,126] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:32,127] [2/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:32,127] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:32,128] [2/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:32,128] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['a'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[None], stride=[1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:32,128] [2/0] torch._dynamo.guards.__guards: [DEBUG] 2*L['a'].size()[0] >= 16                                      # _dynamo/output_graph.py:339 in init_ambient_guards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  0.4921, -1.7825,  0.2682, -0.6509,  0.4737,  0.8816, -0.9086])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.compile(dynamic=True)\n",
    "def fn(a):\n",
    "    if a.shape[0] * 2 < 16:\n",
    "        return a\n",
    "    else:\n",
    "        return a + 1\n",
    "\n",
    "fn(torch.randn(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LLaMAFirstLayerModel(nn.Module):\n",
    "    def __init__(self, llama_model_name: str, output_dim: int):\n",
    "        super(LLaMAFirstLayerModel, self).__init__()\n",
    "\n",
    "        # Load the LLaMA model\n",
    "        full_llama = AutoModel.from_pretrained(llama_model_name)\n",
    "\n",
    "        # Extract and store the embedding layer\n",
    "        self.embed_tokens = full_llama.embed_tokens\n",
    "\n",
    "        # Extract and store the first decoder layer\n",
    "        self.first_layer = full_llama.layers[0]\n",
    "\n",
    "        # Linear layer to map to output dimensions\n",
    "        llama_hidden_dim = full_llama.config.hidden_size\n",
    "        self.linear = nn.Linear(llama_hidden_dim, output_dim)\n",
    "\n",
    "        # Softmax for output probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Explicit typing of input_ids and attention_mask for TorchScript\n",
    "    def forward(self, input_ids):\n",
    "        # Generate embeddings\n",
    "        embeddings = self.embed_tokens(input_ids)\n",
    "\n",
    "        # Check if position_ids need to be explicitly handled\n",
    "        position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Pass through the first layer with position_ids\n",
    "        layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
    "\n",
    "        # Pool the output (mean along sequence dimension)\n",
    "        pooled_output = torch.mean(layer_output, dim=1)\n",
    "\n",
    "        # Map to output dimension\n",
    "        logits = self.linear(pooled_output)\n",
    "\n",
    "        # Apply softmax\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # Replace with actual model name\n",
    "output_dim = 10  # Number of classes for classification\n",
    "\n",
    "# Initialize the model\n",
    "model = LLaMAFirstLayerModel(llama_model_name, output_dim).to(\"cuda\")\n",
    "\n",
    "# Example tokenizer and input\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "example_text = [\"This is an example input.\"]\n",
    "inputs = tokenizer(example_text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:694: UserWarning: explain(f, *args, **kwargs) is deprecated, use explain(f)(*args, **kwargs) instead.  If you don't migrate, we may break your explain call in the future if your user defined kwargs conflict with future kwargs added to explain(f).\n",
      "  warnings.warn(\n",
      "[2024-12-28 16:21:37,925] torch._dynamo.eval_frame: [DEBUG] skipping _wrapped_call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 16:21:37,925] torch._dynamo.eval_frame: [DEBUG] skipping _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 16:21:37,926] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:37,927] [3/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/343866.py:26\n",
      "[2024-12-28 16:21:37,927] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:26\n",
      "[2024-12-28 16:21:37,927] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-28 16:21:37,928] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:37,929] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:37,929] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:28\n",
      "[2024-12-28 16:21:37,929] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:37,930] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,930] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,930] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,930] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,931] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,931] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/343866.py:28\n",
      "[2024-12-28 16:21:37,931] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:37,931] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:21:37,934] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:21:37,934] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:37,934] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:37,934] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:37,935] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:37,936] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:37,936] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,936] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:21:37,937] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:37,937] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,937] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,938] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,938] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:21:37,938] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:37,939] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:37,939] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:37,948] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:37,948] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:37,948] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:37,950] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:37,951] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:37,951] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,951] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:37,952] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:37,952] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:37,952] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:37,953] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:21:37,954] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:37,954] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:37,954] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,954] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,955] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,955] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,956] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,956] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,956] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,957] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:37,957] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:37,957] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:37,957] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:37,960] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,960] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:37,961] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:37,961] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,961] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:37,961] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:37,961] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:37,962] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:37,962] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:37,962] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:37,963] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:37,963] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,963] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,963] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,964] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,965] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,965] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,965] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,965] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,965] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,966] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,967] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,968] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,969] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:37,970] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:37,970] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:37,970] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:37,970] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:37,970] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,971] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,971] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,972] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:37,972] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:37,972] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:37,972] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:21:37,973] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:21:37,973] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:37,973] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:21:37,974] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:37,975] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,975] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,975] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,975] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,976] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:37,976] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:21:37,976] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:37,976] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:37,976] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:37,979] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:21:37,979] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:37,979] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:37,980] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:21:37,980] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:37,980] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:37,980] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:37,981] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:37,981] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:37,982] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:37,982] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:37,982] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,983] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,983] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:37,983] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:37,983] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:37,984] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,984] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,985] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,985] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,986] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,986] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,986] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,986] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:37,987] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:37,987] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:37,987] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,107] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,108] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,108] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,108] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,108] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,108] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,109] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,110] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,111] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,112] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:38,112] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,112] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,112] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,113] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,113] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,113] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,113] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,114] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,114] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:38,114] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,114] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,114] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:38,115] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,115] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:38,116] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,116] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,116] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,116] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,117] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:38,118] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,118] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,119] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,120] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,120] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,120] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,120] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,121] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,121] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,121] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,121] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,122] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:38,122] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:38,123] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,123] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,124] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,124] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,124] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,125] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:38,125] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:38,126] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,126] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,127] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,127] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,128] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,128] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,128] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,129] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:38,130] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,130] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,130] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,130] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:38,131] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,132] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,132] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,133] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,133] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,134] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,134] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,134] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,136] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,136] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,138] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,138] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,138] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,140] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,141] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,141] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,141] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,142] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,142] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,142] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,143] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,143] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,144] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:38,145] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,146] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,146] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,147] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,147] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,148] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,148] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,148] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,149] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,149] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,149] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,149] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,151] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,152] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,153] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,153] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,154] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,154] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,154] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,155] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,155] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:21:38,155] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,156] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,156] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,156] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,157] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,158] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,159] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:21:38,160] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,160] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,160] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:38,161] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,161] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,161] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,161] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,161] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,162] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:21:38,163] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,166] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,166] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,166] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,167] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,167] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,167] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,167] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,167] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,168] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,168] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,168] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,169] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,169] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,169] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,170] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,170] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,170] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,170] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,170] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,171] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,171] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,171] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,172] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,172] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,172] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,173] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,173] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,173] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,174] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,175] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,176] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,177] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,178] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,178] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:38,178] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,178] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,178] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,180] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,180] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,180] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,181] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:38,182] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,182] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:38,182] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:38,183] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:38,183] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:38,183] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:38,183] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:38,184] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:38,184] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,184] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,184] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:38,184] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:38,185] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:38,186] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,186] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,186] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:38,187] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,188] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,188] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,189] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,189] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:38,189] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,189] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,190] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:38,191] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,191] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,191] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,192] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,192] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,192] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,192] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,193] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,195] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,195] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,195] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,197] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,198] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,198] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,198] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,198] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,199] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,199] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,200] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,200] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,200] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,200] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,203] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,203] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,204] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,204] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,205] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,205] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,206] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,206] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,206] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,206] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,208] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,208] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:38,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,211] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,211] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,212] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,212] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,213] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,213] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,213] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,213] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,214] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,214] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,215] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,215] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,215] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,216] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,217] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,217] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,217] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:38,217] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,218] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,219] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,220] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,220] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,221] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,222] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,226] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,227] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,228] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,228] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,229] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,229] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,229] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,229] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,230] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,231] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,231] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:38,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,236] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,237] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,237] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,238] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,238] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,240] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,240] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,240] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,240] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,242] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,243] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,244] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,244] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,244] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,245] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,245] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,245] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,246] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,246] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,246] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:38,247] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:38,247] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,247] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,248] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,248] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,248] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,248] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:38,249] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:38,250] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,250] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:38,251] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:38,251] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:21:38,251] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,251] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,252] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,252] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,253] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:38,254] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:38,254] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,254] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,254] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,255] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,255] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:21:38,255] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:38,255] [3/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,255] [3/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,256] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,256] [3/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:38,258] [3/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,258] [3/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_7 =====\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.201 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,259] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_7 <eval_with_key>.201 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:21:38,260] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_7 =====\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:38,261] [3/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,263] [3/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,266] [3/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:38,266] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291338011728)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/343866.py:28 in forward\n",
      "[2024-12-28 16:21:38,266] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/343866.py:28 in forward\n",
      "[2024-12-28 16:21:38,267] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/343866.py:31 in forward\n",
      "[2024-12-28 16:21:38,267] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,267] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,268] [3/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,268] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,269] [3/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,269] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,295] torch._dynamo.eval_frame: [DEBUG] skipping __getattr__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-28 16:21:38,296] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,297] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:21:38,298] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:21:38,298] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:38,298] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:38,300] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:38,301] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,301] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:21:38,301] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:38,302] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,302] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:38,302] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:21:38,302] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:38,303] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,303] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,304] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,304] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,304] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,305] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:21:38,305] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:38,305] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,305] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,308] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,308] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,309] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,309] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,309] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,309] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,309] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,310] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,310] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,310] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,311] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,311] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,311] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,311] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,312] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,312] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,312] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,312] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,313] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,313] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,313] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,314] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,314] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,314] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,315] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,315] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,315] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,316] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,317] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,317] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,317] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,318] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,319] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,320] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,320] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,320] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,320] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,320] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:38,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,322] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,322] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,322] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,322] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,322] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,323] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:38,324] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,325] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:38,326] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,326] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,326] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,326] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,326] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:38,327] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,327] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,327] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,327] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,328] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,329] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,329] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:38,329] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:38,329] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,329] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,330] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,330] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,330] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,331] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:38,331] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:38,331] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,331] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,331] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,332] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,332] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,332] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,332] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,333] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,334] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,334] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,334] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,335] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,335] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,335] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,336] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,336] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,336] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,336] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,336] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,337] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,338] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,338] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,338] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,338] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,339] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,339] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,339] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,339] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,339] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:38,340] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,340] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,342] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,342] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,342] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,342] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,344] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,344] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,344] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,344] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:21:38,344] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:21:38,345] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:21:38,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,348] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:21:38,349] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:21:38,350] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,353] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,354] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,354] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,354] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,355] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,356] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,356] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,356] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,356] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,357] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,357] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,357] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,357] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,358] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,360] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:38,362] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,362] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,362] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,363] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,363] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,363] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,363] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:38,365] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,365] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:38,365] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:38,365] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:38,365] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:38,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:38,367] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,367] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,367] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:38,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,369] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,369] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:38,369] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,369] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,370] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,370] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,370] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,370] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,370] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,371] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,375] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,375] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,375] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,376] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,376] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,376] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,376] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,377] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,377] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,377] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,377] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,380] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,380] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,380] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,380] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,380] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,381] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,385] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,385] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,385] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,385] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:38,386] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,386] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,386] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,386] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,387] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,387] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,387] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,388] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,388] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,388] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,388] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,388] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,389] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,390] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,390] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,390] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,391] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,391] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,391] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,391] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,392] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,392] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,392] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,392] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:38,392] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,393] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,393] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,393] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,393] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,393] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,394] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,394] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,394] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,395] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,395] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,395] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,396] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,396] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,397] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,398] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,398] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,398] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,398] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:38,399] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,399] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,399] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,399] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,400] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,400] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,400] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,401] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,401] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,401] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,401] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,401] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,402] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,403] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,403] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,403] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,403] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,404] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,404] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,404] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,405] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,405] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,405] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:38,405] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,406] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:38,407] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:38,407] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,407] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:38,409] [4/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:38,409] [4/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:38,409] [4/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,409] [4/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,409] [4/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:38,411] [4/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,411] [4/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_9 =====\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.202 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,413] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_9 <eval_with_key>.202 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:21:38,414] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_9 =====\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:38,415] [4/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,416] [4/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,421] [4/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:38,422] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240560848)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,423] [4/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,426] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:38,427] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:38,427] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,432] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,432] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:21:38,433] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,434] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,435] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,435] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,436] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,438] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:38,439] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,440] [4/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,440] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,440] [4/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,441] [4/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:21:38,441] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,442] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,442] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,443] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,443] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,444] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,444] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,445] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,445] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,445] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,478] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,480] [5/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:21:38,481] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:21:38,481] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:38,482] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:38,483] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:38,484] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:38,485] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:38,485] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:38,485] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:38,485] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:38,485] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:38,486] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,486] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:21:38,486] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:38,486] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:38,486] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:38,487] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,487] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,487] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:38,488] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,489] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,490] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:38,490] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,490] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,492] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,492] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:21:38,492] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,492] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,492] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,493] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,493] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,493] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,494] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:21:38,494] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,494] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,496] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,497] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:21:38,497] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,497] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,497] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,498] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,498] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,498] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,499] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:21:38,499] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,499] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,501] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,502] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:21:38,502] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,502] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,502] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,503] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,503] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,504] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,504] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:21:38,504] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,504] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,507] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,507] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:38,507] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,507] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:38,508] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,508] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,508] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,509] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,509] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,510] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,510] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,510] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,511] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,511] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:38,511] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,511] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,512] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,513] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,513] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,513] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,514] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,514] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:38,514] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,514] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,515] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,515] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:38,515] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,515] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:38,516] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,516] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,516] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,516] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,516] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,517] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,517] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,517] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,518] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,518] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:38,518] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,518] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,519] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,519] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,520] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,521] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,521] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:38,521] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,522] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,523] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,523] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,523] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,523] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,524] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:38,524] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,524] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,525] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,525] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,526] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,527] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,527] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:21:38,527] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:38,528] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,529] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:38,529] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,530] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,531] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,531] [5/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:38,532] [5/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:38,532] [5/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:38,533] [5/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_11 =====\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.203 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,534] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_11 <eval_with_key>.203 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:21:38,535] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_11 =====\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,536] [5/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,548] [5/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:38,548] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240568144)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:21:38,549] [5/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:21:38,549] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:38,549] [5/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:38,550] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,550] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,550] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:21:38,551] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,551] [5/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,552] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,552] [5/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,553] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:21:38,553] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,554] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,573] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,573] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* warning_once             /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/utils/logging.py 319\n",
      "[2024-12-28 16:21:38,574] torch._dynamo.eval_frame: [DEBUG] skipping warning /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,574] torch._dynamo.eval_frame: [DEBUG] skipping isEnabledFor /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,574] torch._dynamo.eval_frame: [DEBUG] skipping _acquireLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,574] torch._dynamo.eval_frame: [DEBUG] skipping disable /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping getEffectiveLevel /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping _releaseLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping _log /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping findCaller /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping <lambda> /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._dynamo.eval_frame: [DEBUG] skipping _is_internal_frame /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,575] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,576] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* normcase             <frozen posixpath> 52\n",
      "[2024-12-28 16:21:38,576] torch._dynamo.eval_frame: [DEBUG] skipping makeRecord /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,576] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,576] torch._dynamo.eval_frame: [DEBUG] skipping getLevelName /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,577] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,577] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* basename             <frozen posixpath> 140\n",
      "[2024-12-28 16:21:38,577] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,577] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _get_sep             <frozen posixpath> 41\n",
      "[2024-12-28 16:21:38,578] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,578] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* splitext             <frozen posixpath> 117\n",
      "[2024-12-28 16:21:38,578] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,578] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _splitext             <frozen genericpath> 121\n",
      "[2024-12-28 16:21:38,578] torch._dynamo.eval_frame: [DEBUG] skipping current_thread /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping current_process /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping filter /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping callHandlers /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,579] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping acquire /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping emit /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping getMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,580] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,581] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,581] torch._dynamo.eval_frame: [DEBUG] skipping formatMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,581] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,581] torch._dynamo.eval_frame: [DEBUG] skipping _format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,581] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,582] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* write             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 624\n",
      "[2024-12-28 16:21:38,582] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,582] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _is_master_process             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 519\n",
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "[2024-12-28 16:21:38,582] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,582] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _schedule_flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 546\n",
      "[2024-12-28 16:21:38,583] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,583] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* schedule             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 258\n",
      "[2024-12-28 16:21:38,583] torch._dynamo.eval_frame: [DEBUG] skipping is_alive /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,583] torch._dynamo.eval_frame: [DEBUG] skipping is_set /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,583] torch._dynamo.eval_frame: [DEBUG] skipping _wait_for_tstate_lock /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,583] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,584] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _event_pipe             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 137\n",
      "[2024-12-28 16:21:38,584] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,584] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* send             /home/gaurav/anaconda3/lib/python3.11/site-packages/zmq/sugar/socket.py 621\n",
      "[2024-12-28 16:21:38,584] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,584] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 561\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping ident /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping wait /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,585] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-28 16:21:38,586] torch._dynamo.eval_frame: [DEBUG] skipping release /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-28 16:21:38,586] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,588] [6/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:38,588] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:38,588] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:38,589] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:38,590] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:38,591] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:38,593] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:38,594] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:38,595] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:21:38,595] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,596] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,597] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,597] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,597] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,597] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,598] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:21:38,598] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:21:38,598] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,598] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,602] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,603] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,603] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,604] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,604] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,604] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,604] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,604] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,605] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,605] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,605] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,605] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,605] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,606] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,606] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,606] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,606] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,607] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,608] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,609] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,610] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,611] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,612] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,612] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,612] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,612] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:21:38,613] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,614] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,615] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,616] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,616] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,616] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,616] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,616] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:21:38,617] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,617] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:21:38,617] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,618] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,618] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:21:38,618] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:21:38,618] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,618] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,619] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,619] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,619] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,619] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:38,620] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,620] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,621] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:38,621] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,622] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,622] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,622] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,622] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:38,622] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,623] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,623] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,623] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:38,623] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,624] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:21:38,625] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,625] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,626] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,626] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:38,626] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:38,626] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:38,626] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:38,627] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:21:38,628] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:21:38,628] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,629] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,629] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,629] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,629] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,630] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,630] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:38,630] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,631] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:21:38,631] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,631] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:38,631] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:21:38,631] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,632] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,632] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,632] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,632] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,633] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,633] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,633] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:38,633] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,634] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,634] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:38,634] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,635] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:21:38,636] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,636] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,637] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,637] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:38,637] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:38,638] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:21:38,639] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,639] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:21:38,639] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:38,639] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:21:38,640] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:38,640] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,641] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,641] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:21:38,641] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:21:38,642] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:21:38,642] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,642] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:21:38,642] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:21:38,643] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,643] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:21:38,643] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,643] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,644] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:21:38,645] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,645] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,646] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:21:38,646] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:38,646] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,646] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,646] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,647] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:21:38,647] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:21:38,647] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,647] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,648] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,648] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,648] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,649] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,649] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,649] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,649] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:38,650] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,650] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,650] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,651] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:38,651] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,651] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,651] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:38,652] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,652] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,652] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,652] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,655] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,655] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,656] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,657] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,657] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,657] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:38,658] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,658] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,659] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,659] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,659] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,659] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:38,659] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,660] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,660] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,660] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,660] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:38,660] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,661] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,662] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,662] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:21:38,662] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,662] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,663] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:21:38,663] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:21:38,663] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,663] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:21:38,663] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:21:38,664] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,665] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,665] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:21:38,665] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,665] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,666] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:21:38,666] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:21:38,666] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,666] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:21:38,666] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:21:38,667] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,667] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,667] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:21:38,668] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,668] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,668] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,669] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:38,670] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:38,670] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:21:38,670] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,670] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,671] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,671] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:38,671] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:21:38,673] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,674] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,674] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,674] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:38,674] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,675] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:38,675] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,675] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:38,676] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:38,676] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:38,676] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,676] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:38,677] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,678] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:38,679] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,679] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,679] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:38,680] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,680] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,680] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,681] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:38,681] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:38,681] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,681] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,681] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,682] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,683] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,683] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,683] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,683] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:38,683] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:21:38,684] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:38,684] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,684] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:21:38,684] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,684] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,685] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:21:38,686] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,687] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,688] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:38,688] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:38,688] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:38,688] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,688] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,689] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,689] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,689] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,689] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:38,690] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,690] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,690] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:21:38,690] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,691] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,692] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:38,692] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,692] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,692] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:21:38,693] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:38,693] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,693] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,693] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,693] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,694] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,695] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:38,696] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:38,696] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:38,696] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,696] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:38,697] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:21:38,697] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,700] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,700] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,701] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,701] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:38,701] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,702] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,702] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,702] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,704] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:21:38,704] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,704] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,705] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:38,705] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:38,705] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:38,706] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:21:38,707] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:21:38,707] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,708] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,708] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,708] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,708] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,709] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:38,709] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,709] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,709] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,709] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,711] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:21:38,712] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,712] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,712] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,712] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,713] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,713] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,713] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,713] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,713] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:21:38,715] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,715] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,716] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:38,716] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,716] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,716] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,717] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,717] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,717] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,720] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,720] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:38,721] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,721] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,721] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,721] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,721] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:21:38,722] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,723] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,723] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,723] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,724] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:38,724] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,724] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,724] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:21:38,725] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:38,725] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,725] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,725] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,725] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:21:38,726] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:21:38,726] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,727] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,728] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:38,729] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:38,729] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:38,729] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,729] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:38,730] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:21:38,731] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,731] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,731] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,732] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,732] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:38,732] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,733] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,733] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,733] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,735] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:21:38,735] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,735] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,736] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:38,736] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:38,736] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:38,737] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:21:38,738] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:21:38,738] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,738] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,739] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,739] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,739] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,739] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:38,739] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,740] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,740] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,740] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,741] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:21:38,741] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,741] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,741] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,742] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,742] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,742] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,743] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,743] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,743] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:21:38,743] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,744] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,744] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:38,744] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,744] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,744] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,745] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,745] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,745] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,746] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,746] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:38,746] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,746] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,747] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,747] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,747] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:21:38,747] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,748] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:21:38,749] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,750] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,751] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,751] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:21:38,751] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:38,751] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:21:38,751] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,752] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,752] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,752] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,753] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,753] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:21:38,753] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:38,753] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,753] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,754] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:21:38,755] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,756] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,757] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,757] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,757] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,757] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,757] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,758] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,758] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,758] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,758] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,758] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,759] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:38,759] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,759] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,759] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,759] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,760] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,760] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,760] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,761] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:38,762] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:38,762] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,762] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,762] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,762] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,763] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,763] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,763] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,763] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,763] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:38,764] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,765] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,766] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,766] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,766] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:38,767] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:21:38,768] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:38,768] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,768] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,768] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,769] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,769] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:21:38,769] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:38,769] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,769] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,770] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,772] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,773] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,774] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,775] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,775] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,775] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,775] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,775] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:38,776] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,776] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,776] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:38,776] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,777] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,777] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,777] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,778] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,779] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,780] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,780] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,780] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,780] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:38,781] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,782] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,783] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,783] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,783] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:38,784] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,785] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,785] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,785] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,785] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,786] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,786] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,786] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,786] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,787] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:38,787] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:38,787] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,788] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,788] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,788] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:38,788] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:38,788] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,790] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:21:38,790] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,790] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:21:38,791] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,791] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,791] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,791] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,792] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:38,792] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:38,792] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,792] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:38,793] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:21:38,793] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:21:38,793] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:21:38,793] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,793] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,794] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,794] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:38,794] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:38,794] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:21:38,794] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,795] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:21:38,795] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:21:38,795] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,796] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,796] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,796] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,797] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,799] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,799] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:38,799] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:38,799] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,802] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:38,802] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,802] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:38,803] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,803] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,803] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:38,803] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:38,803] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,804] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:38,804] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:21:38,804] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:38,804] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:21:38,804] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,805] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:21:38,805] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:21:38,805] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,806] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,806] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,806] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,806] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,807] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,807] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,807] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:21:38,807] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:38,807] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,808] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:38,808] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:21:38,808] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:38,808] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,809] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,809] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,809] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,809] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,809] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,810] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:21:38,810] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:38,810] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,811] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:38,811] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:21:38,811] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:21:38,812] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:38,812] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:38,812] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,812] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:38,813] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:21:38,813] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,813] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,813] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,814] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,814] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,814] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,814] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:38,814] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,815] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:38,815] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:38,815] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:38,815] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:38,815] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:38,816] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:38,817] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:21:38,817] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:21:38,817] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:21:38,818] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:38,818] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:38,818] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:38,818] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:38,819] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:21:38,819] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:38,819] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:38,819] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:38,819] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:38,820] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,821] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:38,822] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:21:38,822] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:38,822] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,822] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,822] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,823] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:38,824] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,826] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:38,826] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:21:38,826] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:21:38,826] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:21:38,826] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,827] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,828] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:38,828] [6/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:38,828] [6/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:38,828] [6/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:38,829] [6/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_13 =====\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.204 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:38,831] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_13 <eval_with_key>.204 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:21:38,833] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_13 =====\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:38,837] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:38,838] [6/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,838] [6/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:38,842] [6/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:38,842] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:38,843] [6/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:38,843] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240568144)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,843] [6/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,844] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:38,844] [6/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:38,844] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:21:38,845] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,845] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:21:38,846] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,846] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:21:38,847] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,847] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:21:38,847] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,848] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,848] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:21:38,849] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:21:38,849] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:21:38,850] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,850] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:21:38,851] [6/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,851] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,851] [6/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:38,851] [6/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:21:38,852] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:21:38,852] [6/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:21:38,853] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,853] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,854] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,854] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,854] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,855] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,855] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,855] [6/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:38,855] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,856] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,856] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,857] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,857] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:38,894] torch._dynamo.eval_frame: [DEBUG] skipping __call__ /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-28 16:21:38,894] torch._dynamo.eval_frame: [DEBUG] skipping del_ten /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py\n",
      "[2024-12-28 16:21:38,895] torch._dynamo.eval_frame: [DEBUG] skipping pop /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-28 16:21:38,895] torch._dynamo.eval_frame: [DEBUG] skipping __hash__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/weak.py\n",
      "[2024-12-28 16:21:38,895] torch._dynamo.eval_frame: [DEBUG] skipping expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\n",
      "[2024-12-28 16:21:38,895] torch._dynamo.eval_frame: [DEBUG] skipping _expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/storage.py\n",
      "[2024-12-28 16:21:38,900] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:38,901] [7/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,901] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:38,901] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:38,902] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:38,907] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:38,910] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,911] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:38,911] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:21:38,911] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:38,912] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:21:38,913] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,913] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,913] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:21:38,913] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:38,913] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,914] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,914] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:21:38,914] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,915] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,916] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,916] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,917] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,918] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:21:38,918] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:38,918] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,918] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,921] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,922] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,922] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,922] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,922] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,923] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,924] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,924] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,924] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,924] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,925] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,925] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,925] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,925] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,925] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,926] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,926] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,926] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,926] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,927] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,927] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,927] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,928] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,929] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,929] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,929] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,929] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,929] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,930] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,931] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,931] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,931] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,932] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,933] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:38,933] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,933] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,933] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,934] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,934] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,934] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,934] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:38,935] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,936] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:38,936] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,936] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,936] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,937] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,937] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:38,938] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,938] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,939] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,939] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:38,939] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,939] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:38,939] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,940] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,940] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,940] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,940] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,940] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,941] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,943] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:38,943] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:38,943] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,943] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,944] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,944] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,944] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,944] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:38,944] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,945] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,946] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,947] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,948] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,948] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:38,949] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,949] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,949] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,950] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,950] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,950] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:38,950] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,951] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,951] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,951] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,952] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,952] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,952] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:38,953] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,954] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,954] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:38,954] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,955] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:38,955] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,955] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,955] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,955] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,956] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,956] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:38,956] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,957] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,957] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:38,957] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,957] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,958] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:38,958] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:21:38,958] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:21:38,958] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,958] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:21:38,959] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,960] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:38,964] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,964] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:38,964] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,965] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,965] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:38,965] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:38,965] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:38,966] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:38,966] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,966] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:38,967] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:38,967] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,967] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,967] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,968] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,968] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,968] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,968] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,968] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,969] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,969] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,969] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,970] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,970] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,970] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,970] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,971] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,971] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,971] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,971] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,972] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:38,973] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:38,973] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,973] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,973] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:38,974] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:38,975] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:38,976] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:38,976] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:38,976] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,976] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,976] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,977] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,978] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:38,979] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,979] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,979] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:38,979] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,979] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,980] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,981] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,981] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,981] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,981] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,981] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,982] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,982] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,982] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,982] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,985] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,986] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,986] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,986] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,986] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,989] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,989] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,990] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:38,994] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,994] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,994] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,994] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:38,995] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,995] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:38,995] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,995] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:38,995] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:21:38,999] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:39,000] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:39,000] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:39,000] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:21:39,000] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:39,001] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:39,002] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:39,002] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:21:39,002] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:21:39,002] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:39,003] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:21:39,003] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:21:39,003] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:21:39,003] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:21:39,003] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:21:39,004] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:21:39,005] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:21:39,006] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:39,006] [7/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:39,007] [7/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:39,007] [7/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_14 =====\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.205 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,008] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_14 <eval_with_key>.205 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:21:39,009] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_14 =====\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:39,011] [7/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:39,013] [7/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:39,014] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240560848)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,014] [7/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,014] [7/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:39,015] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:39,015] [7/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:39,015] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:21:39,016] [7/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:39,016] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:21:39,016] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:21:39,016] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:21:39,017] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,017] [7/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,017] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,019] [7/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,019] [7/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:21:39,019] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,020] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,020] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,021] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,021] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,021] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,022] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,022] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:39,023] [7/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:39,023] [7/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:39,029] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:39,030] [8/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:39,030] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:39,030] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:39,031] [8/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:39,032] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:39,032] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:39,032] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:21:39,032] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:21:39,033] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:39,033] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:21:39,033] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:37\n",
      "[2024-12-28 16:21:39,033] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:39,033] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:39,034] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:39,034] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:39,034] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:39,034] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:39,035] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:39,035] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:39,035] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/343866.py:37\n",
      "[2024-12-28 16:21:39,035] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:39,035] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:39,037] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:21:39,037] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:40\n",
      "[2024-12-28 16:21:39,037] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:39,037] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:39,037] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:21:39,038] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:39,038] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:39,038] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:39,039] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/343866.py:40\n",
      "[2024-12-28 16:21:39,039] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:39,039] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:39,041] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:21:39,041] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:43\n",
      "[2024-12-28 16:21:39,041] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:39,042] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:39,042] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:21:39,042] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:39,042] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:39,043] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:39,043] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/343866.py:43\n",
      "[2024-12-28 16:21:39,043] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:39,043] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 16:21:39,044] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:45\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:39,045] [8/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_15 =====\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.206 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_15 <eval_with_key>.206 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:21:39,046] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_15 =====\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:39,047] [8/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:21:39,048] [8/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:39,049] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291338011728)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 16:21:39,049] [8/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 16:21:39,049] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:39,050] [8/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:39,050] [8/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:39,050] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,051] [8/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,051] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,051] [8/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:39,052] [8/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/343866.py, line 34 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 3:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 6:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 7:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291338011728)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4e472e2f0; to 'LLaMAFirstLayerModel' at 0x7bf4ccc9c450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc97d530; to 'type' at 0x8a23560 (LLaMAFirstLayerModel)>\n",
      "  Guard 12:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 17:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b98a40; to 'Tensor' at 0x7bf5b0a4eb10>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 20:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 21:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 22:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 23:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 24:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b98a40; to 'Tensor' at 0x7bf5b0a4eb10>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 28:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291240560848)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b99d00; to 'LlamaDecoderLayer' at 0x7bf4c6fac8d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 29:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b989f0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 32:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 34:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 41:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b989f0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 46:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 48:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5ddc180; to 'Tensor' at 0x7bf4cc98ecf0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 49:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291240568144)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbf880; to 'LlamaAttention' at 0x7bf4c6fae550>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 50:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291240568144)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbf880; to 'LlamaAttention' at 0x7bf4c6fae550>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 72:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5ddc180; to 'Tensor' at 0x7bf4cc98ecf0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 78:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b989f0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 79:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 86:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730900; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 88:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730900; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 92:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730680; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 93:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b989f0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730040; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 99:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 100:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 101:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 102:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 103:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 104:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 105:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730040; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6730680; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6733ec0; to 'Tensor' at 0x7bf4c6306690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 119:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 120:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 121:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 123:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291240560848)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b99d00; to 'LlamaDecoderLayer' at 0x7bf4c6fac8d0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 124:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 128:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b98a40; to 'Tensor' at 0x7bf5b0a4eb10>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 133:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 135:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 138:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 151:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b487c0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 153:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 154:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 155:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291338011728)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4e472e2f0; to 'LLaMAFirstLayerModel' at 0x7bf4ccc9c450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc97d530; to 'type' at 0x8a23560 (LLaMAFirstLayerModel)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.3451, 0.1526, 0.0770, 0.2759, 0.1257, 0.0239\n",
      "OutputGraph.call_user_compiler   0.0014, 0.0003, 0.0003, 0.0004, 0.0003, 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use TorchDynamo's explain to capture the graph\n",
    "# Extract the input_ids tensor from BatchEncoding\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "explanation = torch._dynamo.explain(model, input_ids)\n",
    "\n",
    "# Print the explanation\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph break to Python `forward`\n",
    "\n",
    "Using `dynamo` explain to evaluate the graph and breaks generated by `torch._dynamo`, use `torch._dynamo.optimize`\n",
    "generate the Python `forward` function for each of these graph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:21:43,338] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:43,339] [9/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/343866.py:26\n",
      "[2024-12-28 16:21:43,339] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:26\n",
      "[2024-12-28 16:21:43,339] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-28 16:21:43,340] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:43,341] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,341] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:28\n",
      "[2024-12-28 16:21:43,341] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:43,341] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,341] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,342] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,342] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,343] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,343] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/343866.py:28\n",
      "[2024-12-28 16:21:43,343] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:43,343] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,345] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:21:43,345] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:43,345] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:43,345] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,346] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,346] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,346] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,347] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:21:43,347] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,347] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,347] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,348] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,348] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:21:43,348] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:43,348] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:43,349] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:43,349] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:43,349] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:43,349] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,350] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:43,350] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:43,351] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,351] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,351] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/343866.py:31\n",
      "[2024-12-28 16:21:43,351] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:43,351] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:43,352] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:21:43,352] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:43,352] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:43,352] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,352] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,353] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,353] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,353] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,354] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,354] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,354] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:43,354] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:43,354] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,355] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,358] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,359] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,359] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,359] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,360] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,360] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,360] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,360] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,360] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,361] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,361] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,361] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,361] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,361] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,362] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,362] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,362] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,362] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,362] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,363] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,363] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,363] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,364] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,364] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,364] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,364] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,365] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,366] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,367] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,368] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,369] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:43,369] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,369] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,370] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,370] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,370] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,370] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,371] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:21:43,371] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,371] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:43,371] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,372] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:43,373] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,373] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,373] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,373] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,374] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,374] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,374] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:43,374] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,374] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,377] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,377] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,377] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,378] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,378] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,378] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,378] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,379] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,379] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,379] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,380] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,381] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,381] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,381] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,382] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,382] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,382] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,382] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,383] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,383] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,383] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,383] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,384] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,385] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,386] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,387] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,388] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:43,388] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,388] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,389] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,389] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,389] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,389] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,390] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:43,391] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,391] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:43,391] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,392] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,392] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:43,392] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,394] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:43,395] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,396] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,396] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:43,396] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,397] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:43,397] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,398] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,398] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:43,399] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:43,399] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,399] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:43,399] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,401] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,401] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,401] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,401] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,402] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:43,402] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:43,403] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,403] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,404] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,404] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,404] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:43,406] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:43,407] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:43,407] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,407] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,408] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,408] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,409] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,409] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,409] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,411] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:43,415] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,415] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,415] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,415] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:43,416] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,417] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,417] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,417] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,418] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:43,418] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,418] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,418] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,420] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,420] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,421] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,421] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,421] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,423] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,423] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,423] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,423] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,425] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,425] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,425] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,425] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,425] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,426] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:43,427] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,427] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,427] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,428] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,428] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,428] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,428] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,428] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,429] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,429] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,429] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,429] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,430] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,431] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,432] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:21:43,432] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,432] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,432] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,432] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,433] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:21:43,434] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,435] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,436] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,436] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:43,436] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,436] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:21:43,436] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,437] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,437] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,437] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,437] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:21:43,438] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,441] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,441] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,442] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,442] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,442] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,442] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,443] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,443] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,443] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,444] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,444] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,444] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,444] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,445] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,446] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,446] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,446] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,446] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,446] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,447] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,447] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,447] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,448] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,449] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,450] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,451] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,452] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,452] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,452] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,452] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:43,453] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,453] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,453] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,455] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,455] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,455] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,455] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:43,458] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,458] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:43,458] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:43,459] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:43,459] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:43,460] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:43,460] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:43,460] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:43,460] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,461] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,461] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:43,461] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:43,461] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:43,462] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,462] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,463] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:43,463] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,463] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,463] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,464] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,464] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:43,464] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,464] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,466] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:43,466] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,467] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,467] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,467] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,467] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,467] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,468] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,468] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,469] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,469] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,470] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,470] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,470] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,474] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,475] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,475] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,475] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,475] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,476] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,477] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,477] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,477] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,477] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,477] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,480] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,481] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,481] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,481] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,481] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,482] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,485] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,485] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,485] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,485] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:43,486] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,486] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,486] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,486] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,486] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,487] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,487] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,488] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,488] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,488] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,488] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,488] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,490] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,490] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,491] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,493] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,493] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,493] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,493] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:43,493] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,494] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,494] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,494] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,494] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,495] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,495] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,496] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,496] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,496] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,496] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,496] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,498] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,498] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,498] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,499] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,499] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,499] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,499] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,499] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,500] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,501] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,501] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,501] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:43,501] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,501] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,502] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,502] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,502] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,503] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,503] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,503] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,504] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,504] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,504] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,504] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,505] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,506] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,506] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,507] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,507] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,507] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,507] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,507] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,508] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,509] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,510] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,510] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,510] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:43,510] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,511] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,512] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,512] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,512] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:43,512] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:43,513] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,513] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,513] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,513] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,514] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:21:43,514] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:43,514] [9/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,514] [9/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,515] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,515] [9/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/343866.py\", line 34, in forward\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:21:43,517] [9/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:21:43,518] [9/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,518] [9/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_16 =====\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.207 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,519] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_16 <eval_with_key>.207 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_16 =====\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:21:43,520] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:43,521] [9/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:43,521] [9/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:43,524] [9/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:43,524] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291338011728)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/343866.py:28 in forward\n",
      "[2024-12-28 16:21:43,525] [9/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/343866.py:28 in forward\n",
      "[2024-12-28 16:21:43,525] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/343866.py:31 in forward\n",
      "[2024-12-28 16:21:43,526] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,526] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,526] [9/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,527] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,527] [9/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,527] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,529] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:43,530] [10/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:21:43,531] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:21:43,531] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:43,531] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:43,532] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:21:43,534] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:43,535] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,535] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,535] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,535] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,536] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,536] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:21:43,536] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:43,536] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,536] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,539] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,539] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,539] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,540] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,540] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,540] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,540] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,541] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,541] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,541] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,542] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,542] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,542] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,543] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,543] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,543] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,543] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,543] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,544] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,544] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,544] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,545] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,545] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,545] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,546] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,546] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,546] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,547] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,548] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,548] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,548] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,548] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,549] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,550] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,551] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,552] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,553] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:43,554] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,554] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:43,555] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,555] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,555] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:43,556] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,556] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:43,556] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:43,557] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,558] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,558] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,558] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,559] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,559] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:43,559] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:43,559] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,559] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,560] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,560] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,560] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:43,561] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:43,561] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,562] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,563] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,564] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,565] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,566] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,567] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,567] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,567] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,567] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,568] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,568] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,568] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,568] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,570] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,570] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,570] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,570] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,570] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,571] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:43,572] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,572] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,572] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,573] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,573] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,573] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,573] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,573] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,574] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,574] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,574] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,574] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,575] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,575] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:43,576] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,576] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:21:43,577] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,578] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:21:43,579] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:21:43,580] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,581] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,582] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:21:43,583] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,587] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,588] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,588] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,588] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,588] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,589] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,589] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,589] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,590] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,590] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,590] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,590] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,590] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,591] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,591] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,591] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,591] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,592] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,592] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,592] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,592] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,593] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,593] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,593] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,594] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,595] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,595] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,595] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,596] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,596] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,596] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,597] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,598] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,598] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,598] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,598] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,599] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,599] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,599] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,599] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,599] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,600] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:21:43,600] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,600] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,601] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,602] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,602] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,602] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,602] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:43,604] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,604] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:43,604] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:43,604] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:43,605] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:43,605] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:43,606] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:43,606] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:43,606] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,606] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,606] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:43,607] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:43,607] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:43,608] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,608] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,608] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:43,609] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,609] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,609] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,609] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,609] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:43,610] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,610] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,610] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:43,611] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,611] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,611] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,612] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,612] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,612] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,612] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,613] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,613] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,613] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,614] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,614] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,614] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,617] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,618] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,618] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,618] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,618] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,619] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,619] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,619] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,620] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,620] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,620] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,624] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,624] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,624] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,624] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,624] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,625] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,625] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,625] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,626] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,626] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,626] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,631] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,631] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,631] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,631] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:43,632] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,632] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,632] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,632] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,633] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,633] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,633] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,633] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,634] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,634] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,634] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,634] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,635] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,635] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,635] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,635] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,636] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,636] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,636] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,636] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,637] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,639] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,639] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,639] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:43,640] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,641] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,641] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,642] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,642] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,642] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,643] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,643] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,643] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,644] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,644] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,644] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,645] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,646] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,646] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,646] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,647] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,647] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,647] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,647] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,648] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,649] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,649] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,649] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:43,649] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,650] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,650] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,650] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,650] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,651] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,651] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,652] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,652] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,652] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,652] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,652] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,654] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,654] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,655] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,655] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,656] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,656] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,656] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,656] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,657] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,658] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,658] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:43,658] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:43,658] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,658] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,659] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,660] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,660] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,660] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:43,661] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:43,662] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,662] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:43,662] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:43,662] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,662] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,663] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,663] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,663] [10/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,664] [10/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:21:43,664] [10/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:21:43,665] [10/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:21:43,665] [10/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,665] [10/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,666] [10/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:43,668] [10/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,668] [10/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:43,669] [10/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_18 =====\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.208 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_18 <eval_with_key>.208 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:21:43,670] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_18 =====\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:43,672] [10/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:43,673] [10/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:43,677] [10/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:43,677] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240560848)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,678] [10/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,679] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:43,679] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:43,680] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,680] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,681] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:21:43,682] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,682] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,683] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,683] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,683] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,683] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:21:43,684] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,684] [10/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,684] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,685] [10/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,685] [10/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:21:43,685] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,686] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,686] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,687] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,687] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,688] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,688] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,689] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:43,689] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,690] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,697] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:43,700] [11/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:21:43,700] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:21:43,700] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:21:43,701] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:43,703] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:43,704] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:21:43,704] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:21:43,705] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:21:43,705] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:21:43,705] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:21:43,705] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:21:43,706] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,706] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:21:43,706] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:21:43,706] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:21:43,707] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:43,707] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,707] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:43,708] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:21:43,708] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,708] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,709] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,709] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:21:43,709] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:43,709] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,709] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,710] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:43,710] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,710] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,711] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,711] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:21:43,711] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,711] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,712] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,712] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,713] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,713] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,713] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:21:43,713] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,713] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,716] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,716] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:21:43,716] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,716] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,717] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,717] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,717] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,717] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,718] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:21:43,718] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,718] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,720] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,720] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:21:43,720] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,721] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,721] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,721] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_input_ids_ : torch.Tensor):\n",
      "    l_input_ids_ = L_input_ids_\n",
      "    l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "    arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "    unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "    return (l__self___embed_tokens, unsqueeze)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add);  add = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "    return (mul_1,)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:21:43,721] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,722] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,722] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:21:43,722] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,722] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,724] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,724] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:43,724] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,724] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:21:43,725] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,725] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,726] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,726] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,726] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,726] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,727] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,728] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,728] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,729] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,730] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,730] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:43,730] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,730] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:21:43,730] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,731] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,732] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,732] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,732] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:43,732] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,732] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,733] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,733] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,733] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,733] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,734] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,734] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:21:43,734] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,734] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,735] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,735] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:43,735] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,735] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:21:43,735] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:21:43,736] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:21:43,736] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,736] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,736] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,736] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,737] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,737] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,737] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,738] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:43,738] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,738] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,739] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:43,739] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,739] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,740] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,740] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,740] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:21:43,740] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,740] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,741] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,742] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:21:43,742] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:21:43,742] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:21:43,742] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,742] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,743] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,743] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:43,743] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,743] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:21:43,744] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:21:43,744] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:21:43,744] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:21:43,745] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:21:43,745] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:43,745] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,745] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,745] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,746] [11/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:21:43,746] [11/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:21:43,747] [11/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:21:43,748] [11/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_20 =====\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.209 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:43,749] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_20 <eval_with_key>.209 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:21:43,750] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_20 =====\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:43,751] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:43,752] [11/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:43,752] [11/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:43,771] [11/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:43,772] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240568144)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:21:43,773] [11/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:21:43,773] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:43,774] [11/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:43,774] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,775] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,776] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:21:43,781] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,784] [11/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,784] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,785] [11/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:43,785] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:21:43,786] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,787] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:43,790] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:43,793] [12/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:43,794] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:21:43,794] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:21:43,795] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:21:43,796] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:43,798] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:43,799] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:21:43,801] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:43,802] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:21:43,802] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,802] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:43,802] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,803] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,803] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:21:43,803] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:21:43,803] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,803] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,804] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,804] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,804] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,804] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,805] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:21:43,805] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:21:43,805] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,806] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,810] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,810] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:43,811] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,811] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,811] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:43,812] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,812] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,813] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:43,813] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,814] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:43,814] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,814] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,814] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,815] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,815] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,815] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,815] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,815] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,816] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,816] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,817] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,817] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,818] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,818] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,818] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,819] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,819] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,820] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,820] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,820] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,820] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:43,821] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:43,822] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,822] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,822] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,822] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,822] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,823] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:43,823] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,823] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,823] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:43,824] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,825] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,825] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,825] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,825] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:43,826] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:43,826] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:43,826] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,826] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,827] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,828] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,828] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,828] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,828] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,829] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:21:43,830] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:43,830] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:21:43,830] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:21:43,830] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:21:43,831] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:21:43,831] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,831] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,831] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,832] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,832] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:21:43,832] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:43,832] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,832] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,833] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,833] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:43,833] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,833] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:21:43,833] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,834] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:21:43,835] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,835] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:21:43,835] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,836] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,836] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:21:43,836] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:21:43,836] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,836] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,837] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,838] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,838] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,838] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:43,838] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:43,838] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,839] [12/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:43,840] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,840] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,841] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,841] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,841] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:43,842] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,842] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,842] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,842] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:43,842] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,845] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:21:43,845] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,846] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,846] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,846] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:43,846] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:43,847] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:43,848] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:43,848] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:21:43,849] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:21:43,849] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,850] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,850] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,851] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,851] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,851] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,851] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:43,851] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,853] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:21:43,853] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,853] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:43,853] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:21:43,854] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,854] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,854] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,854] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:43,855] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,855] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,855] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,855] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:43,856] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,856] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,856] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:43,856] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,858] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:21:43,858] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,859] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,859] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,859] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:43,859] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:43,860] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:21:43,861] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,862] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,862] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:21:43,862] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:21:43,862] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:21:43,863] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,863] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:21:43,863] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:21:43,864] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,864] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:21:43,864] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,864] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,865] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,865] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:21:43,865] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,865] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,866] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,866] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:21:43,866] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,866] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,867] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:21:43,867] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:21:43,867] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,867] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,867] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,868] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,869] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,869] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,869] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,869] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,869] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:43,871] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,871] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,871] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,872] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:21:43,872] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,872] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,872] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:43,873] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,874] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,874] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,874] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,876] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,877] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:43,877] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,877] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,878] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,878] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,878] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:43,878] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:43,880] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,880] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,880] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:43,881] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,881] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,882] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,882] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,882] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,882] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:43,883] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,885] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,886] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,886] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,886] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:43,886] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,889] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,889] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,889] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:21:43,890] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,890] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,890] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:21:43,891] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:21:43,893] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,893] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:21:43,893] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:21:43,895] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,896] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,896] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:21:43,896] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,896] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,897] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:21:43,897] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:21:43,898] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,898] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:21:43,898] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:21:43,899] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,900] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,900] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:21:43,900] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,901] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,902] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,902] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,903] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,903] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:21:43,904] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:21:43,904] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,904] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:43,904] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:43,905] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:21:43,905] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,906] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:43,907] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,907] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:43,907] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,909] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:43,910] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,910] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:43,912] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:21:43,913] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:21:43,913] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,914] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:43,914] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,914] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:43,914] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,917] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:43,917] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,917] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:43,917] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:43,918] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:43,919] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,919] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:43,921] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,922] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,922] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,923] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,923] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:43,923] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,925] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:43,926] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,926] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:43,926] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:43,928] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,928] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,928] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:43,929] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:21:43,929] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:43,929] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,930] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,930] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:43,931] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:21:43,931] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,931] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:21:43,931] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,932] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:21:43,932] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,932] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,933] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,933] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,933] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,934] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:43,934] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:21:43,935] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:43,935] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:43,935] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:21:43,936] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,936] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:43,936] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:21:43,937] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:21:43,937] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:21:43,937] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:21:43,938] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:43,938] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,938] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,939] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,939] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,939] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,940] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:21:43,940] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:21:43,940] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,940] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:21:43,941] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,941] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:21:43,941] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,941] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,941] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:43,942] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:21:43,942] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:43,942] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:43,942] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,943] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,943] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,943] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:43,943] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,944] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:43,945] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,945] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:43,945] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:21:43,945] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:21:43,945] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:21:43,946] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,946] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,946] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,946] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:43,946] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,947] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:21:43,947] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,947] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:43,948] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:21:43,950] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:21:43,950] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:43,950] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,950] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,951] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,951] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:43,951] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:43,951] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "    l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "    l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "    view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    return (transpose, transpose_1, transpose_2)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:21:43,952] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:43,953] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:43,953] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,953] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:43,954] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:21:43,955] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,955] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,955] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,956] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,956] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:43,957] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,957] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,957] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:43,957] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,958] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:43,959] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:21:43,961] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:21:43,961] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,961] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,961] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,962] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,962] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,962] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:43,962] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,963] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,963] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:43,963] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,964] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:21:43,964] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,964] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,964] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,965] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:21:43,966] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,966] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,967] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:43,967] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,967] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,967] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,968] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,968] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,968] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,969] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,969] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:43,969] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,970] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,970] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,970] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:43,970] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:21:43,971] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,971] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,971] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:43,971] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,972] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:43,972] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,972] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:43,973] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:21:43,974] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:21:43,974] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:43,975] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:43,976] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:43,977] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:43,977] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:43,977] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,977] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:43,978] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:21:43,979] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,979] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,979] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,979] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,981] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:43,981] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,981] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,981] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:43,981] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,982] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:21:43,983] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:21:43,984] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:21:43,984] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,984] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,984] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,985] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,985] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,985] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:21:43,985] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:43,986] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,986] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:43,986] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,987] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:21:43,987] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,987] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,988] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:43,988] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:43,988] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:43,988] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,989] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,989] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,989] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:21:43,990] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:43,990] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,990] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:21:43,990] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,990] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,991] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,991] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:21:43,991] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:43,991] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:43,992] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:43,992] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:21:43,993] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,993] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,993] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,993] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:43,993] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:21:43,994] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,994] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,994] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:43,994] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:43,995] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:43,995] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:21:43,995] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:21:43,995] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:21:43,995] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:21:43,996] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,996] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:43,996] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:21:43,996] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:21:43,996] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:43,997] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:43,998] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:21:43,998] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:43,998] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:21:43,998] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:43,998] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:43,999] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,000] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:21:44,001] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,001] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:21:44,001] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:21:44,001] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:21:44,002] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,003] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,004] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,004] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,004] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,004] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,004] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,005] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,005] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,005] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,005] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,006] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:44,006] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,007] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,007] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,007] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:44,008] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,008] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,008] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,010] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:44,010] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:44,010] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,010] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,011] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,012] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,012] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,012] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,012] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,013] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:44,013] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:44,013] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,013] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,014] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,015] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,016] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:44,016] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,016] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:21:44,016] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:44,016] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:21:44,017] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:21:44,017] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,017] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,017] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,018] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:21:44,019] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,019] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,019] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:21:44,019] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,019] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:21:44,020] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:21:44,020] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:21:44,021] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,022] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,023] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,023] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,023] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,023] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,023] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,024] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,024] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,024] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,024] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,024] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:21:44,025] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,025] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,025] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:21:44,025] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:44,026] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,026] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,026] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,028] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:21:44,028] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:21:44,028] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,028] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,029] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,030] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,030] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,030] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,030] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,031] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:44,031] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:44,031] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,031] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,031] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,032] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,033] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,033] [12/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:21:44,034] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,034] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:44,034] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:44,034] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:44,034] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,035] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:44,035] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,035] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,035] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:44,036] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:44,037] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,037] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,037] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:44,037] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:44,037] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,039] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:21:44,040] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:44,040] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:21:44,040] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:44,041] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,042] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:44,042] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:21:44,042] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:21:44,042] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:21:44,042] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,043] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:21:44,044] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:21:44,044] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,044] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,044] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,044] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:44,045] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:44,045] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:44,045] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:44,045] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:44,045] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,047] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:44,047] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:44,047] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:21:44,048] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:44,048] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:44,048] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:21:44,048] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:44,048] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,050] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:44,050] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:21:44,050] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:44,050] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:21:44,050] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,051] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:21:44,051] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:21:44,051] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,051] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,052] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:44,052] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,053] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,053] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,053] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,054] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:21:44,054] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:44,054] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,055] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:44,056] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:21:44,056] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:44,056] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:44,057] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,057] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:44,057] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,058] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,058] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,058] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:21:44,058] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:44,058] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,061] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,061] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:21:44,061] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:21:44,061] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:44,062] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:21:44,062] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:44,062] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:21:44,063] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:21:44,063] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,063] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,064] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,064] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,065] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,065] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,065] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:21:44,066] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,066] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:44,066] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:44,066] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:44,067] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:21:44,067] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:21:44,067] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,068] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,068] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,068] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:44,068] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:44,068] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:21:44,070] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:21:44,071] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:21:44,071] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:21:44,072] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:21:44,072] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:44,072] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:21:44,073] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,073] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:21:44,073] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:44,074] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:44,074] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:21:44,074] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:21:44,074] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,074] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,075] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,075] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,075] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:21:44,075] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:44,075] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,076] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,076] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:21:44,076] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:44,077] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,077] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,077] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:44,078] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,078] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,078] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,078] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:21:44,078] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:44,079] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,079] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,079] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,080] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,080] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,080] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:21:44,080] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:44,080] [12/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,082] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,082] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:21:44,082] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:21:44,082] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:21:44,083] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,083] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:21:44,083] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:21:44,083] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:21:44,084] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,084] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:21:44,084] [12/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:21:44,084] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:21:44,084] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:21:44,085] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,085] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,085] [12/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:44,086] [12/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:44,086] [12/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:44,086] [12/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:44,088] [12/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_22 =====\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.210 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,089] [12/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_22 <eval_with_key>.210 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:21:44,091] [12/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_22 =====\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,095] [12/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:44,096] [12/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:44,096] [12/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:44,100] [12/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:44,101] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:44,101] [12/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:44,102] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240568144)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,102] [12/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,102] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:44,102] [12/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:21:44,103] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:21:44,103] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,103] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:21:44,104] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,104] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:21:44,104] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,105] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:21:44,105] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,105] [12/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,106] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:21:44,106] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:21:44,107] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:21:44,107] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,107] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:21:44,108] [12/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,108] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,108] [12/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,109] [12/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:21:44,109] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:21:44,110] [12/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:21:44,110] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,110] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,110] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,111] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,111] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,111] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,112] [12/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,112] [12/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,112] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,113] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,113] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,113] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,114] [12/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,119] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:44,120] [13/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:44,120] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:21:44,120] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:21:44,121] [13/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:44,122] [13/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:44,123] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,123] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:44,124] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:21:44,124] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:21:44,124] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:21:44,124] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,124] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,125] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,126] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,126] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:21:44,126] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,127] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,128] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,128] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:21:44,128] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:21:44,128] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,128] [13/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:44,130] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,130] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:44,131] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,131] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,131] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:44,131] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:44,132] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,132] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:44,132] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:44,132] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:44,132] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,133] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,133] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,133] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:44,133] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,133] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,134] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,134] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,134] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,134] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,134] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,135] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,135] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,135] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,135] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:44,136] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:44,137] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,138] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,139] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:44,140] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:44,141] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,141] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,142] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,142] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,142] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:44,142] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,142] [13/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,143] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:21:44,144] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:44,144] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,144] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:44,144] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,144] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:44,145] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,146] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,146] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,146] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:44,146] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:44,147] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:44,148] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:21:44,149] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:21:44,149] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,149] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,149] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,149] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,150] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,150] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:44,150] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:21:44,151] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,152] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:44,152] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,152] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,152] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:21:44,153] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,153] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:44,153] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,153] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,154] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,154] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,154] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:44,154] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,155] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,156] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,156] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:44,156] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,156] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,157] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,157] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:44,157] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,157] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,157] [13/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:21:44,158] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,158] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,158] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:21:44,159] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:44,159] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:21:44,159] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,159] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:44,159] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,160] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,160] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,160] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:44,160] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,161] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,161] [13/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:21:44,161] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,162] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,163] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,163] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,163] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,164] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:21:44,164] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:21:44,164] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,164] [13/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:44,167] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,167] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:21:44,168] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,168] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,168] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:21:44,168] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:44,168] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,170] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:21:44,170] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:44,170] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:21:44,170] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:21:44,171] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,171] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,171] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:44,171] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,171] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,172] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,172] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,172] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,172] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,173] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,173] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,173] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,174] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,174] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,174] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,175] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,176] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:21:44,177] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:21:44,178] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:21:44,178] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:21:44,178] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,178] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,178] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,179] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:21:44,180] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:21:44,180] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:21:44,180] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,181] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,182] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:21:44,182] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,182] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,182] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,183] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,183] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,184] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,184] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,185] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,185] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,186] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,186] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,186] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,187] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,187] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,187] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,187] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,187] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:44,192] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,193] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,193] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,193] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,193] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,196] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,196] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,197] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,197] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,198] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,198] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,198] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,198] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:21:44,203] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,203] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,203] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,203] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,204] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,204] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,204] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,204] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,204] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,209] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:21:44,209] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:21:44,209] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:21:44,209] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:21:44,210] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,210] [13/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:21:44,210] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,210] [13/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:21:44,210] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,211] [13/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:21:44,212] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:21:44,213] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:21:44,214] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:21:44,215] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:21:44,215] [13/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:21:44,215] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:21:44,216] [13/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:21:44,216] [13/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:44,216] [13/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:44,216] [13/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_23 =====\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.211 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,218] [13/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_23 <eval_with_key>.211 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:21:44,219] [13/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_23 =====\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,221] [13/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:44,222] [13/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:44,222] [13/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:44,225] [13/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:44,225] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291240560848)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,226] [13/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,226] [13/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,227] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:44,227] [13/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:44,228] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:21:44,228] [13/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,228] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:21:44,229] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:21:44,229] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:21:44,229] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,230] [13/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,230] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,231] [13/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,232] [13/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:21:44,232] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,232] [13/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,233] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,233] [13/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,234] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,234] [13/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,235] [13/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,235] [13/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:21:44,236] [13/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,236] [13/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,242] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:21:44,242] [14/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:44,243] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:34\n",
      "[2024-12-28 16:21:44,243] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:21:44,244] [14/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:21:44,245] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:21:44,246] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:21:44,246] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:21:44,246] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:21:44,247] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,247] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,247] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:37\n",
      "[2024-12-28 16:21:44,247] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:44,247] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:21:44,248] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:21:44,248] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:21:44,248] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/343866.py:37\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:44,249] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,251] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:21:44,251] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:40\n",
      "[2024-12-28 16:21:44,251] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:44,251] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,252] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,252] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,252] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,253] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,253] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/343866.py:40\n",
      "[2024-12-28 16:21:44,253] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:44,253] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:21:44,258] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:21:44,258] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:43\n",
      "[2024-12-28 16:21:44,258] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:44,258] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:21:44,258] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,259] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:21:44,259] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,259] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:21:44,260] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/343866.py:43\n",
      "[2024-12-28 16:21:44,260] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:44,260] [14/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 16:21:44,262] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:21:44,262] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/343866.py:45\n",
      "[2024-12-28 16:21:44,262] [14/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:21:44,262] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:21:44,263] [14/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:21:44,263] [14/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:21:44,263] [14/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:21:44,263] [14/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_24 =====\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.212 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_24 <eval_with_key>.212 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:21:44,264] [14/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_24 =====\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:21:44,265] [14/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:21:44,267] [14/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:21:44,267] [14/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291338011728)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 16:21:44,267] [14/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/343866.py:40 in <resume in forward>\n",
      "[2024-12-28 16:21:44,268] [14/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:44,268] [14/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:21:44,268] [14/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:21:44,269] [14/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,269] [14/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,269] [14/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,270] [14/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:21:44,270] [14/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "    l_position_ids_ = L_position_ids_\n",
      "    l_query_states_ = L_query_states_\n",
      "    l_key_states_ = L_key_states_\n",
      "    l_value_states_ = L_value_states_\n",
      "    _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "    l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "    getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "    float_1 = getitem.float();  getitem = None\n",
      "    expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "    getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "    float_2 = getitem_1.float();  getitem_1 = None\n",
      "    _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "    float_3 = expand.float();  expand = None\n",
      "    float_4 = float_2.float();  float_2 = None\n",
      "    matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "    transpose = matmul.transpose(1, 2);  matmul = None\n",
      "    cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "    cos = cat.cos()\n",
      "    sin = cat.sin();  cat = None\n",
      "    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "    mul = cos * 1.0;  cos = None\n",
      "    mul_1 = sin * 1.0;  sin = None\n",
      "    to = mul.to(dtype = torch.float32);  mul = None\n",
      "    to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "    _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "    unsqueeze = to.unsqueeze(1);  to = None\n",
      "    unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "    mul_2 = l_query_states_ * unsqueeze\n",
      "    getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "    neg = -getitem_3;  getitem_3 = None\n",
      "    cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "    mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "    getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "    neg_1 = -getitem_5;  getitem_5 = None\n",
      "    cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "    mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "    add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "    getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "    expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "    reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "    getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "    expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "    reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "    transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "    matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "    truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "    softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "    to_2 = softmax.to(torch.float32);  softmax = None\n",
      "    dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "    matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "    transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "    contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "    reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "    l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "    return (l__self___o_proj,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    l_residual_ = L_residual_\n",
      "    add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "    to = add.to(torch.float32)\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add_1 = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "    l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "    l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "    l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "    mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "    l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "    add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "    return (add_2,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "    l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "    l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "    return (l__self___softmax,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1006, 0.0982, 0.1000, 0.0982, 0.1100, 0.0975, 0.0986, 0.0959, 0.1019,\n",
       "         0.0992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Python code from the torch._dynamo graph\n",
    "def debug_callback(graph_module, example_inputs):\n",
    "    # Generate Python code for the traced graph\n",
    "    print(graph_module.code)\n",
    "    return graph_module\n",
    "\n",
    "# Wrap your model with the debug callback\n",
    "model_optimized = torch._dynamo.optimize(debug_callback)(model)\n",
    "\n",
    "# Run your model to trigger the tracing\n",
    "model_optimized(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps - Capturing `nn.Module` with Custom ops\n",
    "\n",
    "There are instances where PyTorch implementation can have custom ops - for instance where the programmer wants to force `kernel` fusion, they can define a custom op as such and would need `torch.compile` to respect that. And similarly in cases where there ops on `numpy` or `scipy` defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lib = torch.library.Library(\"scale_custom_op\", \"DEF\")\n",
    "\n",
    "# Step 2: Define the custom op schema\n",
    "my_lib.define(\"scale_by_max(Tensor input) -> Tensor\")\n",
    "\n",
    "def scale_by_max(input: torch.Tensor) -> torch.Tensor:\n",
    "    max_value = torch.max(input)\n",
    "    return input * max_value\n",
    "\n",
    "# Use IMPL to register the implementation\n",
    "impl_lib = torch.library.Library(\"scale_custom_op\", \"IMPL\")\n",
    "impl_lib.impl(\"scale_by_max\", scale_by_max, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::hardsigmoid.out\n",
      "aten::reflection_pad3d_backward\n",
      "aten::logical_and.out\n",
      "aten::quantized_lstm.input_legacy\n",
      "aten::linalg_eig.out\n",
      "aten::log_sigmoid_backward.grad_input\n",
      "prepacked::conv2d_transpose_clamp_run\n",
      "aten::leaky_relu.out\n",
      "aten::_log_softmax_backward_data\n",
      "aten::_foreach_pow_.ScalarList\n",
      "aten::atanh.out\n",
      "aten::sgn\n",
      "aten::_to_sparse_bsr\n",
      "aten::ge.Scalar\n",
      "aten::mean.out\n",
      "aten::geqrf.a\n",
      "aten::_foreach_pow_.Scalar\n",
      "aten::xlogy.Tensor\n",
      "aten::isin.Scalar_Tensor\n",
      "aten::_foreach_cos_\n",
      "aten::std.correction_out\n",
      "aten::silu_backward.grad_input\n",
      "aten::atan2\n",
      "aten::_foreach_sinh\n",
      "aten::_test_optional_filled_intlist\n",
      "aten::bucketize.Tensor\n",
      "aten::_foreach_log_\n",
      "aten::bitwise_and.Tensor_out\n",
      "aten::_foreach_acos\n",
      "aten::lt.Tensor\n",
      "aten::pow.Tensor_Scalar\n",
      "aten::_foreach_maximum_.Scalar\n",
      "aten::round\n",
      "aten::__irshift__.Scalar\n",
      "aten::special_laguerre_polynomial_l.out\n",
      "aten::pow.Scalar\n",
      "aten::sin.out\n",
      "aten::masked_fill_.Tensor\n",
      "aten::softplus_backward.grad_input\n",
      "aten::div.Tensor_mode\n",
      "aten::linalg_matrix_exp\n",
      "aten::atanh\n",
      "aten::_foreach_round\n",
      "aten::_foreach_addcdiv_.Scalar\n",
      "aten::asinh.out\n",
      "aten::complex.out\n",
      "aten::nanmedian\n",
      "aten::clamp_min.Tensor\n",
      "aten::_foreach_lgamma_\n",
      "c10d::monitored_barrier_\n",
      "aten::digamma_\n",
      "aten::index.Tensor\n",
      "aten::atan2.out\n",
      "aten::special_modified_bessel_i1.out\n",
      "aten::_foreach_copy_\n",
      "aten::igamma\n",
      "aten::special_i1\n",
      "aten::eq.Scalar_out\n",
      "c10d::reduce_scatter_\n",
      "aten::hardshrink.out\n",
      "aten::_cummin_helper\n",
      "aten::erf_\n",
      "aten::floor_divide\n",
      "aten::hardsigmoid_backward\n",
      "aten::_foreach_mul_.Scalar\n",
      "aten::lerp.Tensor\n",
      "aten::_upsample_nearest_exact2d\n",
      "aten::bitwise_left_shift.Tensor_out\n",
      "aten::max\n",
      "aten::pow_.Tensor\n",
      "aten::_linalg_svd.U\n",
      "aten::_standard_gamma_grad\n",
      "aten::_foreach_add.Scalar\n",
      "aten::_foreach_sqrt\n",
      "aten::hardtanh.out\n",
      "aten::cumprod_\n",
      "aten::special_shifted_chebyshev_polynomial_v.out\n",
      "aten::acosh_\n",
      "aten::hardtanh_backward.grad_input\n",
      "aten::_foobar\n",
      "aten::prod.dim_int\n",
      "aten::count_nonzero.dim_IntList\n",
      "aten::bernoulli_.Tensor\n",
      "c10d::reduce_scatter_tensor_coalesced_\n",
      "aten::upsample_trilinear3d\n",
      "aten::replication_pad3d.out\n",
      "aten::isposinf.out\n",
      "aten::_foreach_log2_\n",
      "aten::mse_loss\n",
      "aten::_add_relu.Scalar\n",
      "aten::histc.out\n",
      "aten::_make_per_tensor_quantized_tensor\n",
      "aten::_make_per_channel_quantized_tensor\n",
      "aten::_foreach_addcdiv.Scalar\n",
      "aten::acosh.out\n",
      "aten::eq_.Tensor\n",
      "aten::tril\n",
      "aten::replication_pad2d.out\n",
      "aten::tan\n",
      "aten::_weight_norm_interface\n",
      "aten::aminmax\n",
      "aten::conj_physical.out\n",
      "aten::renorm.out\n",
      "aten::log2.out\n",
      "aten::bitwise_or.Tensor\n",
      "mkldnn_prepacked::conv2d_run\n",
      "aten::upsample_bilinear2d_backward\n",
      "aten::norm.dtype_out\n",
      "aten::replication_pad3d\n",
      "aten::fill_.Scalar\n",
      "aten::ge_.Tensor\n",
      "aten::_upsample_bilinear2d_aa.out\n",
      "aten::_stack\n",
      "aten::_slow_conv2d_forward.output\n",
      "aten::_fft_r2c.out\n",
      "aten::_upsample_nearest_exact3d.out\n",
      "aten::sinc_\n",
      "aten::exp_\n",
      "aten::bernoulli.out\n",
      "c10d::allreduce_coalesced_\n",
      "aten::_upsample_bicubic2d_aa_backward\n",
      "aten::avg_pool2d_backward.grad_input\n",
      "aten::tanh_backward\n",
      "aten::special_chebyshev_polynomial_t\n",
      "aten::geqrf\n",
      "aten::huber_loss.out\n",
      "aten::pow.Tensor_Scalar_out\n",
      "aten::special_airy_ai.out\n",
      "aten::clamp\n",
      "aten::special_hermite_polynomial_h\n",
      "aten::elu_\n",
      "quantized::linear_prepack_fp16\n",
      "aten::masked_scatter_\n",
      "aten::_linalg_eigh\n",
      "aten::_foreach_sub.ScalarList\n",
      "aten::reflection_pad1d_backward.grad_input\n",
      "aten::nll_loss_forward.output\n",
      "aten::__lshift__.Scalar\n",
      "aten::_log_softmax_backward_data.out\n",
      "aten::_pdist_backward\n",
      "scale_custom_op::scale_by_max\n",
      "aten::polygamma.out\n",
      "aten::_pdist_forward\n",
      "aten::gt.Scalar_out\n",
      "aten::take.out\n",
      "aten::replication_pad3d_backward\n",
      "aten::repeat_interleave.Tensor\n",
      "aten::bitwise_or.Tensor_out\n",
      "aten::mse_loss_backward.grad_input\n",
      "aten::linalg_lstsq.out\n",
      "aten::_foreach_erfc_\n",
      "aten::gelu_backward.grad_input\n",
      "quantized::linear_with_input_q_dq_qweight_dq_relu_output_fp32\n",
      "aten::_upsample_bilinear2d_aa_backward\n",
      "aten::_foreach_maximum.List\n",
      "aten::ormqr.out\n",
      "aten::_logcumsumexp.out\n",
      "prepacked::conv2d_transpose_clamp_prepack\n",
      "aten::clamp_min_.Tensor\n",
      "aten::_foreach_clamp_min.Scalar\n",
      "aten::exp\n",
      "aten::upsample_nearest2d_backward\n",
      "aten::unique_dim_consecutive\n",
      "aten::rrelu_with_noise\n",
      "aten::asinh\n",
      "aten::bitwise_not_\n",
      "aten::asinh_\n",
      "aten::log_sigmoid_forward\n",
      "aten::add_.Tensor\n",
      "aten::special_scaled_modified_bessel_k0\n",
      "aten::lcm.out\n",
      "aten::_foreach_acos_\n",
      "aten::bitwise_left_shift.Tensor\n",
      "aten::_convert_indices_from_csr_to_coo.out\n",
      "aten::glu\n",
      "aten::lgamma.out\n",
      "aten::linalg_qr\n",
      "aten::upsample_bilinear2d.out\n",
      "aten::_scaled_dot_product_flash_attention\n",
      "aten::_foreach_pow.Scalar\n",
      "aten::tanh_backward.grad_input\n",
      "aten::quantized_lstm.data_legacy\n",
      "aten::binomial\n",
      "aten::max.unary_out\n",
      "aten::xlogy_.Tensor\n",
      "aten::_compute_linear_combination\n",
      "aten::linalg_cross.out\n",
      "aten::tan.out\n",
      "quantized::embedding_bag_2bit_rowwise_offsets\n",
      "aten::segment_reduce\n",
      "sparse::qlinear_dynamic\n",
      "aten::reflection_pad3d.out\n",
      "aten::quantize_per_tensor\n",
      "aten::_fake_quantize_per_tensor_affine_cachemask_tensor_qparams\n",
      "aten::lt_.Scalar\n",
      "aten::grid_sampler_3d_backward\n",
      "aten::linalg_solve_triangular.out\n",
      "aten::addmv.out\n",
      "aten::topk\n",
      "aten::baddbmm\n",
      "aten::masked_select.out\n",
      "aten::from_file\n",
      "aten::native_channel_shuffle\n",
      "aten::_foreach_frac\n",
      "aten::_foreach_sqrt_\n",
      "aten::quantized_gru.input_legacy\n",
      "aten::reflection_pad2d.out\n",
      "aten::_foreach_minimum.ScalarList\n",
      "aten::_cdist_backward\n",
      "c10d::_allgather_base_\n",
      "aten::_add_relu_.Scalar\n",
      "aten::hardsigmoid\n",
      "aten::copysign.Tensor\n",
      "aten::cumprod.out\n",
      "aten::_linalg_slogdet\n",
      "aten::le.Tensor_out\n",
      "aten::slow_conv3d_forward.output\n",
      "aten::_foreach_mul.List\n",
      "aten::gcd.out\n",
      "aten::_foreach_log10_\n",
      "aten::special_shifted_chebyshev_polynomial_v\n",
      "aten::special_modified_bessel_k0\n",
      "aten::_fft_c2r.out\n",
      "aten::_foreach_tanh\n",
      "aten::_foreach_sin_\n",
      "aten::mse_loss.out\n",
      "aten::mish.out\n",
      "aten::threshold\n",
      "aten::index_select.out\n",
      "aten::_foreach_mul.Scalar\n",
      "aten::expm1_\n",
      "aten::cumsum_\n",
      "aten::maximum\n",
      "aten::threshold.out\n",
      "aten::_ctc_loss.Tensor\n",
      "aten::_adaptive_avg_pool3d_backward\n",
      "aten::tanh.out\n",
      "aten::glu_backward_jvp\n",
      "aten::clamp.Tensor\n",
      "mkl::_mkl_linear\n",
      "aten::special_chebyshev_polynomial_w\n",
      "aten::median\n",
      "quantized::linear_dynamic_fp16\n",
      "aten::_adaptive_avg_pool2d\n",
      "aten::special_bessel_y0\n",
      "aten::triu.out\n",
      "aten::_foreach_log10\n",
      "aten::add.Tensor\n",
      "c10d::scatter_\n",
      "aten::index_copy.out\n",
      "aten::silu\n",
      "aten::__rshift__.Tensor\n",
      "aten::upsample_trilinear3d.out\n",
      "aten::signbit.out\n",
      "aten::mish_backward\n",
      "aten::_upsample_nearest_exact1d_backward\n",
      "aten::_foreach_asin_\n",
      "aten::max_pool3d_with_indices_backward.grad_input\n",
      "aten::index.Tensor_out\n",
      "aten::gt_.Tensor\n",
      "quantized::embedding_bag_4bit_prepack\n",
      "aten::pow.Scalar_out\n",
      "aten::_fft_r2c\n",
      "aten::mul_.Tensor\n",
      "aten::resize_\n",
      "aten::cosh_\n",
      "aten::poisson\n",
      "aten::grid_sampler_2d\n",
      "aten::reflection_pad2d_backward\n",
      "aten::_foreach_mul.ScalarList\n",
      "aten::ne.Scalar_out\n",
      "aten::special_erfcx\n",
      "aten::replication_pad1d\n",
      "aten::_to_sparse\n",
      "aten::fake_quantize_per_channel_affine_cachemask\n",
      "aten::multi_margin_loss_backward.grad_input\n",
      "aten::quantize_per_tensor.tensors\n",
      "aten::_assert_async.msg\n",
      "aten::logit_backward.grad_input\n",
      "aten::_foreach_minimum_.List\n",
      "aten::ge.Tensor_out\n",
      "aten::ge.Tensor\n",
      "aten::scatter.value\n",
      "aten::_foreach_norm.Scalar\n",
      "aten::bincount\n",
      "aten::_foreach_sub.List\n",
      "aten::index_reduce\n",
      "aten::special_spherical_bessel_j0.out\n",
      "aten::randperm.generator_out\n",
      "aten::scatter.value_out\n",
      "aten::upsample_nearest1d.out\n",
      "aten::leaky_relu_\n",
      "c10d::reduce_\n",
      "aten::batch_norm_update_stats\n",
      "aten::linalg_vector_norm.out\n",
      "aten::adaptive_max_pool2d_backward.grad_input\n",
      "aten::normal_\n",
      "aten::trunc_\n",
      "aten::asin.out\n",
      "aten::_fake_quantize_learnable_per_tensor_affine_backward\n",
      "aten::_foreach_div_.ScalarList\n",
      "aten::special_entr.out\n",
      "aten::_add_relu.out\n",
      "aten::addcdiv.out\n",
      "aten::_test_functorch_fallback\n",
      "aten::nansum.out\n",
      "aten::logaddexp2\n",
      "sparse::qlinear_relu_dynamic\n",
      "aten::_foreach_lerp_.List\n",
      "aten::isin.Tensor_Scalar\n",
      "aten::glu_backward\n",
      "aten::_foreach_log\n",
      "aten::round.decimals_out\n",
      "aten::gt.Tensor_out\n",
      "aten::linalg_ldl_factor_ex.out\n",
      "aten::eye.out\n",
      "aten::sum.dim_IntList\n",
      "aten::max_pool3d_with_indices\n",
      "aten::exp2.out\n",
      "aten::lgamma\n",
      "aten::_upsample_nearest_exact2d_backward\n",
      "aten::slow_conv_transpose2d\n",
      "aten::_native_multi_head_attention\n",
      "aten::zero_\n",
      "c10d::allgather_into_tensor_coalesced_\n",
      "aten::sign_\n",
      "aten::clamp_min.Tensor_out\n",
      "aten::channel_shuffle\n",
      "aten::special_i0e\n",
      "aten::hardtanh\n",
      "aten::_efficientzerotensor\n",
      "quantized::embedding_bag_byte_unpack\n",
      "aten::gcd_\n",
      "aten::max_pool2d_with_indices_backward\n",
      "quantized::embedding_byte\n",
      "aten::_foreach_abs\n",
      "aten::addmm\n",
      "aten::min.dim\n",
      "aten::binary_cross_entropy.out\n",
      "aten::_foreach_addcdiv.ScalarList\n",
      "aten::rrelu_with_noise_\n",
      "mkldnn::_convolution_pointwise\n",
      "aten::special_chebyshev_polynomial_t.out\n",
      "quantized::quantized_rnn_relu_cell_dynamic\n",
      "aten::cos.out\n",
      "aten::_unique2\n",
      "aten::_functional_assert_async.msg\n",
      "aten::hardswish.out\n",
      "aten::quantized_lstm.input\n",
      "aten::softshrink\n",
      "aten::clamp_\n",
      "aten::lerp_.Tensor\n",
      "aten::acos_\n",
      "aten::reflection_pad3d\n",
      "aten::fmod.Tensor\n",
      "aten::div.out\n",
      "aten::std_mean.correction\n",
      "aten::sinh.out\n",
      "aten::round_.decimals\n",
      "aten::sub.out\n",
      "aten::_upsample_nearest_exact3d\n",
      "aten::gelu\n",
      "aten::lu_unpack.out\n",
      "aten::addcdiv\n",
      "aten::_foreach_clamp_min.ScalarList\n",
      "quantized::embedding_bag_2bit_unpack\n",
      "aten::special_xlog1py.out\n",
      "aten::_fft_c2c\n",
      "aten::_foreach_sin\n",
      "quantized::conv2d_dynamic\n",
      "aten::max_pool3d_with_indices_backward\n",
      "aten::hardswish_backward\n",
      "aten::narrow_copy.out\n",
      "aten::gt_.Scalar\n",
      "aten::le.Tensor\n",
      "aten::leaky_relu_backward.grad_input\n",
      "aten::_cdist_forward\n",
      "quantized::conv_transpose2d_dynamic\n",
      "aten::_foreach_tanh_\n",
      "aten::acosh\n",
      "c10d::_reduce_scatter_base_\n",
      "aten::index_select\n",
      "aten::_nested_tensor_from_mask_left_aligned\n",
      "mkldnn_prepacked::conv2d_prepack\n",
      "quantized::embedding_bag_byte_prepack\n",
      "aten::hardswish_\n",
      "aten::frac.out\n",
      "aten::_empty_affine_quantized\n",
      "aten::cholesky\n",
      "aten::random_.to\n",
      "aten::reflection_pad2d\n",
      "aten::_foreach_maximum.Scalar\n",
      "aten::isin.Tensor_Tensor\n",
      "aten::fmod.Tensor_out\n",
      "aten::remainder.Scalar_Tensor\n",
      "aten::tril_\n",
      "aten::_transform_bias_rescale_qkv\n",
      "aten::quantized_gru.data_legacy\n",
      "aten::triangular_solve.X\n",
      "aten::linalg_ldl_solve\n",
      "aten::triu_\n",
      "aten::remainder.Tensor_out\n",
      "aten::argmax.out\n",
      "aten::aminmax.out\n",
      "aten::addmm_\n",
      "aten::logit.out\n",
      "aten::_foreach_lgamma\n",
      "aten::exp.out\n",
      "aten::scatter_add.out\n",
      "aten::linalg_ldl_solve.out\n",
      "aten::_upsample_bilinear2d_aa_backward.grad_input\n",
      "aten::lgamma_\n",
      "aten::gcd\n",
      "aten::_foreach_reciprocal\n",
      "aten::amax\n",
      "aten::avg_pool3d.out\n",
      "aten::_fake_quantize_learnable_per_channel_affine\n",
      "aten::sign\n",
      "aten::im2col\n",
      "aten::_foreach_div_.List\n",
      "aten::lt_.Tensor\n",
      "aten::lt.Scalar_out\n",
      "aten::floor_divide_.Tensor\n",
      "aten::slow_conv_dilated2d\n",
      "aten::__irshift__.Tensor\n",
      "aten::sqrt.out\n",
      "aten::reciprocal_\n",
      "aten::nextafter_\n",
      "aten::nll_loss2d_forward.output\n",
      "aten::special_ndtri.out\n",
      "aten::sin_\n",
      "aten::any\n",
      "aten::_nested_from_padded\n",
      "aten::_foreach_clamp_min.List\n",
      "aten::clamp_max_\n",
      "quantized::conv_transpose1d_dynamic\n",
      "aten::special_shifted_chebyshev_polynomial_u\n",
      "_quantized::linear_prepack_fp16\n",
      "aten::sinh_\n",
      "aten::view_as_complex\n",
      "aten::_foreach_sign_\n",
      "aten::scatter_reduce.two_out\n",
      "aten::upsample_bicubic2d.out\n",
      "aten::hardshrink\n",
      "aten::_foreach_floor\n",
      "aten::triu_indices\n",
      "aten::igammac\n",
      "aten::addbmm.out\n",
      "aten::native_layer_norm\n",
      "aten::lt.Tensor_out\n",
      "aten::_foreach_minimum.Scalar\n",
      "aten::norm.ScalarOpt_dim_dtype\n",
      "aten::_foreach_mul_.Tensor\n",
      "aten::clamp_.Tensor\n",
      "aten::special_modified_bessel_i0.out\n",
      "aten::scatter_add_\n",
      "aten::_upsample_bicubic2d_aa\n",
      "aten::log_sigmoid_forward.output\n",
      "aten::upsample_nearest2d\n",
      "aten::_segment_reduce_backward\n",
      "aten::rrelu_with_noise.out\n",
      "aten::scatter.value_reduce\n",
      "aten::erfinv\n",
      "aten::fractional_max_pool3d_backward.grad_input\n",
      "aten::atan2_\n",
      "aten::trunc.out\n",
      "aten::frexp.Tensor_out\n",
      "mkldnn::_convolution_pointwise.binary\n",
      "aten::amin\n",
      "aten::dequantize.self\n",
      "aten::min.unary_out\n",
      "aten::cholesky_inverse\n",
      "aten::index_copy_\n",
      "aten::special_entr\n",
      "aten::polygamma\n",
      "aten::upsample_nearest3d.out\n",
      "aten::_adaptive_avg_pool2d_backward\n",
      "aten::isin.Scalar_Tensor_out\n",
      "aten::_foreach_clamp_min_.Scalar\n",
      "aten::dot\n",
      "aten::mul.Tensor\n",
      "aten::_linalg_solve_ex\n",
      "aten::sparse_dim\n",
      "aten::_embedding_bag_forward_only\n",
      "quantized::quantized_gru_cell_dynamic\n",
      "aten::adaptive_max_pool2d.out\n",
      "aten::quantize_per_channel\n",
      "aten::pow.Tensor_Tensor_out\n",
      "aten::nll_loss_backward.grad_input\n",
      "aten::_fft_c2c.out\n",
      "aten::linalg_lu_factor_ex\n",
      "aten::copysign.out\n",
      "aten::polar.out\n",
      "aten::special_modified_bessel_i1\n",
      "aten::bitwise_and_.Tensor\n",
      "mkldnn::_linear_pointwise.binary\n",
      "aten::narrow_copy\n",
      "aten::_foreach_sub_.List\n",
      "aten::mul.out\n",
      "aten::i0.out\n",
      "aten::mkldnn_rnn_layer_backward\n",
      "aten::upsample_nearest1d_backward.grad_input\n",
      "aten::linalg_solve_triangular\n",
      "aten::scatter.reduce\n",
      "aten::slow_conv_transpose2d.out\n",
      "aten::scatter_.value_reduce\n",
      "aten::index_add.out\n",
      "aten::_softmax\n",
      "aten::min.dim_min\n",
      "aten::log\n",
      "aten::adaptive_avg_pool3d.out\n",
      "aten::random_\n",
      "aten::native_dropout\n",
      "aten::bitwise_xor_.Tensor\n",
      "aten::linalg_cholesky_ex\n",
      "aten::scatter_add\n",
      "aten::multilabel_margin_loss_forward\n",
      "aten::max_pool2d_with_indices\n",
      "quantized::conv3d_dynamic\n",
      "aten::_foreach_maximum.ScalarList\n",
      "aten::as_strided\n",
      "aten::neg.out\n",
      "aten::sin\n",
      "aten::threshold_backward\n",
      "aten::native_batch_norm\n",
      "aten::addcmul\n",
      "aten::baddbmm_\n",
      "mkldnn::_reorder_mkldnn_rnn_layer_weight\n",
      "aten::upsample_trilinear3d_backward.grad_input\n",
      "aten::adaptive_max_pool3d_backward\n",
      "aten::huber_loss_backward.out\n",
      "aten::_softmax_backward_data\n",
      "aten::_foreach_zero_\n",
      "aten::huber_loss\n",
      "aten::upsample_linear1d\n",
      "aten::div_.Tensor\n",
      "aten::is_set_to\n",
      "aten::erfc.out\n",
      "aten::special_scaled_modified_bessel_k1\n",
      "aten::digamma\n",
      "quantized::linear_prepack_fp16_legacy\n",
      "aten::all.dim\n",
      "aten::_foreach_floor_\n",
      "aten::lerp.Scalar\n",
      "aten::_prelu_kernel_backward\n",
      "aten::index_fill_.int_Tensor\n",
      "aten::special_chebyshev_polynomial_w.out\n",
      "aten::digamma.out\n",
      "aten::_foreach_pow.ScalarAndTensor\n",
      "aten::special_bessel_y1\n",
      "aten::multinomial\n",
      "aten::reflection_pad1d.out\n",
      "aten::reflection_pad2d_backward.grad_input\n",
      "aten::floor.out\n",
      "aten::special_shifted_chebyshev_polynomial_t.out\n",
      "aten::erfc\n",
      "aten::_foreach_atan_\n",
      "aten::le_.Tensor\n",
      "aten::linalg_inv_ex\n",
      "aten::lerp.Scalar_out\n",
      "aten::special_airy_ai\n",
      "aten::_foreach_expm1\n",
      "aten::_aminmax.dim\n",
      "aten::_foreach_lerp_.Scalar\n",
      "aten::_to_sparse_csc\n",
      "aten::eq_.Scalar\n",
      "aten::relu_\n",
      "aten::logit_backward\n",
      "aten::_foreach_pow.ScalarList\n",
      "aten::rsub.Tensor\n",
      "aten::log_\n",
      "aten::special_bessel_y1.out\n",
      "aten::multi_margin_loss_backward\n",
      "aten::_histogramdd_from_bin_cts\n",
      "aten::__rshift__.Scalar\n",
      "aten::col2im.out\n",
      "aten::special_spherical_bessel_j0\n",
      "aten::round_\n",
      "aten::atan\n",
      "aten::logit_\n",
      "aten::cos\n",
      "aten::special_hermite_polynomial_h.out\n",
      "aten::avg_pool3d\n",
      "aten::div_.Tensor_mode\n",
      "aten::_foreach_log1p_\n",
      "aten::mish\n",
      "aten::smooth_l1_loss_backward.grad_input\n",
      "aten::log2\n",
      "aten::quantized_gru.data\n",
      "aten::special_zeta.out\n",
      "aten::sgn.out\n",
      "aten::normal.Tensor_Tensor_out\n",
      "aten::i0_\n",
      "aten::heaviside\n",
      "aten::max_pool3d_with_indices.out\n",
      "aten::addbmm_\n",
      "aten::_stack.out\n",
      "aten::_reshape_alias\n",
      "aten::_ctc_loss_backward\n",
      "aten::upsample_nearest2d_backward.grad_input\n",
      "aten::_foreach_reciprocal_\n",
      "aten::replication_pad1d_backward.grad_input\n",
      "aten::max_pool2d_with_indices.out\n",
      "aten::_embedding_bag_dense_backward\n",
      "aten::var.correction\n",
      "aten::fmin\n",
      "aten::hardsigmoid_backward.grad_input\n",
      "quantized::linear_relu_dynamic\n",
      "aten::nan_to_num.out\n",
      "aten::renorm\n",
      "aten::multi_margin_loss.out\n",
      "aten::_masked_softmax_backward\n",
      "aten::quantize_per_tensor_dynamic\n",
      "aten::elu\n",
      "aten::special_chebyshev_polynomial_u.out\n",
      "aten::searchsorted.Tensor\n",
      "aten::ceil.out\n",
      "aten::_foreach_clamp_min_.List\n",
      "aten::_foreach_addcmul_.Tensor\n",
      "aten::clamp_max.Tensor\n",
      "mkldnn::_linear_pointwise\n",
      "aten::linalg_lu_factor_ex.out\n",
      "aten::addcmul.out\n",
      "aten::scatter.src\n",
      "aten::prod\n",
      "aten::log_sigmoid_backward\n",
      "aten::mish_\n",
      "aten::_foreach_minimum_.ScalarList\n",
      "aten::ne.Scalar\n",
      "aten::_cummax_helper\n",
      "aten::frac_\n",
      "aten::sigmoid_backward\n",
      "aten::rsqrt\n",
      "aten::_foreach_asin\n",
      "aten::special_chebyshev_polynomial_u\n",
      "aten::_foreach_clamp_min_.ScalarList\n",
      "aten::_fused_moving_avg_obs_fq_helper\n",
      "aten::igammac.out\n",
      "aten::nansum\n",
      "aten::fractional_max_pool3d.output\n",
      "aten::max_unpool3d.out\n",
      "aten::_sample_dirichlet\n",
      "aten::leaky_relu_backward\n",
      "aten::addr\n",
      "aten::_fake_quantize_learnable_per_channel_affine_backward\n",
      "aten::lu_unpack\n",
      "aten::adaptive_max_pool3d_backward.grad_input\n",
      "aten::linspace.out\n",
      "aten::sigmoid\n",
      "aten::sign.out\n",
      "quantized::quantized_rnn_tanh_cell_dynamic\n",
      "aten::to_mkldnn\n",
      "aten::special_i1e\n",
      "aten::_foreach_frac_\n",
      "aten::searchsorted.Tensor_out\n",
      "aten::signbit\n",
      "aten::avg_pool3d_backward.grad_input\n",
      "aten::linalg_inv_ex.inverse\n",
      "aten::_compute_linear_combination.out\n",
      "aten::erfinv.out\n",
      "aten::ormqr\n",
      "aten::special_bessel_j1.out\n",
      "aten::_foreach_sub_.Scalar\n",
      "aten::eye.m_out\n",
      "aten::replication_pad2d_backward\n",
      "aten::lt.Scalar\n",
      "aten::addcdiv_\n",
      "aten::gather\n",
      "aten::log2_\n",
      "aten::avg_pool2d\n",
      "aten::linalg_cholesky_ex.L\n",
      "aten::linalg_lu\n",
      "aten::var_mean.correction\n",
      "aten::multilabel_margin_loss_backward.grad_input\n",
      "aten::log10\n",
      "aten::_log_softmax.out\n",
      "aten::_upsample_bicubic2d_aa_backward.grad_input\n",
      "aten::nonzero.out\n",
      "quantized::make_quantized_cell_params_dynamic\n",
      "aten::exp2\n",
      "mkldnn::_convolution_pointwise_.binary\n",
      "aten::isneginf.out\n",
      "aten::_foreach_pow_.List\n",
      "aten::_foreach_neg\n",
      "aten::upsample_nearest3d\n",
      "aten::searchsorted.Scalar\n",
      "aten::_foreach_erf_\n",
      "aten::_validate_compressed_sparse_indices\n",
      "aten::isneginf\n",
      "aten::_fake_quantize_learnable_per_tensor_affine\n",
      "aten::scatter_.value\n",
      "aten::linalg_ldl_factor_ex\n",
      "aten::gt.Tensor\n",
      "aten::igammac_\n",
      "aten::angle\n",
      "aten::amin.out\n",
      "aten::native_batch_norm_backward\n",
      "aten::_linalg_det\n",
      "aten::_foreach_maximum_.List\n",
      "aten::softplus\n",
      "aten::bitwise_and.Tensor\n",
      "aten::silu.out\n",
      "aten::_foreach_add.List\n",
      "aten::_foreach_sigmoid\n",
      "aten::_foreach_addcmul.ScalarList\n",
      "aten::_foreach_minimum_.Scalar\n",
      "aten::_linalg_solve_ex.result\n",
      "aten::erfc_\n",
      "aten::_foreach_erfc\n",
      "aten::_native_batch_norm_legit.no_stats_out\n",
      "aten::fractional_max_pool3d\n",
      "aten::replication_pad2d\n",
      "aten::hypot\n",
      "aten::upsample_bicubic2d\n",
      "aten::_foreach_div_.Scalar\n",
      "aten::_slow_conv2d_backward.grad_input\n",
      "aten::empty_strided\n",
      "aten::gelu.out\n",
      "aten::nonzero\n",
      "aten::exponential_\n",
      "aten::special_shifted_chebyshev_polynomial_t\n",
      "aten::var.correction_out\n",
      "aten::_nested_tensor_from_mask\n",
      "quantized::embedding_bag_byte_rowwise_offsets\n",
      "aten::special_modified_bessel_i0\n",
      "aten::normal.float_Tensor_out\n",
      "aten::atanh_\n",
      "aten::_add_relu_.Tensor\n",
      "aten::_addmm_activation\n",
      "aten::adaptive_max_pool2d_backward\n",
      "aten::lcm_\n",
      "aten::binary_cross_entropy_backward\n",
      "aten::ne_.Scalar\n",
      "aten::mse_loss_backward\n",
      "aten::leaky_relu\n",
      "aten::_foreach_div.ScalarList\n",
      "aten::special_i1e.out\n",
      "aten::fmax\n",
      "aten::sum.IntList_out\n",
      "aten::clamp_min_\n",
      "aten::_foreach_pow.List\n",
      "aten::any.dim\n",
      "aten::masked_select\n",
      "aten::trace\n",
      "aten::_foreach_ceil\n",
      "aten::norm.out\n",
      "aten::minimum\n",
      "aten::_foreach_mul_.List\n",
      "aten::elu.out\n",
      "aten::_aminmax\n",
      "aten::any.all_out\n",
      "quantized::conv_transpose3d_dynamic\n",
      "aten::__lshift__.Tensor\n",
      "aten::igamma_\n",
      "aten::lcm\n",
      "aten::cholesky_inverse.out\n",
      "aten::ceil_\n",
      "aten::pixel_unshuffle\n",
      "aten::_foreach_cosh_\n",
      "aten::nextafter.out\n",
      "aten::upsample_bicubic2d_backward.grad_input\n",
      "aten::_logcumsumexp\n",
      "aten::_foreach_add_.List\n",
      "aten::ne_.Tensor\n",
      "aten::unfold_backward\n",
      "aten::tril_indices\n",
      "prepacked::conv2d_clamp_run\n",
      "aten::native_group_norm\n",
      "aten::_foreach_clamp_max.ScalarList\n",
      "quantized::embedding_bag_byte\n",
      "aten::unique_dim\n",
      "aten::silu_\n",
      "aten::upsample_bilinear2d\n",
      "aten::_to_sparse.sparse_dim\n",
      "aten::normal.Tensor_float_out\n",
      "aten::all\n",
      "aten::masked_fill_.Scalar\n",
      "aten::_foreach_add.ScalarList\n",
      "aten::normal.float_Tensor\n",
      "aten::all.out\n",
      "aten::empty.memory_format\n",
      "aten::special_shifted_chebyshev_polynomial_w\n",
      "aten::_adaptive_avg_pool3d\n",
      "aten::pow.Tensor_Tensor\n",
      "aten::_foreach_trunc\n",
      "aten::std.correction\n",
      "aten::_foreach_div.List\n",
      "aten::_linalg_svd\n",
      "aten::_foreach_add_.Scalar\n",
      "aten::equal\n",
      "aten::special_scaled_modified_bessel_k1.out\n",
      "aten::slow_conv_transpose3d\n",
      "c10d::gather_\n",
      "aten::logical_or.out\n",
      "aten::norm.ScalarOpt_dim\n",
      "aten::nextafter\n",
      "aten::sqrt_\n",
      "aten::baddbmm.out\n",
      "aten::lerp.Tensor_out\n",
      "aten::_upsample_nearest_exact1d.out\n",
      "aten::neg_\n",
      "aten::triu\n",
      "aten::_native_batch_norm_legit.out\n",
      "aten::special_xlog1py\n",
      "aten::reflection_pad1d_backward\n",
      "aten::renorm_\n",
      "aten::special_ndtri\n",
      "aten::sub.Tensor\n",
      "aten::where.self\n",
      "aten::special_log_ndtr.out\n",
      "aten::_ctc_loss_backward.Tensor\n",
      "aten::quantized_lstm.data\n",
      "aten::_foreach_addcmul_.Scalar\n",
      "aten::log1p\n",
      "aten::adaptive_max_pool3d\n",
      "aten::hardtanh_backward\n",
      "aten::special_hermite_polynomial_he\n",
      "aten::_test_optional_intlist\n",
      "aten::exp2_\n",
      "aten::__ilshift__.Scalar\n",
      "aten::any.out\n",
      "aten::take\n",
      "aten::addmv_\n",
      "aten::special_zeta\n",
      "aten::adaptive_max_pool2d\n",
      "aten::cat.out\n",
      "aten::reflection_pad3d_backward.grad_input\n",
      "aten::special_scaled_modified_bessel_k0.out\n",
      "aten::argmin\n",
      "aten::slow_conv3d_forward\n",
      "aten::eq.Tensor\n",
      "aten::fmod_.Tensor\n",
      "aten::glu_backward.grad_input\n",
      "aten::_upsample_nearest_exact3d_backward\n",
      "aten::_transformer_encoder_layer_fwd\n",
      "aten::max_unpool2d.out\n",
      "aten::native_dropout_backward\n",
      "aten::_add_relu.Tensor\n",
      "aten::fmax.out\n",
      "aten::index_fill_.int_Scalar\n",
      "aten::geometric_\n",
      "aten::index_copy\n",
      "aten::ne.Tensor_out\n",
      "aten::_test_optional_floatlist\n",
      "aten::_to_sparse_bsc\n",
      "aten::pixel_shuffle\n",
      "aten::fractional_max_pool2d\n",
      "aten::_embedding_bag_per_sample_weights_backward\n",
      "quantization::_FloatToBfloat16Quantized\n",
      "aten::_convert_indices_from_coo_to_csr.out\n",
      "aten::scatter_.src\n",
      "aten::index_add_\n",
      "aten::special_bessel_j0\n",
      "aten::sinc\n",
      "aten::igamma.out\n",
      "aten::_foreach_exp_\n",
      "aten::nll_loss_backward\n",
      "aten::clamp_max\n",
      "aten::col2im\n",
      "aten::_linalg_slogdet.sign\n",
      "aten::_foreach_ceil_\n",
      "aten::linalg_vector_norm\n",
      "aten::_upsample_nearest_exact3d_backward.grad_input\n",
      "aten::xlogy.OutTensor\n",
      "aten::upsample_nearest1d\n",
      "aten::_empty_per_channel_affine_quantized\n",
      "aten::_convert_indices_from_csr_to_coo\n",
      "aten::threshold_\n",
      "aten::_foreach_sign\n",
      "aten::cholesky.out\n",
      "aten::elu_backward.grad_input\n",
      "aten::_embedding_bag\n",
      "aten::hypot_\n",
      "aten::min\n",
      "aten::addcmul_\n",
      "aten::angle.out\n",
      "aten::sigmoid_backward.grad_input\n",
      "mkldnn::_reorder_convolution_weight\n",
      "aten::_foreach_addcdiv.Tensor\n",
      "aten::range.out\n",
      "aten::trunc\n",
      "aten::clamp.Tensor_out\n",
      "aten::set_\n",
      "aten::_upsample_nearest_exact1d\n",
      "aten::mode\n",
      "aten::scatter_reduce.two\n",
      "quantized::embedding_bag_4bit\n",
      "aten::_unique\n",
      "aten::addr.out\n",
      "aten::adaptive_avg_pool3d_backward.grad_input\n",
      "aten::dense_dim\n",
      "quantized::embedding_4bit\n",
      "aten::silu_backward\n",
      "aten::maximum.out\n",
      "aten::grid_sampler_2d_backward\n",
      "aten::triangular_solve\n",
      "aten::_foreach_sub_.ScalarList\n",
      "c10d::recv_\n",
      "aten::cosh\n",
      "aten::sort.stable\n",
      "aten::special_shifted_chebyshev_polynomial_w.out\n",
      "aten::_index_put_impl_\n",
      "aten::logaddexp\n",
      "aten::_fused_sdp_choice\n",
      "aten::softshrink_backward.grad_input\n",
      "aten::nll_loss2d_backward\n",
      "aten::grid_sampler_3d\n",
      "aten::roll\n",
      "aten::fill_.Tensor\n",
      "aten::embedding_renorm_\n",
      "aten::bitwise_right_shift.Tensor\n",
      "aten::upsample_nearest1d_backward\n",
      "aten::_foreach_log1p\n",
      "aten::upsample_nearest3d_backward\n",
      "aten::logaddexp2.out\n",
      "aten::erfinv_\n",
      "aten::le.Scalar\n",
      "aten::special_log_ndtr\n",
      "aten::round.decimals\n",
      "aten::addmm.out\n",
      "aten::hardsigmoid_\n",
      "aten::gt.Scalar\n",
      "_quantized::linear_prepack_fp16_legacy\n",
      "aten::argmin.out\n",
      "aten::_foreach_addcdiv_.Tensor\n",
      "aten::nonzero_static\n",
      "c10d::alltoall_base_\n",
      "aten::ge_.Scalar\n",
      "aten::ne.Tensor\n",
      "aten::_cholesky_solve_helper\n",
      "aten::bitwise_right_shift_.Tensor\n",
      "aten::le.Scalar_out\n",
      "quantized::make_quantized_cell_params\n",
      "mkldnn::_reorder_convolution_transpose_weight\n",
      "aten::max.dim_max\n",
      "aten::acos.out\n",
      "aten::replication_pad1d_backward\n",
      "aten::special_chebyshev_polynomial_v\n",
      "aten::log.out\n",
      "c10d::broadcast_\n",
      "aten::log1p.out\n",
      "aten::searchsorted.Scalar_out\n",
      "aten::remainder.Tensor\n",
      "aten::sort.values_stable\n",
      "c10d::alltoall_\n",
      "aten::_make_dep_token\n",
      "aten::cosh.out\n",
      "aten::amax.out\n",
      "aten::_foreach_cos\n",
      "aten::mvlgamma.out\n",
      "aten::atan.out\n",
      "aten::special_hermite_polynomial_he.out\n",
      "aten::_foreach_minimum.List\n",
      "aten::_foreach_sigmoid_\n",
      "aten::normal.Tensor_float\n",
      "aten::nll_loss2d_forward\n",
      "aten::cauchy_\n",
      "aten::upsample_trilinear3d_backward\n",
      "aten::bitwise_right_shift.Tensor_out\n",
      "aten::median.dim_values\n",
      "aten::linalg_householder_product\n",
      "aten::ceil\n",
      "aten::_foreach_neg_\n",
      "aten::upsample_linear1d_backward.grad_input\n",
      "quantized::linear_dynamic\n",
      "aten::flip\n",
      "onednn::qconv_prepack\n",
      "quantized::embedding_bag_4bit_unpack\n",
      "aten::special_modified_bessel_k1.out\n",
      "aten::acos\n",
      "aten::add.out\n",
      "aten::nll_loss_forward\n",
      "aten::special_chebyshev_polynomial_v.out\n",
      "aten::asin\n",
      "aten::argsort.stable\n",
      "aten::slow_conv_dilated3d\n",
      "aten::_foreach_log2\n",
      "aten::isnan\n",
      "aten::i0\n",
      "aten::softshrink_backward\n",
      "aten::_foreach_clamp_max.List\n",
      "aten::_foreach_tan_\n",
      "aten::cos_\n",
      "aten::hardswish\n",
      "aten::neg\n",
      "aten::_foreach_abs_\n",
      "aten::upsample_nearest3d_backward.grad_input\n",
      "aten::multinomial.out\n",
      "aten::round.out\n",
      "aten::adaptive_max_pool3d.out\n",
      "aten::cumprod\n",
      "aten::linalg_qr.out\n",
      "aten::sinh\n",
      "aten::sspaddmm.out\n",
      "aten::_native_batch_norm_legit\n",
      "c10d::allgather_\n",
      "aten::nonzero_static.out\n",
      "aten::max_unpool3d\n",
      "aten::logical_not.out\n",
      "aten::set_.source_Storage_storage_offset\n",
      "aten::multilabel_margin_loss_forward.output\n",
      "aten::addmv\n",
      "aten::isin.Tensor_Tensor_out\n",
      "aten::div.Tensor\n",
      "c10d::allreduce_\n",
      "aten::replication_pad2d_backward.grad_input\n",
      "aten::uniform_\n",
      "aten::upsample_linear1d_backward\n",
      "aten::set_.source_Tensor\n",
      "aten::tanh_\n",
      "aten::clamp_min.out\n",
      "aten::random_.from\n",
      "aten::_slow_conv2d_forward\n",
      "aten::_linalg_det.result\n",
      "aten::_foreach_mul.Tensor\n",
      "aten::index_reduce.out\n",
      "aten::quantize_per_tensor.tensor_qparams\n",
      "aten::_foreach_round_\n",
      "aten::ge.Scalar_out\n",
      "aten::eq.Scalar\n",
      "aten::_upsample_bicubic2d_aa.out\n",
      "aten::_spdiags\n",
      "aten::tan_\n",
      "aten::_foreach_lerp.Scalar\n",
      "aten::relu\n",
      "aten::glu_jvp\n",
      "aten::_upsample_bilinear2d_aa\n",
      "aten::clamp_max_.Tensor\n",
      "aten::fractional_max_pool3d_backward\n",
      "aten::smooth_l1_loss\n",
      "aten::_softmax.out\n",
      "aten::avg_pool2d_backward\n",
      "prepacked::linear_clamp_prepack\n",
      "aten::_masked_softmax\n",
      "aten::mkldnn_rnn_layer\n",
      "aten::fractional_max_pool2d_backward\n",
      "aten::erf\n",
      "_quantized::linear_dynamic\n",
      "aten::gelu_backward\n",
      "aten::_native_batch_norm_legit.no_stats\n",
      "aten::sinc.out\n",
      "aten::scatter_.reduce\n",
      "aten::hardshrink_backward\n",
      "aten::abs.out\n",
      "aten::glu.out\n",
      "aten::fmin.out\n",
      "aten::binary_cross_entropy\n",
      "aten::avg_pool2d.out\n",
      "aten::sgn_\n",
      "aten::reflection_pad1d\n",
      "aten::special_bessel_j1\n",
      "aten::minimum.out\n",
      "aten::atan_\n",
      "aten::floor_\n",
      "aten::lerp_.Scalar\n",
      "aten::mean.dim\n",
      "aten::gather.out\n",
      "aten::max_unpool2d\n",
      "aten::_foreach_addcdiv_.ScalarList\n",
      "aten::logspace.out\n",
      "aten::fractional_max_pool2d_backward.grad_input\n",
      "aten::special_i0e.out\n",
      "aten::special_modified_bessel_k1\n",
      "aten::softplus_backward\n",
      "aten::_histogramdd_bin_edges\n",
      "aten::avg_pool3d_backward\n",
      "aten::softshrink.out\n",
      "aten::elu_backward\n",
      "aten::unique_consecutive\n",
      "prepacked::linear_clamp_run\n",
      "aten::embedding_dense_backward\n",
      "aten::prod.int_out\n",
      "aten::put_\n",
      "aten::argmax\n",
      "aten::_local_scalar_dense\n",
      "aten::upsample_nearest2d.out\n",
      "aten::log1p_\n",
      "aten::slow_conv_transpose3d.out\n",
      "aten::multi_margin_loss\n",
      "aten::eq.Tensor_out\n",
      "aten::pow_.Scalar\n",
      "aten::_scaled_dot_product_flash_attention_backward\n",
      "aten::sub_.Tensor\n",
      "aten::nll_loss2d_backward.grad_input\n",
      "aten::erf.out\n",
      "aten::upsample_linear1d.out\n",
      "aten::frac\n",
      "aten::_assert_async\n",
      "aten::log10_\n",
      "aten::_foreach_add_.ScalarList\n",
      "aten::arange.start_out\n",
      "aten::_ctc_loss\n",
      "aten::reciprocal\n",
      "aten::rsqrt_\n",
      "aten::linalg_lu_solve.out\n",
      "c10d::recv_any_source_\n",
      "aten::fake_quantize_per_tensor_affine_cachemask\n",
      "aten::copysign_.Tensor\n",
      "aten::multilabel_margin_loss_backward\n",
      "aten::_foreach_atan\n",
      "aten::_foreach_cosh\n",
      "aten::scatter.src_out\n",
      "aten::bucketize.Scalar\n",
      "aten::tanh\n",
      "aten::linalg_householder_product.out\n",
      "aten::linalg_lu_solve\n",
      "aten::isin.Tensor_Scalar_out\n",
      "aten::heaviside_\n",
      "aten::view_as_real\n",
      "aten::view\n",
      "aten::_foreach_mul_.ScalarList\n",
      "aten::bitwise_xor.Tensor_out\n",
      "aten::log10.out\n",
      "aten::nanmedian.dim_values\n",
      "aten::special_bessel_y0.out\n",
      "aten::bucketize.Tensor_out\n",
      "aten::max.dim\n",
      "aten::_nested_view_from_buffer\n",
      "aten::_slow_conv2d_backward.output_mask\n",
      "aten::linalg_eig\n",
      "aten::_foreach_clamp_max_.List\n",
      "aten::special_erfcx.out\n",
      "aten::_weight_norm_interface_backward\n",
      "aten::hardtanh_\n",
      "aten::_upsample_nearest_exact2d_backward.grad_input\n",
      "aten::bitwise_not\n",
      "aten::isposinf\n",
      "aten::smooth_l1_loss.out\n",
      "aten::sigmoid.out\n",
      "quantized::linear_relu_dynamic_fp16\n",
      "aten::le_.Scalar\n",
      "c10d::allgather_coalesced_\n",
      "aten::special_modified_bessel_k0.out\n",
      "mkldnn::_reorder_linear_weight\n",
      "aten::replication_pad1d.out\n",
      "quantized::embedding_bag_4bit_rowwise_offsets\n",
      "aten::set_.source_Storage\n",
      "aten::_foreach_clamp_max.Scalar\n",
      "aten::reciprocal.out\n",
      "c10d::barrier\n",
      "aten::scatter.value_reduce_out\n",
      "aten::_addmm_activation.out\n",
      "aten::clamp_max.Tensor_out\n",
      "aten::histogram.bin_ct\n",
      "aten::floor\n",
      "quantized::max_pool2d\n",
      "aten::_unsafe_index.Tensor\n",
      "aten::_foreach_exp\n",
      "aten::quantized_gru.input\n",
      "aten::clamp.out\n",
      "_inductor_test::realize\n",
      "aten::_fft_c2r\n",
      "aten::_softmax_backward_data.out\n",
      "aten::mm\n",
      "mkldnn::_convolution_transpose_pointwise\n",
      "aten::_convert_indices_from_coo_to_csr\n",
      "aten::_foreach_sub.Scalar\n",
      "aten::threshold_backward.grad_input\n",
      "aten::adaptive_avg_pool2d.out\n",
      "c10d::send\n",
      "aten::bitwise_left_shift_.Tensor\n",
      "aten::_foreach_expm1_\n",
      "aten::clamp_max.out\n",
      "aten::special_bessel_j0.out\n",
      "aten::__ilshift__.Tensor\n",
      "quantization::_Bfloat16QuantizedToFloat\n",
      "aten::cumsum\n",
      "aten::_upsample_nearest_exact1d_backward.grad_input\n",
      "aten::cat\n",
      "quantized::embedding_bag_2bit_prepack\n",
      "aten::native_layer_norm_backward\n",
      "aten::where.self_out\n",
      "aten::_foreach_clamp_max_.Scalar\n",
      "aten::softplus.out\n",
      "aten::bitwise_not.out\n",
      "aten::rsqrt.out\n",
      "aten::fractional_max_pool2d.output\n",
      "aten::_foreach_addcmul.Tensor\n",
      "aten::_dirichlet_grad\n",
      "aten::_foreach_erf\n",
      "aten::_prelu_kernel\n",
      "aten::histogram.bin_ct_out\n",
      "aten::expm1.out\n",
      "aten::bitwise_xor.Tensor\n",
      "aten::_linalg_eigh.eigenvalues\n",
      "aten::histogram.bins_tensor_out\n",
      "aten::_foreach_trunc_\n",
      "aten::bernoulli_.float\n",
      "aten::clamp_min\n",
      "aten::_foreach_sinh_\n",
      "aten::scatter.reduce_out\n",
      "aten::histc\n",
      "aten::special_shifted_chebyshev_polynomial_u.out\n",
      "aten::_foreach_addcmul_.ScalarList\n",
      "aten::heaviside.out\n",
      "aten::tril.out\n",
      "aten::_foreach_addcmul.Scalar\n",
      "aten::native_batch_norm.out\n",
      "aten::normal.Tensor_Tensor\n",
      "aten::log_normal_\n",
      "aten::cumsum.out\n",
      "quantized::linear_unpack.legacy\n",
      "aten::kthvalue.values\n",
      "aten::topk.values\n",
      "aten::_to_sparse_csr\n",
      "aten::upsample_bilinear2d_backward.grad_input\n",
      "aten::floor_divide.out\n",
      "aten::_foreach_lerp.List\n",
      "aten::hardshrink_backward.grad_input\n",
      "aten::_foreach_maximum_.ScalarList\n",
      "aten::linalg_cross\n",
      "aten::replication_pad3d_backward.grad_input\n",
      "aten::_foreach_div.Scalar\n",
      "aten::sqrt\n",
      "aten::index_reduce_\n",
      "aten::logaddexp.out\n",
      "aten::sigmoid_\n",
      "quantized::linear_unpack_fp16.legacy\n",
      "aten::_foreach_clamp_max_.ScalarList\n",
      "aten::expm1\n",
      "aten::addbmm\n",
      "aten::binary_cross_entropy_backward.grad_input\n",
      "aten::special_i1.out\n",
      "aten::div.out_mode\n",
      "aten::special_laguerre_polynomial_l\n",
      "aten::_log_softmax\n",
      "aten::asin_\n",
      "aten::logical_xor.out\n",
      "aten::_standard_gamma\n",
      "aten::upsample_bicubic2d_backward\n",
      "aten::histogram.bins_tensor\n",
      "aten::gelu_\n",
      "aten::mm.out\n",
      "aten::bmm.out\n",
      "mkl::_mkl_reorder_linear_weight\n",
      "aten::special_legendre_polynomial_p.out\n",
      "aten::bmm\n",
      "onednn::qlinear_prepack\n",
      "aten::native_group_norm_backward\n",
      "aten::special_legendre_polynomial_p\n",
      "aten::bitwise_or_.Tensor\n",
      "aten::_upsample_nearest_exact2d.out\n",
      "aten::linalg_lu.out\n",
      "quantized::linear_with_input_q_dq_qweight_dq_output_fp32\n",
      "quantized::conv1d_dynamic\n",
      "aten::unfold\n",
      "aten::hypot.out\n",
      "quantized::quantized_lstm_cell_dynamic\n",
      "aten::logit\n",
      "aten::max_pool2d_with_indices_backward.grad_input\n",
      "prepacked::conv2d_clamp_prepack\n",
      "aten::vdot\n",
      "aten::_histogramdd_from_bin_tensors\n",
      "aten::_foreach_tan\n",
      "aten::remainder_.Tensor\n",
      "aten::index_add\n",
      "aten::all.all_out\n",
      "aten::scatter_reduce_.two\n",
      "aten::im2col.out\n"
     ]
    }
   ],
   "source": [
    "# Verify if the op was successfully registered - \n",
    "# List all registered operators for the CPU backend\n",
    "torch._C._dispatch_print_registrations_for_dispatch_key(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Test your custom operator\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "result = torch.ops.scale_custom_op.scale_by_max(x)\n",
    "print(result)  # Output: tensor([3.0, 6.0, 9.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaWithCustomOp(nn.Module):\n",
    "    def __init__(self, llama_model_name: str, output_dim: int):\n",
    "        super(LlamaWithCustomOp, self).__init__()\n",
    "\n",
    "        # Load the LLaMA model\n",
    "        full_llama = AutoModel.from_pretrained(llama_model_name)\n",
    "\n",
    "        # Extract and store the embedding layer\n",
    "        self.embed_tokens = full_llama.embed_tokens\n",
    "\n",
    "        # Extract and store the first decoder layer\n",
    "        self.first_layer = full_llama.layers[0]\n",
    "\n",
    "        # Linear layer to map to output dimensions\n",
    "        llama_hidden_dim = full_llama.config.hidden_size\n",
    "        self.linear = nn.Linear(llama_hidden_dim, output_dim)\n",
    "\n",
    "        # Softmax for output probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Explicit typing of input_ids and attention_mask for TorchScript\n",
    "    def forward(self, input_ids, custom_forward_fn=None):\n",
    "        # Generate embeddings\n",
    "        embeddings = self.embed_tokens(input_ids)\n",
    "\n",
    "        # Check if position_ids need to be explicitly handled\n",
    "        position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Pass through the first layer with position_ids\n",
    "        layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
    "\n",
    "        # Pool the output (mean along sequence dimension)\n",
    "        pooled_output = torch.mean(layer_output, dim=1)\n",
    "\n",
    "        # Map to output dimension\n",
    "        logits = self.linear(pooled_output)\n",
    "\n",
    "        if custom_forward_fn is not None:\n",
    "            # Apply the custom operation\n",
    "            custom_logits = custom_forward_fn(logits)\n",
    "        else:\n",
    "            custom_logits = logits\n",
    "\n",
    "        # Apply softmax\n",
    "        probs = self.softmax(custom_logits)\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:22:37,729] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:37,730] [15/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:22:37,731] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:22:37,731] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:22:37,731] [15/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:22:37,732] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,732] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:22:37,732] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:22:37,733] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,733] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,733] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,733] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,734] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,734] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:22:37,734] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:22:37,734] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,736] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:22:37,736] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:22:37,736] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:22:37,737] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,737] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,737] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:37,737] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,737] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:22:37,738] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:37,738] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,738] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,739] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,739] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:22:37,739] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:22:37,739] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:22:37,740] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:22:37,740] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:22:37,740] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:22:37,740] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,741] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:22:37,742] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:37,743] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:22:37,743] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:22:37,743] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:22:37,743] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,744] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,744] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,744] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,744] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,745] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,748] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,749] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:37,749] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,749] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,750] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,751] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,751] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,751] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,751] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,751] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,752] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,752] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,752] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,752] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,753] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,753] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,753] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,753] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,754] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,754] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,754] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,754] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,755] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,756] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,757] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:37,758] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,759] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:37,759] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,759] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,759] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,761] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:22:37,762] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,762] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,762] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:22:37,762] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,763] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:22:37,763] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,763] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:37,763] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,763] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:37,764] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,765] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,767] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,767] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:37,768] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,768] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,768] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:37,768] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,768] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,769] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:37,769] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,769] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,769] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,770] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,771] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,771] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,771] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,771] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,772] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,772] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,772] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,772] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,773] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,773] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,773] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,773] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,773] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,774] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,775] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,776] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,777] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:37,778] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,778] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:37,778] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,778] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,779] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,779] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,779] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,779] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,780] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:37,780] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,780] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:22:37,781] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,781] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,781] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:22:37,781] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,782] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:22:37,783] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,783] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,783] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:37,784] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,784] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:22:37,785] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:37,786] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,786] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:37,787] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:37,787] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,787] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:37,787] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,788] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,788] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,788] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,789] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,789] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:22:37,790] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:22:37,790] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,791] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,791] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,791] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,791] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:37,792] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:22:37,793] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:22:37,793] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,793] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,794] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,794] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,795] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,795] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,795] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,796] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:22:37,796] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,796] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,797] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,797] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:22:37,798] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,798] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:37,798] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,799] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,799] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:37,800] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,800] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,800] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,802] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,802] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,803] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,803] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,803] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,804] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,805] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,805] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,805] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,806] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,807] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,807] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,807] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,807] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,808] [15/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:22:37,809] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,809] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,810] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,811] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,811] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,811] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,811] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,812] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:37,813] [15/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:37,813] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:37,813] [15/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:22:37,814] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,815] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,815] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,815] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:22:37,816] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,817] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:22:37,818] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,818] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,818] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:22:37,818] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,819] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,820] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:22:37,821] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:22:37,822] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:37,825] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,826] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,826] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:37,827] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,827] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,827] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,827] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,827] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,828] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,828] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,828] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,828] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,828] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,829] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,829] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,830] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,830] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,830] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,830] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,831] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,831] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,831] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,832] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,833] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,834] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,834] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,834] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,834] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,835] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,836] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,836] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,836] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,836] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,836] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:37,837] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,837] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:22:37,837] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,837] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,838] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,839] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:22:37,839] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,839] [15/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,840] [15/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:22:37,841] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,841] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:22:37,842] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:22:37,842] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:22:37,842] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:22:37,842] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:22:37,842] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:22:37,843] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:22:37,843] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,843] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,843] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:22:37,844] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:22:37,844] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:22:37,844] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:37,845] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:37,845] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:22:37,845] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,845] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,846] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,846] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,846] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:22:37,846] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,846] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,847] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:22:37,847] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,848] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,849] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,849] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,850] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,850] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,850] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,850] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,853] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,853] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,853] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,853] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,854] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,854] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,854] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,855] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,855] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,855] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,855] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,857] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,858] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,858] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,858] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,858] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,859] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,859] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,859] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,860] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,860] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,860] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,862] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,863] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,863] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,863] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:22:37,863] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:37,864] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:37,864] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,864] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,864] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,865] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,865] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,865] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,865] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,866] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,866] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,866] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,867] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:37,867] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,868] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:37,869] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,869] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,869] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,870] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:22:37,870] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:37,870] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:37,871] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,871] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,871] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,871] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,872] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,872] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,872] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,873] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,873] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,873] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,873] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:37,874] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:37,874] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,874] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,875] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,875] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,875] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,875] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:37,876] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,876] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,876] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,876] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:22:37,876] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:37,877] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:37,877] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,877] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,877] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,878] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,878] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,878] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,879] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,879] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,879] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,879] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,880] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:37,880] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:37,880] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,881] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,881] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,881] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,881] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,881] [15/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:37,882] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,882] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,882] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:22:37,882] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:22:37,882] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,883] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,883] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,883] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,883] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:37,883] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:22:37,884] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:22:37,885] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,885] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:22:37,885] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:22:37,885] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:22:37,885] [15/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:37,886] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:37,886] [15/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:37,886] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:37,886] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:37,887] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:22:37,888] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:22:37,888] [15/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:37,888] [15/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,888] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:37,888] [15/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:22:37,890] [15/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:37,891] [15/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_25 =====\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.213 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_25 <eval_with_key>.213 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:22:37,892] [15/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_25 =====\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:37,893] [15/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:37,896] [15/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:37,896] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:22:37,897] [15/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:22:37,897] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:22:37,898] [15/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:37,898] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:37,901] [15/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:37,901] [15/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:37,902] [15/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:37,902] [15/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:37,904] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:37,905] [16/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:22:37,906] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:22:37,906] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:22:37,906] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:37,907] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:22:37,909] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:37,910] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,910] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,910] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,910] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,911] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,911] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:22:37,911] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:37,911] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,911] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,913] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,913] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:37,914] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,914] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,914] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:37,914] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,915] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,915] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:37,915] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,916] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,916] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,916] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,917] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,917] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,918] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,918] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,918] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,918] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,918] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,919] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,919] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,920] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,920] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,920] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,920] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,921] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,921] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,921] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,921] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,921] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,922] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:37,923] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,923] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,923] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,923] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,923] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,924] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:37,925] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,926] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,927] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:22:37,928] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Explanation for custom_forward_fn=None ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:22:37,929] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,930] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:37,930] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:37,930] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,930] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:37,930] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,931] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,931] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,931] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,931] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,931] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,932] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:37,934] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:22:37,934] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:22:37,934] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:37,935] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,936] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:22:37,936] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,936] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,936] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:37,937] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:22:37,937] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,937] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:37,937] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,937] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,938] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:37,938] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,938] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,938] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,939] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,939] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:37,939] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,939] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,939] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,940] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,940] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,940] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:37,940] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,941] [16/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:22:37,942] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,942] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,943] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,944] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,944] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,944] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:37,944] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:37,945] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:37,945] [16/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:37,945] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:37,945] [16/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:22:37,946] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:22:37,947] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:22:37,948] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:22:37,949] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,950] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:37,950] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,950] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,950] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,951] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:22:37,952] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:22:37,953] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:37,955] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,955] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:37,955] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,956] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,956] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:37,956] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:37,956] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:37,956] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:37,957] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,957] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:37,957] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:37,957] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,957] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,958] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,959] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,960] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,961] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,962] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,963] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:22:37,964] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:37,964] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:37,964] [16/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,964] [16/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:22:37,966] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,966] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:22:37,966] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:22:37,966] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:22:37,967] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:22:37,967] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:22:37,967] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:22:37,967] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:22:37,967] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:37,968] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,968] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:22:37,968] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:22:37,968] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:22:37,968] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:37,969] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:37,969] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:22:37,969] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,969] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,969] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,970] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,970] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:22:37,970] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,970] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,970] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:22:37,971] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,971] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,971] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:37,971] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,971] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,972] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,972] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,972] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,972] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,973] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,973] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,973] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,973] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,979] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,980] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,980] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,980] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,980] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,981] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,987] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,988] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,988] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,988] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:37,988] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,989] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,989] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,989] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:37,990] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,990] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:37,990] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:37,994] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:37,995] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,995] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,995] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:22:37,995] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:37,996] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:37,996] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,996] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,996] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,997] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,998] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:37,998] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,998] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:37,999] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:22:37,999] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:37,999] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,000] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,001] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,001] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,001] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,002] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,002] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,002] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,002] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,003] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,003] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,003] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,003] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:22:38,004] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:38,004] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:38,004] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,004] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,004] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,005] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,005] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,005] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,005] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,006] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,006] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,006] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,007] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,007] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,007] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,008] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,008] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,008] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,008] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,008] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,009] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,009] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,009] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,009] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:22:38,009] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:38,010] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:38,010] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,010] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,010] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,011] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,012] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,012] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,012] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,013] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,013] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,013] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,013] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,013] [16/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,014] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,014] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,014] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:22:38,014] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:22:38,014] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:22:38,015] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,016] [16/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,017] [16/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:38,017] [16/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:22:38,018] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:22:38,018] [16/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:22:38,018] [16/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,018] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:38,019] [16/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:22:38,020] [16/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:38,021] [16/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_27 =====\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.214 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,022] [16/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_27 <eval_with_key>.214 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:22:38,023] [16/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_27 =====\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,024] [16/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,028] [16/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:38,028] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,028] [16/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,028] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,029] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,029] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,030] [16/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,030] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:22:38,031] [16/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,032] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,032] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,033] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,033] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,034] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:22:38,034] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,035] [16/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,036] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,036] [16/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,037] [16/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:22:38,037] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,037] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,038] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,038] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,038] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,039] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,039] [16/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,039] [16/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,040] [16/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,040] [16/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,046] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:38,049] [17/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:22:38,049] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:22:38,049] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:22:38,050] [17/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:38,052] [17/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:22:38,053] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:22:38,053] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:22:38,053] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:22:38,054] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:22:38,055] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:22:38,055] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:38,055] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:38,055] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:22:38,056] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,056] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,056] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,056] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:22:38,056] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:22:38,057] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,057] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,057] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:22:38,058] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,058] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,058] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,059] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:22:38,059] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,059] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,059] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,059] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,060] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,060] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,060] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:22:38,060] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,060] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,062] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,062] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:22:38,062] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,063] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,063] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,063] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,064] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,064] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,064] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:22:38,064] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,064] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,066] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,066] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:22:38,066] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,067] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,067] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,067] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,068] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,068] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,068] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:22:38,068] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,068] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,070] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,070] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:22:38,070] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,071] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:22:38,071] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:38,071] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:38,072] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,072] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,072] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,072] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,073] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,074] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,075] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,075] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,075] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,075] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,076] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:22:38,076] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,076] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:38,077] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:38,078] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,078] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,078] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,078] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,078] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,079] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,079] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,079] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:22:38,079] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,079] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,080] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,080] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,081] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,082] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,082] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:22:38,082] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,082] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:22:38,082] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:22:38,083] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:22:38,083] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,083] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,083] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,084] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,084] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,085] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,085] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,085] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:22:38,085] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,085] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,086] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,086] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,087] [17/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,088] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:22:38,089] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:38,090] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:22:38,090] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,091] [17/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:22:38,092] [17/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:22:38,092] [17/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:22:38,093] [17/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_29 =====\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.215 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_29 <eval_with_key>.215 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:22:38,094] [17/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_29 =====\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,095] [17/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:38,096] [17/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,096] [17/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,107] [17/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:38,107] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:22:38,108] [17/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:22:38,108] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,109] [17/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,109] [17/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,110] [17/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,110] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:22:38,111] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,111] [17/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,111] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,112] [17/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,112] [17/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:22:38,113] [17/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,113] [17/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,116] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:38,119] [18/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:22:38,120] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:22:38,120] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:22:38,121] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:22:38,122] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:22:38,124] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:22:38,126] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:22:38,127] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:38,128] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:22:38,128] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,128] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:22:38,128] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,129] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,129] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:22:38,129] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:22:38,129] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,129] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,130] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,130] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,130] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,130] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,131] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:22:38,131] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:22:38,131] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,131] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,135] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,135] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:38,135] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,135] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,135] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:38,136] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,136] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,136] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:38,137] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,137] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,137] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,138] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,138] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,138] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,138] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,138] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,139] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,139] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,139] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,139] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,140] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,140] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,140] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,140] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,141] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,142] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,143] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:38,144] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,145] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:38,145] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,145] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,145] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,146] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,146] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,146] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,147] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:22:38,147] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,147] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:22:38,147] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:22:38,147] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:22:38,148] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:22:38,149] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:22:38,149] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,149] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,149] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,150] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,150] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:22:38,150] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,150] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,151] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,151] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,151] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,152] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,152] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,152] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,152] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:22:38,153] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,154] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,155] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,155] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,155] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,155] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:22:38,155] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,156] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,156] [18/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:22:38,157] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,157] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,157] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,157] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:22:38,158] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,160] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:22:38,161] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,161] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,161] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,161] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:22:38,161] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:22:38,162] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:22:38,162] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:22:38,162] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:22:38,164] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:22:38,164] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,164] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:22:38,165] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,166] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,167] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,168] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,168] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,168] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,169] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,169] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:22:38,169] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,170] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,170] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:22:38,170] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,171] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:22:38,172] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,173] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,173] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,173] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:22:38,173] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:22:38,174] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:22:38,174] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,174] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:22:38,174] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:22:38,175] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:22:38,175] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:22:38,175] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,175] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,175] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:22:38,176] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:22:38,176] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:22:38,176] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,176] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:22:38,176] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:22:38,177] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,177] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:22:38,177] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,177] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,177] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:22:38,178] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,179] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,179] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:22:38,179] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:22:38,179] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,180] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,180] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,180] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:22:38,181] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:22:38,181] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,181] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,181] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,181] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,182] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,182] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,182] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,182] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,182] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:22:38,183] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,184] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,185] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,185] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:22:38,185] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,185] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,185] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:22:38,186] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,187] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,187] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,187] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,189] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,190] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,191] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,192] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,192] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:22:38,192] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,192] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,192] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,193] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,193] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,193] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:22:38,193] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,193] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,194] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,194] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,194] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:22:38,194] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,195] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,195] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,195] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:22:38,196] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,198] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:22:38,199] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:22:38,199] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,199] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:22:38,199] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:22:38,200] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,200] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,200] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:22:38,200] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,201] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,201] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,201] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,201] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,201] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:22:38,202] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,203] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:38,203] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,203] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:22:38,203] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,204] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:22:38,205] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,205] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:22:38,205] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:22:38,205] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:22:38,206] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,206] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:38,206] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,206] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:22:38,206] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,208] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:22:38,208] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,208] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:22:38,208] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:22:38,208] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:22:38,209] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:38,209] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:22:38,211] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,212] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,212] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,213] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,213] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:22:38,213] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,214] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:22:38,214] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,217] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:38,218] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:22:38,220] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,220] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,221] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,223] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:22:38,223] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:22:38,223] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,225] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,228] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,229] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:22:38,231] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,231] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:22:38,231] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,231] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:22:38,232] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,234] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,235] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,235] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,236] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,238] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,239] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:22:38,239] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,240] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,240] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,241] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,241] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:22:38,242] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:22:38,242] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:22:38,242] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:22:38,242] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:22:38,242] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,243] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,243] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,243] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,243] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,244] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,244] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:22:38,244] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:22:38,244] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,244] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:22:38,245] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,246] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,247] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:22:38,247] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,247] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,247] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:22:38,247] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,248] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,249] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:22:38,249] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,249] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,250] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:22:38,250] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:22:38,251] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,251] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,251] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,251] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:22:38,252] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:22:38,253] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,253] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,254] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,254] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,254] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,254] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:38,255] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,256] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:22:38,257] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:22:38,257] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:22:38,257] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,257] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:22:38,259] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:22:38,259] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,259] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,259] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,260] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,260] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:22:38,260] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,261] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,261] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,261] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,262] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:22:38,262] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,262] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,262] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:22:38,263] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:22:38,263] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:22:38,263] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:22:38,264] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:22:38,264] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,265] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,265] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,265] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,265] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,266] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:22:38,266] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,266] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,266] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,266] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,267] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:22:38,268] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,268] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,268] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,268] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,268] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,269] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,269] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,269] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,269] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:22:38,270] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,270] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,270] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,271] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,273] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,273] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:22:38,273] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,274] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,274] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,274] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,274] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:22:38,275] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,275] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,275] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,275] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:22:38,276] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,277] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,277] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,277] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:22:38,277] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:38,278] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,279] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:22:38,280] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:22:38,280] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:22:38,280] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,280] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:22:38,281] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:22:38,281] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,282] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,282] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,282] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,283] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:22:38,283] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,283] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,283] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,283] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,285] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:22:38,285] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,285] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,285] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:22:38,286] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:22:38,286] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:22:38,286] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:22:38,287] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:22:38,287] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,288] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,288] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,288] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,288] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,288] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:22:38,289] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,289] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,289] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,289] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,290] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:22:38,290] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,290] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,290] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,291] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,291] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,291] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,292] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,292] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,292] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:22:38,292] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,293] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,293] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:22:38,293] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,293] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,293] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,294] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,294] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,294] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,296] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:22:38,297] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,298] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,298] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,298] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,298] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:22:38,299] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,299] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:22:38,299] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:22:38,299] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:22:38,299] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,300] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,300] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:22:38,300] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,300] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,301] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,301] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:22:38,301] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:22:38,301] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:22:38,301] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,302] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,302] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,302] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:22:38,302] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:22:38,302] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:22:38,303] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,303] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,303] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,303] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,303] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,304] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:22:38,305] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,306] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:22:38,307] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:22:38,307] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,307] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,307] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,308] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,309] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,309] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,309] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,309] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,310] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,310] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,310] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:22:38,310] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,311] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,313] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:22:38,313] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:22:38,313] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,314] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,315] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,315] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,315] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,315] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,315] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:22:38,316] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:22:38,316] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,316] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,316] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,317] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,317] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,317] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,317] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,318] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,318] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,318] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,319] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,319] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:22:38,320] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,320] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:22:38,320] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:22:38,320] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:22:38,320] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:22:38,321] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,321] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,321] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,321] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,322] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:22:38,323] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,323] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,323] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:22:38,323] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,323] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:22:38,324] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,325] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,326] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,327] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,327] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,327] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,327] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,327] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,328] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,328] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,328] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,328] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,328] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,329] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,329] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:22:38,329] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,329] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,330] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:22:38,330] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,330] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,330] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,330] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,333] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:22:38,333] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:22:38,334] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,334] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,334] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,334] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,335] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,335] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,335] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,335] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,335] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,336] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,336] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,336] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,337] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,337] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:22:38,337] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:22:38,337] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,337] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,338] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,338] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,338] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,338] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,338] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,339] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,339] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,339] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,340] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,340] [18/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:22:38,340] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,340] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:22:38,340] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:22:38,341] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,341] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,341] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,341] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,341] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:22:38,342] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,343] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,343] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,344] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:22:38,344] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:22:38,344] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,345] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:22:38,346] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:38,346] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:22:38,346] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:22:38,347] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,348] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:22:38,348] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:22:38,348] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:22:38,349] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:22:38,349] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,350] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,352] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,352] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:22:38,352] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:22:38,352] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:22:38,353] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,353] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:22:38,353] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:22:38,354] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,354] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,354] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,354] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:38,355] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:38,355] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:38,355] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:22:38,355] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:22:38,355] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,358] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:22:38,358] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:38,358] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:22:38,359] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:22:38,360] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:22:38,360] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,360] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:22:38,360] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:22:38,361] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,361] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,361] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:38,361] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,361] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,362] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:22:38,363] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:22:38,363] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:22:38,363] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,363] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,363] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:22:38,364] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,366] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,366] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:22:38,366] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:22:38,366] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:22:38,367] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:22:38,367] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:38,367] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:22:38,368] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:22:38,368] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,368] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,369] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,370] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,370] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,370] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,370] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:22:38,371] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,371] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:22:38,371] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:22:38,371] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:22:38,371] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:22:38,372] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:22:38,372] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,373] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,373] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,373] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:22:38,373] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:22:38,373] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:22:38,375] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:22:38,376] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,377] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:22:38,377] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:22:38,377] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:22:38,377] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:22:38,378] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:22:38,378] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,378] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,378] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,378] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,379] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:22:38,379] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:22:38,379] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,380] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,380] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:22:38,380] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:22:38,380] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,380] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,381] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:22:38,381] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,381] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,381] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,382] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,383] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,383] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:22:38,383] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:22:38,383] [18/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,385] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:22:38,386] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:22:38,387] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:22:38,388] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,388] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,388] [18/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,388] [18/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:22:38,388] [18/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:22:38,389] [18/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:22:38,390] [18/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_31 =====\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.216 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,392] [18/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_31 <eval_with_key>.216 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:22:38,394] [18/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_31 =====\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,400] [18/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:38,401] [18/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,401] [18/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,406] [18/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:38,406] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:22:38,407] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:22:38,407] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,408] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,408] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:22:38,409] [18/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:22:38,409] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:22:38,409] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,410] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:22:38,410] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,411] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:22:38,411] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,411] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:22:38,412] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,412] [18/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,413] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:22:38,413] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:22:38,413] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:22:38,413] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,414] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:22:38,414] [18/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,415] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,415] [18/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,415] [18/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:22:38,416] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:22:38,416] [18/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:22:38,416] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,417] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,417] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,417] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,418] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,418] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,419] [18/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,419] [18/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,420] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,420] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,421] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,421] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,421] [18/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,426] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:38,426] [19/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:38,427] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:22:38,427] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:22:38,427] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:38,428] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:38,429] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,429] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:22:38,430] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,430] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,430] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:22:38,430] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,430] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,431] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,432] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,432] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:22:38,432] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:22:38,432] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,433] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:22:38,433] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:22:38,433] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:38,433] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,433] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,434] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,434] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,434] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,435] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:22:38,435] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:22:38,435] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,435] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,437] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,437] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:38,438] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,438] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,438] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:38,438] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,438] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,439] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,440] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,441] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,441] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,441] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,441] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,441] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,442] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,443] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,444] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,445] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,446] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,447] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:22:38,448] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:38,448] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,448] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:38,448] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:22:38,449] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,449] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:38,449] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,449] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,450] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,450] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:38,450] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,450] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:22:38,450] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:22:38,451] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,451] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,451] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,451] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:38,451] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:38,452] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:22:38,453] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:22:38,453] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,453] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,454] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,454] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,454] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,454] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:38,454] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,455] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:22:38,455] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,455] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,456] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,456] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:22:38,456] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,456] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,457] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,458] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,458] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,459] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,459] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,459] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,460] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,460] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,460] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,460] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,461] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,461] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,461] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:38,461] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,461] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,462] [19/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:22:38,462] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,462] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,463] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:22:38,463] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,463] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:22:38,464] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,464] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:38,464] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,465] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,465] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,465] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:38,465] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,466] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,467] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:22:38,467] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,467] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,468] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,468] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:22:38,468] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:22:38,468] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,468] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,469] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,469] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,469] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,470] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:22:38,470] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:22:38,470] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,470] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,472] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,472] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,473] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:22:38,474] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,474] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:22:38,474] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,474] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,475] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,476] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,476] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,476] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,476] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,476] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,477] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,477] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,477] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,477] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,478] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,479] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:22:38,480] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:22:38,481] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,482] [19/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:22:38,483] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,483] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:22:38,484] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:22:38,484] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:22:38,484] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:22:38,484] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,485] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,486] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:22:38,486] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,486] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,486] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,487] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,487] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,487] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,487] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,487] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,488] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,488] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,488] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,489] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:38,492] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,493] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,493] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,493] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,493] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,495] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,495] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,495] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,495] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,495] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,496] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,496] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,496] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:22:38,498] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,499] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,499] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,499] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,499] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,499] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,500] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,500] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,500] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,503] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:22:38,503] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:22:38,503] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:22:38,504] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:22:38,504] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,504] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:22:38,504] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,504] [19/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:22:38,505] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,505] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:22:38,505] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,505] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:22:38,505] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,506] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,506] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:22:38,506] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,506] [19/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:22:38,507] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:22:38,507] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:22:38,507] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:22:38,508] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,509] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:22:38,509] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:22:38,509] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:22:38,509] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:22:38,510] [19/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:22:38,511] [19/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_32 =====\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.217 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,512] [19/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_32 <eval_with_key>.217 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:22:38,513] [19/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_32 =====\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:38,514] [19/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,515] [19/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,517] [19/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:38,517] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,517] [19/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,518] [19/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,518] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,519] [19/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,519] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:22:38,520] [19/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,520] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:22:38,520] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:22:38,521] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:22:38,521] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,521] [19/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,521] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,522] [19/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,522] [19/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:22:38,522] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,522] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,523] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,523] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,523] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,523] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,524] [19/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,524] [19/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:22:38,524] [19/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,525] [19/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,528] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:22:38,529] [20/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:22:38,529] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:22:38,529] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:22:38,530] [20/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:22:38,531] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:22:38,531] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:22:38,531] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,531] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:22:38,532] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,532] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,533] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:22:38,533] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:22:38,533] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:22:38,534] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:22:38,534] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:22:38,535] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:22:38,535] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,535] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,536] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:22:38,536] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:22:38,536] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:22:38,536] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,538] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:22:38,538] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:22:38,538] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:22:38,538] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,539] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,539] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,539] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,540] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,540] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:22:38,540] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:22:38,540] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,545] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:22:38,548] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:22:38,548] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:22:38,548] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:22:38,549] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,549] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:22:38,549] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:22:38,550] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:42\n",
      "[2024-12-28 16:22:38,550] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = logits\n",
      "[2024-12-28 16:22:38,550] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits []\n",
      "[2024-12-28 16:22:38,550] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:22:38,553] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:22:38,553] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:22:38,554] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:22:38,554] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,555] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:22:38,555] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,555] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:22:38,556] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:22:38,556] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:22:38,556] [20/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:22:38,558] [20/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_33 =====\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.218 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:22:38,559] [20/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_33 <eval_with_key>.218 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_33 =====\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:22:38,560] [20/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,561] [20/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:22:38,562] [20/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:22:38,562] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:22:38,563] [20/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:22:38,563] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,563] [20/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:22:38,564] [20/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:22:38,564] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 8820832)              # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:22:38,564] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,565] [20/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,565] [20/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,565] [20/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:22:38,566] [20/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 3:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 6:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 12:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 17:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc955170; to 'Tensor' at 0x7bf4c6fb8d70>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 20:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 21:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 22:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 23:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 24:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 28:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 31:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 32:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc955170; to 'Tensor' at 0x7bf4c6fb8d70>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc954bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 41:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f8dd50; to 'Tensor' at 0x7bf4c5f61610>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 45:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 48:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 49:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 50:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc954bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f8dd50; to 'Tensor' at 0x7bf4c5f61610>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 71:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 75:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 78:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc954bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 79:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 86:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 87:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 88:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f9bb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 89:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc954bd0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 93:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f9bb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 99:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 100:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 101:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 102:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 104:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f9a840; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5f9a840; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcf380; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcf380; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 123:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6377150; to 'Tensor' at 0x7bf4c5e89430>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 124:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 128:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 134:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 135:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 137:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 138:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 139:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4cc955170; to 'Tensor' at 0x7bf4c6fb8d70>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 140:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 151:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67dbec0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 152:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 153:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 154:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 155:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 161:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.1736, 0.1410, 0.0687, 0.3082, 0.1009, 0.0390\n",
      "OutputGraph.call_user_compiler   0.0004, 0.0004, 0.0004, 0.0008, 0.0004, 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "torch._dynamo.reset()\n",
    "model_w_custom_op = LlamaWithCustomOp(llama_model_name, output_dim).to(\"cuda\")\n",
    "\n",
    "# Step 1: Analyze with custom_forward_fn=None\n",
    "print(\"=== Explanation for custom_forward_fn=None ===\")\n",
    "explanation_none = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=None)\n",
    "print(explanation_none)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:43,456] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,457] [21/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:23:43,458] [21/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:43,459] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,460] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,460] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,461] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,463] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,464] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:43,465] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,466] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,467] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,468] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,469] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:43,470] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,471] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,472] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,473] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,476] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,476] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,477] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,478] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,479] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,480] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,481] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,482] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,483] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,484] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,485] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,486] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,487] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,488] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,489] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,490] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,491] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,492] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,493] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,494] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,497] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,498] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,499] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,500] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,501] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,502] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,503] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,503] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,504] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,505] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,505] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,506] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,508] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,509] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,510] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,511] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,512] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,512] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,513] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,514] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,514] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,515] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,516] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,517] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:43,518] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,519] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,519] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:43,520] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,521] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:43,522] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,522] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,524] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,524] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,525] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,526] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,527] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,527] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,528] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,529] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,533] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:43,534] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:43,534] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,535] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,536] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,537] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,538] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:43,539] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,539] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,540] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,541] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,543] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,545] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,547] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,548] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,548] [21/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:43,549] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,549] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,550] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,551] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,552] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,553] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,553] [21/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,554] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:43,555] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,556] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,557] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,558] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,559] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,560] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,561] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:43,562] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,563] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:43,564] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,567] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,567] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,568] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,569] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,570] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,570] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,571] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,572] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,573] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,574] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,575] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,576] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,577] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,578] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,579] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,580] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,581] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,583] [21/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,584] [21/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,585] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,585] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,586] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,587] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,588] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,589] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,590] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,591] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,591] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,592] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,593] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,594] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,597] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,598] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,599] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,601] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,602] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,603] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,605] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,606] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,607] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,608] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,609] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,610] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,611] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,612] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,613] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,614] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,614] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,615] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,616] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,617] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,618] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,619] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,620] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,621] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,621] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,622] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,623] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,624] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,625] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,626] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,627] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,627] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:43,628] [21/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,629] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,630] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,631] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:43,631] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,632] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,633] [21/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:23:43,634] [21/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:23:43,635] [21/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,635] [21/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_34 =====\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.219 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,636] [21/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_34 <eval_with_key>.219 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:23:43,637] [21/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_34 =====\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,638] [21/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,641] [21/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,642] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:43,642] [21/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:43,643] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:23:43,643] [21/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,644] [21/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,645] [21/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,645] [21/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Explanation for custom_forward_fn=custom_scale_fn ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:43,657] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,658] [22/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,659] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,660] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,661] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,662] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,663] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,664] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,664] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,665] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,669] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,670] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,671] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,671] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,672] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,672] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,673] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,674] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,676] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,677] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,677] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,678] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,679] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,680] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,681] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,682] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,683] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,685] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,686] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,687] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,689] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,690] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:43,692] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,693] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:43,694] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,695] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:43,696] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:43,697] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,698] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,698] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,699] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,700] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,701] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,702] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:43,704] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:43,704] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,705] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,706] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:43,708] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,709] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,710] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,711] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,711] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,712] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,713] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,714] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,715] [22/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:43,716] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,717] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:43,718] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,719] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,720] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:43,721] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,721] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:23:43,722] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,723] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:23:43,724] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,725] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,726] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:43,727] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:43,728] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,730] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,730] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:43,731] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,732] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:43,733] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,734] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,734] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,735] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,736] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,736] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,737] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,738] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,739] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,740] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,741] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,742] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,743] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,744] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,745] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,746] [22/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,749] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,750] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,751] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,752] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,753] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,754] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,755] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,756] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,757] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,764] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,765] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,766] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,772] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,773] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,774] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,775] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,781] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,782] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,783] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,784] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,785] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,786] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,786] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,787] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,788] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,789] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,790] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,791] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,792] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,793] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,794] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,795] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,796] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,797] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,798] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,799] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,800] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,801] [22/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,802] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,803] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,804] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,805] [22/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,806] [22/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,806] [22/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,807] [22/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,809] [22/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,809] [22/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_36 =====\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.220 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,811] [22/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_36 <eval_with_key>.220 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:23:43,812] [22/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_36 =====\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,813] [22/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,814] [22/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,818] [22/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,818] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,819] [22/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,819] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,820] [22/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,821] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:23:43,821] [22/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,822] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,823] [22/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,824] [22/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,825] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,826] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:43,827] [22/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,828] [22/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,832] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,834] [23/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:43,835] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:43,835] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:43,836] [23/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,837] [23/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,838] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:43,839] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:43,840] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:43,841] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,841] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:43,842] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,843] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,843] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:43,844] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,845] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,846] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:43,848] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,849] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,850] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:43,852] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,853] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,854] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:43,857] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,858] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,859] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,860] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,861] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,862] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,863] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,864] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,865] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,866] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,867] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:43,868] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,869] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,870] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,871] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,872] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:43,872] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,873] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,874] [23/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:43,875] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,876] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:23:43,877] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,878] [23/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,879] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,879] [23/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:43,880] [23/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:43,881] [23/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:43,881] [23/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:43,883] [23/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_38 =====\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.221 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:43,884] [23/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_38 <eval_with_key>.221 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:23:43,885] [23/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_38 =====\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:43,886] [23/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:43,887] [23/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,887] [23/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:43,905] [23/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:43,906] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:43,906] [23/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:43,907] [23/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,908] [23/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,908] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,909] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:23:43,910] [23/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,911] [23/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:43,914] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:43,917] [24/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,918] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:43,918] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:43,919] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:43,921] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,923] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,925] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:43,927] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:43,928] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:23:43,928] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:43,929] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:43,930] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:43,931] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:43,932] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,068] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,068] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,069] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,070] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,071] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,072] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,073] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,074] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,075] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,076] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,077] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,078] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,079] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,080] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,081] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,082] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:23:44,083] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:23:44,084] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,085] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,086] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,087] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,088] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,089] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,090] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,091] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,092] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,093] [24/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,094] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,095] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,095] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,096] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,099] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:44,099] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,100] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,101] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,102] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,102] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:23:44,104] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,104] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,105] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,106] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,107] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:23:44,108] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,109] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,110] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,111] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,111] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,112] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,114] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,115] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:23:44,117] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,118] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:23:44,118] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:23:44,119] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:44,120] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:44,121] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,121] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,122] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,123] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,124] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,125] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,125] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,126] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,127] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,129] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,130] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,131] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,134] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,135] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,136] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,137] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,138] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,139] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,141] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:23:44,142] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,143] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:23:44,144] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,145] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:44,146] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,147] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:44,148] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,149] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,150] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,151] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,152] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,153] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,154] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,155] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,156] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,157] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,158] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,159] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,160] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:44,161] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,162] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,163] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:44,164] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,165] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:44,166] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,167] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,168] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,169] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,170] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,171] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,172] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,172] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,173] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,174] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,175] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,176] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,177] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,178] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,179] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,180] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,181] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,182] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,183] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,184] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,185] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:44,186] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,187] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,188] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,189] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,190] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,191] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,191] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,192] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,193] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,193] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,194] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,195] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,196] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:44,197] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:44,198] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,199] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,200] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,201] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,202] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,203] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:44,204] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,205] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,207] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:44,208] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,209] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,210] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,211] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,212] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,213] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:44,214] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,215] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,216] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,217] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,218] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,219] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,220] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,223] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,223] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,224] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,225] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,226] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,227] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,228] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,230] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,231] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,232] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:44,233] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,233] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,234] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,235] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,236] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,237] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,238] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,239] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,241] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,242] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,243] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,244] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,245] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,246] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,246] [24/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,247] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,248] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,249] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,250] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,251] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,252] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,253] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:23:44,254] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,255] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,256] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,257] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,258] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,261] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,262] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:44,263] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,264] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,265] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,266] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,267] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,268] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,270] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:44,271] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,272] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,273] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,274] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,275] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,276] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:44,277] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:23:44,277] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,278] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,279] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,280] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,281] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:44,282] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,283] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,284] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,285] [24/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:44,287] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:23:44,288] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,289] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,290] [24/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,292] [24/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_40 =====\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.222 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,293] [24/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_40 <eval_with_key>.222 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:23:44,296] [24/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_40 =====\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,300] [24/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,301] [24/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,305] [24/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,305] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,306] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,306] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,307] [24/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,308] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:44,309] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,310] [24/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:23:44,311] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,312] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:44,313] [24/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,314] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,315] [24/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,316] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,317] [24/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,322] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:44,323] [25/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:44,324] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,326] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,327] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:44,328] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,329] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,330] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,331] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,332] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,334] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,335] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,336] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,337] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,338] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,339] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,340] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,341] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,342] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,343] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,344] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,345] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,346] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,347] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:44,348] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,349] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:44,350] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,351] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,352] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,353] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,354] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,355] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,356] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,357] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,358] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,359] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,359] [25/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,360] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,361] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,362] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,363] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,364] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,366] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,366] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,367] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,368] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,369] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,370] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,371] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,372] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,373] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,374] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,375] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,376] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:44,377] [25/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,379] [25/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:23:44,380] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,381] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,382] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,383] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,384] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,385] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,388] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,389] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,391] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,391] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,392] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,396] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,397] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,401] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:44,402] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,403] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,404] [25/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:23:44,405] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:44,406] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:23:44,407] [25/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,408] [25/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_41 =====\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.223 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,409] [25/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_41 <eval_with_key>.223 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:23:44,410] [25/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_41 =====\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,411] [25/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,412] [25/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,412] [25/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,414] [25/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,414] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,415] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:23:44,416] [25/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,417] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:44,417] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:44,418] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:23:44,418] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,419] [25/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,420] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,421] [25/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,424] [25/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:44,425] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,426] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,426] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,427] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,427] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,428] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,428] [25/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,429] [25/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:44,429] [25/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,430] [25/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,435] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:44,436] [26/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:44,437] [26/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:44,439] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,440] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:44,440] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,441] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,442] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,443] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,444] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,445] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,446] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,447] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:23:44,451] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [UserFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:44,452] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn [NullVariable]\n",
      "[2024-12-28 16:23:44,453] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call scale_by_max from <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:23:44,454] [26/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-28 16:23:44,455] [26/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object scale_by_max at 0x7bf4c5d5f130, file \"/tmp/ipykernel_414314/2274816616.py\", line 6>\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:6 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def scale_by_max(input: torch.Tensor) -> torch.Tensor:\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:7 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,456] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:44,457] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD max [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:44,457] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method max of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call max_1 from scale_by_max /tmp/ipykernel_414314/2274816616.py:7 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,458] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~^^^^^^^\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST max_value [TensorVariable()]\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line scale_by_max /tmp/ipykernel_414314/2274816616.py:8 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return input * max_value\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input []\n",
      "[2024-12-28 16:23:44,460] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST max_value [TensorVariable()]\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from scale_by_max /tmp/ipykernel_414314/2274816616.py:8 (inline depth: 1)\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return input * max_value\n",
      "[2024-12-28 16:23:44,461] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~^~~~~~~~~~~\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object scale_by_max at 0x7bf4c5d5f130, file \"/tmp/ipykernel_414314/2274816616.py\", line 6>\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 386 []\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,462] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:44,463] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,464] [26/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:23:44,466] [26/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_42 =====\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.224 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2274816616.py:7, code: max_value = torch.max(input)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         max_1 = torch.max(l__self___linear)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/2274816616.py:8, code: return input * max_value\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = l__self___linear * max_1;  l__self___linear = max_1 = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(mul);  mul = None\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:44,467] [26/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_42 <eval_with_key>.224 opcode         name               target                                                   args                       kwargs\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -------------------------  ----------\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                         {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)             {'dim': 1}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                    {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  max_1              <built-in method max of type object at 0x7bf5a531cde0>   (l__self___linear,)        {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                <built-in function mul>                                  (l__self___linear, max_1)  {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (mul,)                     {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)    {}\n",
      "[2024-12-28 16:23:44,468] [26/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_42 =====\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] max_1: ()\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,469] [26/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:44,471] [26/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:44,472] [26/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 136291731076128)      # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,473] [26/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:44,474] [26/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 46\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "    <built-in method max of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 12:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 13:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 17:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 21:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 22:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 24:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 32:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 41:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 42:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 48:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 49:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5915c60; to 'Tensor' at 0x7bf4c5f63e30>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 50:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3f830; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 69:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 72:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 75:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e7bc90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 76:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 78:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 79:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fce200; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 85:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3e750; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 86:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 88:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 89:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 90:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e7bc90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 91:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 99:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 100:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 101:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 102:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 104:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5915c60; to 'Tensor' at 0x7bf4c5f63e30>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 105:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3f830; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3e750; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcdc10; to 'Tensor' at 0x7bf4c6b22090>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 123:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 124:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 125:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67375b0; to 'Tensor' at 0x7bf4c5983d70>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 128:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 135:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 138:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 136291731076128)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b4467a10; to 'type' at 0x86f540 (function)>\n",
      "  Guard 151:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 153:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 154:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c63cad40; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 155:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 161:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.1902, 0.1733, 0.0812, 0.4060, 0.1112, 0.0400\n",
      "OutputGraph.call_user_compiler   0.0005, 0.0004, 0.0008, 0.0004, 0.0004, 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Analyze with custom_forward_fn=custom_scale_fn (no reset here)\n",
    "print(\"\\n=== Explanation for custom_forward_fn=custom_scale_fn ===\")\n",
    "explanation_custom = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=scale_by_max)\n",
    "print(explanation_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:48,605] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:48,606] [27/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:23:48,607] [27/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:48,608] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,609] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,610] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,612] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,613] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,614] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,615] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,616] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,617] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,618] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:48,618] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,619] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,620] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,621] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,622] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,623] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,626] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,627] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,628] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,629] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,630] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,631] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,631] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,632] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,633] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,633] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,634] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,635] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,636] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,637] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,638] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,639] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,640] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,641] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,642] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,643] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,644] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,645] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,646] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,649] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,650] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,651] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,652] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,653] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,654] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,655] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,656] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,656] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,657] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,658] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,659] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,660] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,661] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,662] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,663] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,664] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,665] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,666] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,667] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,668] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,669] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,670] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,671] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,672] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,673] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:48,674] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,675] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,676] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,678] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,680] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,681] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,682] [27/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:48,683] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,683] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,684] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,685] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,687] [27/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:48,688] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,689] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,690] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,691] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,692] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,693] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:48,694] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:48,695] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,699] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,700] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,701] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,702] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,703] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,704] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,705] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,706] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,707] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,708] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,709] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,710] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,711] [27/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,712] [27/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:48,714] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:48,715] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:48,716] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,717] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,717] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:48,718] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,718] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,719] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:48,720] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,720] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,721] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:48,722] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,722] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,723] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,727] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,727] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,728] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,728] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,729] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,734] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,735] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,736] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,737] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,741] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,742] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,742] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,743] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,744] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:48,747] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,748] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,749] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,749] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,750] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,751] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,752] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,753] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,754] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,755] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:48,756] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,757] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,758] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,758] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,759] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,759] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,760] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,761] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,762] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:48,764] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,765] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,766] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,766] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,767] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,770] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,770] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,771] [27/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:48,773] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,774] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,775] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,776] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,777] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,777] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,778] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,779] [27/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,780] [27/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:23:48,782] [27/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,783] [27/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_43 =====\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.225 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_43 <eval_with_key>.225 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:23:48,784] [27/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_43 =====\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:48,785] [27/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:48,786] [27/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:48,789] [27/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:23:48,790] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:23:48,790] [27/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,791] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,791] [27/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,792] [27/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,793] [27/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,793] [27/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,796] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:48,796] [28/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:48,797] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:23:48,797] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,798] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:48,799] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:23:48,801] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,802] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,803] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,803] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,804] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,808] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,808] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,809] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,810] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,810] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,811] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,812] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,813] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,814] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,815] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,816] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,817] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,818] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,819] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,820] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,821] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:48,822] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,823] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,823] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,824] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:48,825] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,826] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,828] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:48,829] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,829] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,830] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,830] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,831] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,832] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,833] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,834] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:48,835] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:48,835] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,836] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,837] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,838] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:48,839] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,840] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,841] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,842] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,843] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,844] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,845] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,846] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,847] [28/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:48,848] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,848] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,849] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,850] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:48,851] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:48,852] [28/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,853] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,854] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:23:48,854] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:23:48,855] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,856] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,857] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,858] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,859] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,860] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,861] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:23:48,862] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,866] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,866] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,867] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:48,870] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:48,871] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:48,872] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:48,873] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,873] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,874] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,875] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,876] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,877] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,877] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,878] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,879] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,879] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,880] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,881] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:48,882] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,882] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,883] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:48,884] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:48,885] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,885] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,886] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,888] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:48,892] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,892] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:48,897] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,898] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:48,900] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,901] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,902] [28/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,904] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,904] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:48,905] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:48,905] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:48,906] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:48,907] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:48,908] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,908] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,909] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,910] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,911] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,912] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,913] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,913] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,914] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,918] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,919] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,920] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,926] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:48,927] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,928] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,928] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:48,929] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,934] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,935] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:48,935] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,936] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,936] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,939] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,940] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,941] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,941] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,942] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,943] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,944] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,945] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,946] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,947] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,948] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,949] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,950] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,950] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,951] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,952] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,953] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,954] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,955] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:48,956] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,957] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:48,958] [28/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,959] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,960] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,961] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:48,962] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,963] [28/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:23:48,964] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:23:48,964] [28/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:23:48,965] [28/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:48,965] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,966] [28/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:48,968] [28/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:48,968] [28/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_45 =====\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.226 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:48,970] [28/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_45 <eval_with_key>.226 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:23:48,971] [28/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_45 =====\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:48,972] [28/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:48,973] [28/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:48,973] [28/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:48,977] [28/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:48,977] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,978] [28/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,978] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:48,979] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:48,979] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,980] [28/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,980] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:23:48,981] [28/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,981] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,982] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,982] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,983] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,984] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:23:48,984] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,985] [28/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,985] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:48,986] [28/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_input_ids_ : torch.Tensor):\n",
      "    l_input_ids_ = L_input_ids_\n",
      "    l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "    arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "    unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "    return (l__self___embed_tokens, unsqueeze)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add);  add = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "    return (mul_1,)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:48,987] [28/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:48,988] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,988] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,989] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,990] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,991] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,992] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,992] [28/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,993] [28/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:48,994] [28/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:48,995] [28/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,001] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,005] [29/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:49,007] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:23:49,007] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:23:49,008] [29/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,010] [29/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:23:49,012] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:23:49,013] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:23:49,014] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,015] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,016] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,017] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,018] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,019] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,020] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,023] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,024] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,025] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,028] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,029] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,030] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,032] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,033] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:23:49,033] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,034] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,035] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,036] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,037] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,038] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,039] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,040] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,041] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,042] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,043] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,043] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,044] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,045] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:23:49,046] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,047] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,048] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,048] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,049] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,050] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,051] [29/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:23:49,052] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,053] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:23:49,054] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,055] [29/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,056] [29/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:23:49,056] [29/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:23:49,057] [29/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:23:49,058] [29/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_47 =====\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.227 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,059] [29/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_47 <eval_with_key>.227 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:23:49,060] [29/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_47 =====\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,062] [29/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,081] [29/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,081] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:49,082] [29/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:23:49,082] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,083] [29/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,083] [29/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,084] [29/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,084] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:23:49,085] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,086] [29/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,087] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,087] [29/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,088] [29/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:23:49,089] [29/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,090] [29/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,093] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,095] [30/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,096] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:23:49,096] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:23:49,097] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:23:49,098] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,100] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,101] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:23:49,103] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,103] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:49,104] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,105] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:23:49,106] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,107] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,109] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,109] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,110] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,111] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,112] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,112] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,113] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,114] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,114] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,115] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,116] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,116] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,117] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,118] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,119] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,120] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,121] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,122] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,123] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,124] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,125] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,126] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,127] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:23:49,128] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,129] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:23:49,130] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,131] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,132] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:49,133] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,133] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,134] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,135] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,136] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,136] [30/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,137] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,138] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,138] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,139] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,139] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,141] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,144] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:49,144] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,145] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,146] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,147] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,147] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:23:49,149] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,149] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,150] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,151] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,155] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,156] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,157] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,157] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,158] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,158] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,159] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,159] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,160] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,162] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,163] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,165] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:23:49,166] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:23:49,167] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,168] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:23:49,169] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,170] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,171] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,172] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,173] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,174] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,175] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,175] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,176] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,177] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,178] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,180] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,181] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,182] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,183] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,184] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,184] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,185] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,187] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:23:49,188] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,190] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,191] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:49,191] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:23:49,192] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,193] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,194] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,195] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:49,196] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,197] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,198] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:49,199] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:23:49,200] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,200] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,201] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,202] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,203] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,203] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,205] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,206] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,207] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,207] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,208] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,208] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,209] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,209] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,210] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,211] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,211] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:23:49,212] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,213] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,214] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,215] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,216] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:23:49,217] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,218] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,219] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,220] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:23:49,221] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,222] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,223] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:49,224] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,225] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,226] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,227] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,229] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,229] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,230] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,231] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,233] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,234] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,235] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,236] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,237] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,238] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,239] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,240] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,241] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,242] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,244] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,245] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,246] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:23:49,247] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,248] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,249] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,250] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,251] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,252] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,252] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,253] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,254] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:23:49,256] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:23:49,257] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:23:49,258] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:23:49,258] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,259] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,260] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,261] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,262] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "    l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "    l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "    view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    return (transpose, transpose_1, transpose_2)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,263] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:23:49,264] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,265] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,266] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,266] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,267] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,268] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,269] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:23:49,270] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:49,271] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,272] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,273] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:49,274] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,275] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,275] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,276] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,277] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,278] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,279] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,280] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,282] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,283] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,284] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,285] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,286] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,287] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,288] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,289] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,290] [30/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,291] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,292] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:23:49,293] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,294] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,295] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,296] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,297] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,298] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,300] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,301] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,302] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,303] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,304] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,305] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,307] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,308] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,309] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,310] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,311] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,313] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:23:49,314] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,315] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:23:49,316] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,317] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:49,318] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,319] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,320] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,321] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,322] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,324] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,326] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,326] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,328] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,329] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:23:49,330] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,331] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:23:49,332] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:23:49,332] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,333] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,334] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,335] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:49,336] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,337] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,337] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,338] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,339] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:23:49,342] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:23:49,343] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,344] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:23:49,345] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:23:49,346] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,347] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:23:49,348] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:23:49,348] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:23:49,349] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:23:49,350] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,351] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,352] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,353] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,354] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,354] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,355] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,356] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,357] [30/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:49,360] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:23:49,361] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,362] [30/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,364] [30/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_49 =====\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.228 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,366] [30/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_49 <eval_with_key>.228 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:23:49,368] [30/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_49 =====\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,375] [30/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,376] [30/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,376] [30/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,381] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,382] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,382] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,383] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,383] [30/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:23:49,384] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:49,384] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,385] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:23:49,385] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,386] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:23:49,386] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,387] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:23:49,387] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,388] [30/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,388] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:23:49,389] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,390] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,391] [30/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,391] [30/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:23:49,392] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,393] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,393] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,394] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,394] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,395] [30/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,396] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,397] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,397] [30/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,401] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,402] [31/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:23:49,403] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,405] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,406] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:49,407] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,408] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:23:49,409] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,410] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,411] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,412] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,415] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,415] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,416] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,417] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,418] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,419] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,420] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,420] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,421] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,422] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,423] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,424] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,425] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,426] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,427] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,429] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,430] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,431] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,432] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:23:49,433] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,434] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,435] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:23:49,435] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,436] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,437] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,438] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,439] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,440] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,442] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,443] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,444] [31/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:23:49,444] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,445] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,446] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,447] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,448] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,449] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,451] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,451] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,452] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,453] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,454] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,455] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,456] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,457] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,458] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,459] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:23:49,460] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:23:49,461] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,462] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:23:49,463] [31/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:23:49,464] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,465] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:23:49,466] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,467] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,468] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,469] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,470] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,474] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,477] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,477] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,478] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,482] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,483] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:23:49,487] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:49,488] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,489] [31/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:23:49,490] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:23:49,491] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:23:49,492] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,493] [31/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_50 =====\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.229 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,495] [31/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_50 <eval_with_key>.229 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:23:49,496] [31/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_50 =====\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,497] [31/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,498] [31/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,498] [31/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,500] [31/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,500] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,501] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,502] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:23:49,503] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,504] [31/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,504] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:23:49,505] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,506] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,507] [31/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:23:49,508] [31/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,508] [31/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,512] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:23:49,513] [32/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:49,514] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:23:49,514] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:23:49,515] [32/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:23:49,516] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,517] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:23:49,518] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:23:49,519] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,520] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,522] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,523] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,524] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:23:49,529] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:42\n",
      "[2024-12-28 16:23:49,530] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = logits\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits []\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:23:49,531] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,532] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,533] [32/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:23:49,534] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:23:49,535] [32/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_51 =====\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.230 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:23:49,536] [32/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_51 <eval_with_key>.230 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_51 =====\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:23:49,537] [32/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-28 16:23:49,538] [32/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-28 16:23:49,539] [32/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:23:49,539] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:49,540] [32/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:23:49,540] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,541] [32/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:23:49,541] [32/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:23:49,542] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 8820832)              # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:23:49,542] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:23:49,543] [32/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "    l_position_ids_ = L_position_ids_\n",
      "    l_query_states_ = L_query_states_\n",
      "    l_key_states_ = L_key_states_\n",
      "    l_value_states_ = L_value_states_\n",
      "    _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "    l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "    getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "    float_1 = getitem.float();  getitem = None\n",
      "    expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "    getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "    float_2 = getitem_1.float();  getitem_1 = None\n",
      "    _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "    float_3 = expand.float();  expand = None\n",
      "    float_4 = float_2.float();  float_2 = None\n",
      "    matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "    transpose = matmul.transpose(1, 2);  matmul = None\n",
      "    cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "    cos = cat.cos()\n",
      "    sin = cat.sin();  cat = None\n",
      "    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "    mul = cos * 1.0;  cos = None\n",
      "    mul_1 = sin * 1.0;  sin = None\n",
      "    to = mul.to(dtype = torch.float32);  mul = None\n",
      "    to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "    _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "    unsqueeze = to.unsqueeze(1);  to = None\n",
      "    unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "    mul_2 = l_query_states_ * unsqueeze\n",
      "    getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "    neg = -getitem_3;  getitem_3 = None\n",
      "    cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "    mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "    getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "    neg_1 = -getitem_5;  getitem_5 = None\n",
      "    cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "    mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "    add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "    getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "    expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "    reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "    getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "    expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "    reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "    transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "    matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "    truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "    softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "    to_2 = softmax.to(torch.float32);  softmax = None\n",
      "    dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "    matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "    transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "    contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "    reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "    l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "    return (l__self___o_proj,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    l_residual_ = L_residual_\n",
      "    add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "    to = add.to(torch.float32)\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add_1 = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "    l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "    l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "    l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "    mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "    l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "    add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "    return (add_2,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "    l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "    l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "    return (l__self___softmax,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0991, 0.0959, 0.1000, 0.0948, 0.1064, 0.0984, 0.0997, 0.1023, 0.1015,\n",
       "         0.1020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap your model with the debug callback\n",
    "model_custom_optimized = torch._dynamo.optimize(debug_callback)(model_w_custom_op)\n",
    "\n",
    "# Run your model to trigger the tracing\n",
    "model_custom_optimized(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the TorchDynamo behavior further\n",
    "\n",
    "As seen in the implementation for the custom op - `scale_by_max`, it is defined for the CPU backend.\n",
    "\n",
    "So obviously, the next thing I wanted to understand was what happens if I move the model to a CUDA device, i.e. Nvidia GPU, and `TorchDynamo` encounters a custom-op with only a CPU backend.\n",
    "\n",
    "The next few cells talk about this in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TorchDynamo captures graphs instead of executing operations directly:\n",
    "# When we wrap the model with torch._dynamo.optimize(debug_callback), TorchDynamo intercepts the Python bytecode and traces the computation graph.\n",
    "# During this tracing phase, TorchDynamo does not execute operations immediately. Instead, it records the operations (including any custom operator) into an FX graph.\n",
    "# Since the actual execution of scale_by_max was deferred, no error was triggered at this stage.\n",
    "#\n",
    "# Using decorators like `@torch._dynamo.disable`, we can force TorchDynamo to insert a GraphBreak for the `custom_forward_fn` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable only graph breaks in TORCH LOGS\n",
    "os.environ[\"TORCH_LOGS\"] = \"+graph_breaks\"\n",
    "\n",
    "custom_lib = torch.library.Library(\"scale_op_eager\", \"DEF\")\n",
    "\n",
    "# Step 2: Define the custom op schema\n",
    "custom_lib.define(\"scale_by_max_eager(Tensor input) -> Tensor\")\n",
    "\n",
    "@torch._dynamo.disable\n",
    "def scale_by_max_eager(input: torch.Tensor) -> torch.Tensor:\n",
    "    max_value = torch.max(input)\n",
    "    return input * max_value\n",
    "\n",
    "# Use IMPL to register the implementation\n",
    "impl_lib = torch.library.Library(\"scale_op_eager\", \"IMPL\")\n",
    "impl_lib.impl(\"scale_by_max_eager\", scale_by_max_eager, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-28 16:24:08,899] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:08,900] [33/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:22\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids, custom_forward_fn=None):\n",
      "[2024-12-28 16:24:08,901] [33/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:24:08,902] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,903] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_414314/1905900009.py:24\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:08,904] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,907] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,908] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,908] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,909] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,910] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,911] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7bf5a531cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,912] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,913] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:08,913] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_414314/1905900009.py:27\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:08,914] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:08,915] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,916] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,917] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,918] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:08,921] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,922] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:08,923] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,923] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,924] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,925] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,926] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,927] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,928] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,929] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,930] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:08,931] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,932] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7bf4c6fb4f40>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,933] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,934] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,935] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,936] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:08,940] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:08,941] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:08,942] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,943] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,944] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,945] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,946] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,946] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,947] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,948] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,949] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,950] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,951] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:08,952] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,953] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:08,954] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,955] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,956] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,959] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:08,960] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,960] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,961] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:08,962] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:08,963] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,964] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:08,965] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:08,966] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,966] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:08,967] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,968] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,969] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,970] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:08,971] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:08,971] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,972] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:08,974] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:08,975] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,976] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:08,977] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,978] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:08,979] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,980] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,981] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,983] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:08,985] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,986] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,987] [33/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:08,988] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,988] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,989] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:08,990] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:08,992] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:08,992] [33/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:08,993] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:24:08,994] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,995] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:08,996] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,997] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,998] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:08,999] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,000] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,001] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,002] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:24:09,003] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,006] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,007] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,007] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,008] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,009] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,010] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,011] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,012] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,012] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,013] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,014] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,015] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,016] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,017] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,018] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,019] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,020] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,022] [33/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,023] [33/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,026] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,026] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,027] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,028] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,029] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,030] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,030] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,031] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,032] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,032] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,033] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,034] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,035] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,039] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,040] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,040] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,041] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,045] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,046] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,046] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,047] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,049] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,050] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,051] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,052] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,053] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,054] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,055] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,056] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,057] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,058] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,060] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,060] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,061] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,062] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,064] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,064] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,065] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,065] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,066] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,067] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,068] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,069] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,069] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,070] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,070] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,071] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,071] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,072] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,072] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,073] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,074] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,075] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,077] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,078] [33/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,080] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,081] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,081] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,082] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,083] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,084] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,085] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,086] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,087] [33/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,088] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,088] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,089] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x7bf4cc78a170, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,091] [33/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,092] [33/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 30, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-28 16:24:09,094] [33/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:24:09,095] [33/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,095] [33/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_52 =====\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.231 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:24, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:27, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,096] [33/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_52 <eval_with_key>.231 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7bf5a531cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_52 =====\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-28 16:24:09,097] [33/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,098] [33/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,098] [33/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,101] [33/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,101] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_414314/1905900009.py:24 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 117923504)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_414314/1905900009.py:27 in forward\n",
      "[2024-12-28 16:24:09,102] [33/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,103] [33/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,104] [33/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,104] [33/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,114] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,115] [34/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,116] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,117] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-28 16:24:09,119] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:24:09,120] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,121] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,121] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,122] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,122] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,123] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,124] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,128] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,129] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,129] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,130] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,131] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,132] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,133] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,134] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,135] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,136] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,137] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,138] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,139] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,140] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,141] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,141] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,142] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,143] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:09,144] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,145] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,146] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,146] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,147] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,148] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:09,149] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,150] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,152] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:09,152] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,153] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:09,155] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,156] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,157] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,158] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,158] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,159] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,160] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,161] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,162] [34/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,163] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,164] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,165] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,166] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,167] [34/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,168] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-28 16:24:09,169] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,170] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,171] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,172] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,173] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,174] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,174] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-28 16:24:09,175] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,178] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,179] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,180] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,181] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,182] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,183] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,184] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,185] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,186] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,187] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,188] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,189] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7bf4c6fb4b80>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,190] [34/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,192] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,192] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,193] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,194] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,195] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,196] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,197] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,197] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,198] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,199] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,204] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,205] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,206] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,212] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,213] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,214] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,219] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,220] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,221] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,222] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,223] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,225] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,226] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,227] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,228] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,229] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,230] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,231] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,232] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,233] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,234] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,235] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,236] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,237] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,238] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,239] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,240] [34/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,241] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,242] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,243] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,244] [34/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0xbb5c590, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,245] [34/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,247] [34/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,248] [34/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,249] [34/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_54 =====\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.232 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,250] [34/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_54 <eval_with_key>.232 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add,)                                    {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-28 16:24:09,251] [34/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_54 =====\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,252] [34/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,253] [34/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,253] [34/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,259] [34/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,260] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,261] [34/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,261] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,262] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,262] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,263] [34/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,263] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 117923504)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-28 16:24:09,264] [34/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,264] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,265] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,266] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-28 16:24:09,266] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,267] [34/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,267] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:24:09,268] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,269] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,270] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,270] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,271] [34/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,271] [34/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,272] [34/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,273] [34/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,279] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,282] [35/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:24:09,283] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-28 16:24:09,283] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-28 16:24:09,284] [35/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,285] [35/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,287] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-28 16:24:09,287] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-28 16:24:09,288] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-28 16:24:09,289] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-28 16:24:09,290] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-28 16:24:09,290] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,291] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,295] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,295] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-28 16:24:09,296] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,296] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-28 16:24:09,297] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,298] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,299] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,299] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,300] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,301] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,302] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,305] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,306] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,309] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,310] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,311] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-28 16:24:09,313] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,314] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,315] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,316] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,317] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,318] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,318] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,319] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,319] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,320] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,321] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,322] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,323] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,324] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,325] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,326] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,327] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,328] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-28 16:24:09,329] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,330] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,331] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,331] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,332] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,333] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,334] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,335] [35/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-28 16:24:09,336] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,337] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-28 16:24:09,338] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,339] [35/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,340] [35/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,340] [35/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_56 =====\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.233 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,342] [35/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_56 <eval_with_key>.233 opcode       name              target            args                                      kwargs\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-28 16:24:09,343] [35/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_56 =====\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,344] [35/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,345] [35/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:24:09,357] [35/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-28 16:24:09,358] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,358] [35/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,359] [35/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,359] [35/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,360] [35/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,361] [35/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 40477776)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-28 16:24:09,362] [35/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,362] [35/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,365] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-28 16:24:09,367] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-28 16:24:09,368] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,370] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,372] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,373] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-28 16:24:09,374] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,375] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-28 16:24:09,375] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,376] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,377] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,378] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,379] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,383] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,383] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,384] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,385] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,385] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,386] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,387] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,388] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,389] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,390] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,391] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,392] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,393] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,394] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,395] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,395] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7bf4c6fb45e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,396] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:24:09,397] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-28 16:24:09,398] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,399] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,400] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,401] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-28 16:24:09,402] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,403] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,404] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,405] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,405] [36/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,406] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,407] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,408] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,409] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,411] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:24:09,411] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,412] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,413] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,413] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,414] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-28 16:24:09,415] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,415] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,416] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,417] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-28 16:24:09,418] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,419] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,420] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,421] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,422] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,423] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,425] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-28 16:24:09,426] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,427] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-28 16:24:09,428] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-28 16:24:09,429] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,430] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-28 16:24:09,431] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,432] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,433] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,434] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,434] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,435] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,436] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,436] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,437] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,438] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,439] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,440] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,442] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,443] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,443] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,447] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,447] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,448] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,449] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,450] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,450] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,451] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,452] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,453] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,454] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,455] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-28 16:24:09,456] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,457] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,458] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-28 16:24:09,459] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,460] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,461] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-28 16:24:09,462] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:24:09,463] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,464] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,466] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,467] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,468] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,469] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,470] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,472] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,473] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,474] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,474] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,475] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,476] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,477] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb45720, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,478] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,479] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7bf5a5a4e670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,480] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-28 16:24:09,481] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,482] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,482] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-28 16:24:09,483] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-28 16:24:09,484] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:09,485] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,486] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,487] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-28 16:24:09,488] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,489] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,490] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,491] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:24:09,492] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,493] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,494] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,495] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,496] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,497] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,498] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,499] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,500] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:24:09,501] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,501] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,502] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,503] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,504] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,505] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:24:09,506] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,506] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,507] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,508] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,509] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,509] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,510] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,511] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-28 16:24:09,512] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-28 16:24:09,513] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,514] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,515] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,516] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,517] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,518] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-28 16:24:09,520] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,522] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-28 16:24:09,523] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,524] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,525] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,526] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,527] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,528] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable()]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7bf5a531cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,529] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,530] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x7bf4cc6fd790, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,531] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,532] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-28 16:24:09,533] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x7bf4cc5ec4b0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-28 16:24:09,534] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:24:09,535] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,536] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:24:09,537] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,538] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:24:09,539] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,540] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,541] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,542] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,543] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,544] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,545] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,547] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,548] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,549] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,550] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,551] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,552] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,553] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,554] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,555] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,556] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,557] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,558] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,559] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,560] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,561] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,562] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-28 16:24:09,563] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,564] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,565] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,566] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,567] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,568] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,569] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,570] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,571] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x7bf4cc749e60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,572] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,573] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,574] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,575] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,576] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,578] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-28 16:24:09,578] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,579] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,580] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,581] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:24:09,582] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,583] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7bf5a55425c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,584] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,586] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,587] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-28 16:24:09,588] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>)]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,589] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,590] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,591] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,593] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7bf5a5541940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,595] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,598] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,599] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,600] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7bf5a531cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,601] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,604] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-28 16:24:09,606] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,607] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-28 16:24:09,611] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,612] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-28 16:24:09,613] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-28 16:24:09,613] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,614] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,615] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-28 16:24:09,616] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,617] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-28 16:24:09,618] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,619] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-28 16:24:09,620] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-28 16:24:09,620] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,621] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,622] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,623] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,624] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,625] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,626] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,627] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,627] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,628] [36/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-28 16:24:09,630] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-28 16:24:09,631] [36/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-28 16:24:09,632] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,633] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,633] [36/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,634] [36/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,636] [36/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_58 =====\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.234 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,638] [36/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_58 <eval_with_key>.234 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7bf5a601d8a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7bf5a531cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7bf5a601dbc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7bf5a531cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7bf5a531cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7bf5a55425c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7bf5a5541940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7bf5a531cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-28 16:24:09,640] [36/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_58 =====\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,644] [36/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,648] [36/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,649] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232187472)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,650] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,650] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 117923504)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:24:09,651] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 117923504)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,652] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 117923504)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-28 16:24:09,653] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,653] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 117923504)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,654] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,655] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,656] [36/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-28 16:24:09,657] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,658] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,659] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,660] [36/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,661] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,661] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,662] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,662] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,663] [36/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,668] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,669] [37/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-28 16:24:09,670] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,671] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,672] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:24:09,673] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,674] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,676] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,677] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,678] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,680] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,681] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,682] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,683] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,684] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,685] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,686] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,687] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,688] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,689] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,690] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7bf4c6fb40e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,691] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,692] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,693] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,694] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,695] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,696] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,697] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,698] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,699] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,700] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,701] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,702] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,703] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,704] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,705] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,705] [37/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,706] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,707] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,708] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7bf4cc833a50, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,709] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,710] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-28 16:24:09,711] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,712] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-28 16:24:09,714] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7bf5a6b38150>)]\n",
      "[2024-12-28 16:24:09,715] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,716] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,717] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,718] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,719] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-28 16:24:09,720] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable())]\n",
      "[2024-12-28 16:24:09,721] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,722] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7bf4c6fb49a0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,723] [37/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-28 16:24:09,724] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,725] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,726] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,727] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,728] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,729] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,733] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,736] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,737] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,741] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,742] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-28 16:24:09,746] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0xbb59980, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7230880, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-28 16:24:09,747] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,748] [37/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-28 16:24:09,749] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-28 16:24:09,750] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-28 16:24:09,751] [37/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,752] [37/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_59 =====\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.235 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,753] [37/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_59 <eval_with_key>.235 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7bf5a531cde0>  (add_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-28 16:24:09,754] [37/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_59 =====\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,757] [37/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,761] [37/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,761] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291232196240)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,762] [37/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,762] [37/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,763] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-28 16:24:09,764] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,765] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,766] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,767] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-28 16:24:09,768] [37/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,769] [37/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,772] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,772] [38/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:30\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-28 16:24:09,773] [38/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,775] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-28 16:24:09,776] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable()]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,777] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7bf5a531cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_414314/1905900009.py:33\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,778] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:24:09,779] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,780] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,781] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,781] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,782] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,782] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_414314/1905900009.py:36\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,783] [38/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:38\n",
      "[2024-12-28 16:24:09,789] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if custom_forward_fn is not None:\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn []\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [SkipFilesVariable()]\n",
      "[2024-12-28 16:24:09,790] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [SkipFilesVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-28 16:24:09,791] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 382 [ConstantVariable(bool)]\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,792] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_forward_fn [NullVariable]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, SkipFilesVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, SkipFilesVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,793] [38/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0> from user code at:\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_414314/1905900009.py\", line 40, in <resume in forward>\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,794] [38/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>], graph_break=True)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_60 =====\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.236 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:33, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:36, code: logits = self.linear(pooled_output)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___linear,)\n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,796] [38/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_60 <eval_with_key>.236 opcode         name              target                                                   args                    kwargs\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------  -------------------------------------------------------  ----------------------  ----------\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_       L_stack0_0_                                              ()                      {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean              <built-in method mean of type object at 0x7bf5a531cde0>  (l_stack0_0_,)          {'dim': 1}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear  L__self___linear                                         (mean,)                 {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output            output                                                   ((l__self___linear,),)  {}\n",
      "[2024-12-28 16:24:09,797] [38/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_60 =====\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,798] [38/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,803] [38/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,804] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:24:09,804] [38/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_414314/1905900009.py:36 in <resume in forward>\n",
      "[2024-12-28 16:24:09,805] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,805] [38/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-28 16:24:09,806] [38/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,806] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['custom_forward_fn'], 136291217694912)      # if custom_forward_fn is not None:  # mp/ipykernel_414314/1905900009.py:38 in <resume in forward>\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,807] [38/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,808] [38/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,808] [38/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,811] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-28 16:24:09,811] [39/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:40\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 custom_logits = custom_forward_fn(logits)\n",
      "[2024-12-28 16:24:09,812] [39/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'] (1, 10) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 378 [TensorVariable()]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST custom_logits [TensorVariable()]\n",
      "[2024-12-28 16:24:09,814] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 386 []\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,815] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST custom_logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_414314/1905900009.py:45\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,816] [39/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-28 16:24:09,818] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_414314/1905900009.py:47\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-28 16:24:09,819] [39/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 47 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_62 =====\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.237 class GraphModule(torch.nn.Module):\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_ : torch.Tensor):\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_ = L_stack0_\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_414314/1905900009.py:45, code: probs = self.softmax(custom_logits)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l_stack0_);  l_stack0_ = None\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-28 16:24:09,820] [39/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_62 <eval_with_key>.237 opcode       name               target             args                     kwargs\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  -----------------  -----------------  -----------------------  --------\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_stack0_          L_stack0_          ()                       {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___softmax  L__self___softmax  (l_stack0_,)             {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output             output             ((l__self___softmax,),)  {}\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_62 =====\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_: (1, 10)\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,821] [39/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 136291221396816)                   # probs = self.softmax(custom_logits)  # mp/ipykernel_414314/1905900009.py:45 in <resume in forward>\n",
      "[2024-12-28 16:24:09,823] [39/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # probs = self.softmax(custom_logits)  # mp/ipykernel_414314/1905900009.py:45 in <resume in forward>\n",
      "[2024-12-28 16:24:09,824] [39/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-28 16:24:09,824] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,825] [39/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-28 16:24:09,826] [39/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 10], stride=[10, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 7\n",
      "Graph Break Count: 6\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 30 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 4:\n",
      "    Reason: call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7bf5a531cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7bf5a601d8a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <function _exit_autocast at 0x7bf5a601dbc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7bf5a55425c0>\n",
      "    <function dropout at 0x7bf5a5541940>\n",
      "    <built-in method matmul of type object at 0x7bf5a531cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7bf5a531cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7bf5a531cde0>\n",
      "  Ops 7:\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 6:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6fc49f0; to 'Tensor' at 0x7bf4c6fb8710>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 9:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 11:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 12:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 17:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 18:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 21:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 22:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 24:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 29:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 32:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 33:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 36:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 39:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 41:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 43:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55be520; to 'Tensor' at 0x7bf4c5563c50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 45:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 46:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 48:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 49:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 50:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44657b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 53:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 40477776)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6bbec00; to 'Logger' at 0x7bf4e41f4950>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b34fc9f0; to 'type' at 0x269a450 (Logger)>\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 56:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 57:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 64:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 66:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 67:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 68:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232187472)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5fcffb0; to 'LlamaAttention' at 0x7bf4c67b0450>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4cc4f7ba0; to 'type' at 0xbc918e0 (LlamaAttention)>\n",
      "  Guard 72:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 73:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3fb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 78:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 79:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55be520; to 'Tensor' at 0x7bf4c5563c50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 80:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b5cb80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 82:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE', 'GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()', '___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 84:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 86:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 87:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 88:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c639eac0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 90:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 91:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 98:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 99:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c639eac0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 101:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44767a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 102:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 103:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 104:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6740f90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 106:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e3fb50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 107:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 117923504)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6b5cb80; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 109:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 110:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 111:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 112:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 113:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 116:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 117:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 120:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291232196240)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c679aed0; to 'LlamaDecoderLayer' at 0x7bf4c67b2690>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c6f972e0; to 'type' at 0xbc9c740 (LlamaDecoderLayer)>\n",
      "  Guard 123:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 124:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 127:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 128:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c6736930; to 'Tensor' at 0x7bf4c5175490>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 130:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 132:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5ac4e0b30; to 'type' at 0x7bf5a5319080 (dtype)>\n",
      "  Guard 134:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 135:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 137:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b449bce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 138:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 141:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44a0950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 144:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 145:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c5e782c0; to 'Tensor' at 0x7bf4c5983dd0>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 149:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 150:\n",
      "    Name: \"L['custom_forward_fn']\"\n",
      "    Source: local\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['custom_forward_fn'], 136291217694912)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b4467a10; to 'type' at 0x86f540 (function)>\n",
      "  Guard 151:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c55df5b0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 153:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 154:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5b44836a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 155:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 156:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 160:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "  Guard 161:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 162:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c514e9d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf5a6bcb060; to 'torch._C._TensorMeta' at 0x7075eb0 (Tensor)>\n",
      "  Guard 163:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 164:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 165:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 166:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 167:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 168:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 136291221396816)\"]\n",
      "    Object Weakref: <weakref at 0x7bf4c67342c0; to 'LlamaWithCustomOp' at 0x7bf4c5d65d50>\n",
      "    Guarded Class Weakref: <weakref at 0x7bf4c63773d0; to 'type' at 0x2a4e77d0 (LlamaWithCustomOp)>\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ------------------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.2056, 0.1625, 0.0845, 0.3021, 0.1022, 0.0381, 0.0155\n",
      "OutputGraph.call_user_compiler   0.0003, 0.0005, 0.0004, 0.0005, 0.0005, 0.0004, 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom op eager\n",
    "explanation_custom = torch._dynamo.explain(model_w_custom_op)(input_ids, custom_forward_fn=scale_by_max_eager)\n",
    "print(explanation_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Capturing expected output for Graph break at `custom_forward_fn`\n",
    "\n",
    "[2024-12-28 16:24:09,795] [38/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call torch._dynamo.disable() wrapped function <function scale_by_max_eager at 0x7bf4c59de0c0>', user_stack=[<FrameSummary file /tmp/ipykernel_414314/1905900009.py, line 40 in <resume in forward>>], graph_break=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
