{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Before we delve into trying to `jit` compile a pytorch module, it is important\n",
    "to understand what `Pytorch 2.0` brings with `torch.compile` and why `torch.jit.script`\n",
    "or `FX tracing` weren't good enough and what were the limitations.\n",
    "\n",
    "Refer to: https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html#comparison-to-torchscript-and-fx-tracing\n",
    "\n",
    "Essentially, scripting or tracing either error out or only capture the activated path in control\n",
    "flow instructions thus being erroneous or non-functional.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "We use `torch.dynamo` here to capture the graphs generated for the corresponding `nn.Module` and understand\n",
    "the number of `graph-breaks` in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/gaurav/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "access_token = os.environ[\"HF_ACCESS_TOKEN\"]\n",
    "login(token=access_token)\n",
    "\n",
    "os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"  # Dumps files in `torch_compile_debug/`\n",
    "\n",
    "# Choose which logs to enable\n",
    "# os.environ[\"TORCH_LOGS\"] = \"+dynamo,+aot_graphs,+inductor,+guards,+graph\"\n",
    "os.environ[\"TORCH_LOGS\"] = \"+dynamo\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch._dynamo import optimize\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LLaMAFirstLayerModel(nn.Module):\n",
    "    def __init__(self, llama_model_name: str, output_dim: int):\n",
    "        super(LLaMAFirstLayerModel, self).__init__()\n",
    "\n",
    "        # Load the LLaMA model\n",
    "        full_llama = AutoModel.from_pretrained(llama_model_name)\n",
    "\n",
    "        # Extract and store the embedding layer\n",
    "        self.embed_tokens = full_llama.embed_tokens\n",
    "\n",
    "        # Extract and store the first decoder layer\n",
    "        self.first_layer = full_llama.layers[0]\n",
    "\n",
    "        # Linear layer to map to output dimensions\n",
    "        llama_hidden_dim = full_llama.config.hidden_size\n",
    "        self.linear = nn.Linear(llama_hidden_dim, output_dim)\n",
    "\n",
    "        # Softmax for output probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Explicit typing of input_ids and attention_mask for TorchScript\n",
    "    def forward(self, input_ids):\n",
    "        # Generate embeddings\n",
    "        embeddings = self.embed_tokens(input_ids)\n",
    "\n",
    "        # Check if position_ids need to be explicitly handled\n",
    "        position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        # Pass through the first layer with position_ids\n",
    "        layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
    "\n",
    "        # Pool the output (mean along sequence dimension)\n",
    "        pooled_output = torch.mean(layer_output, dim=1)\n",
    "\n",
    "        # Map to output dimension\n",
    "        logits = self.linear(pooled_output)\n",
    "\n",
    "        # Apply softmax\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # Replace with actual model name\n",
    "output_dim = 10  # Number of classes for classification\n",
    "\n",
    "# Initialize the model\n",
    "model = LLaMAFirstLayerModel(llama_model_name, output_dim).to(\"cuda\")\n",
    "\n",
    "# Example tokenizer and input\n",
    "tokenizer = AutoTokenizer.from_pretrained(llama_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "example_text = [\"This is an example input.\"]\n",
    "inputs = tokenizer(example_text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:694: UserWarning: explain(f, *args, **kwargs) is deprecated, use explain(f)(*args, **kwargs) instead.  If you don't migrate, we may break your explain call in the future if your user defined kwargs conflict with future kwargs added to explain(f).\n",
      "  warnings.warn(\n",
      "[2024-12-24 18:09:11,453] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,453] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,454] torch._dynamo.eval_frame: [DEBUG] skipping helper /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,454] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,454] torch._dynamo.eval_frame: [DEBUG] skipping enable_dynamic /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-24 18:09:11,454] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,454] torch._dynamo.eval_frame: [DEBUG] skipping _wrapped_call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-24 18:09:11,455] torch._dynamo.eval_frame: [DEBUG] skipping _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-24 18:09:11,455] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:11,457] [0/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_1020204/343866.py:26\n",
      "[2024-12-24 18:09:11,459] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:26\n",
      "[2024-12-24 18:09:11,459] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-24 18:09:11,483] [0/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:09:11,484] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,485] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:28\n",
      "[2024-12-24 18:09:11,485] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:09:11,485] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,485] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,486] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,486] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,486] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,487] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_1020204/343866.py:28\n",
      "[2024-12-24 18:09:11,487] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:09:11,487] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,490] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-24 18:09:11,490] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:09:11,490] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:09:11,491] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,491] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,491] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:11,492] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,492] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-24 18:09:11,492] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:11,493] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,493] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,493] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,493] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-24 18:09:11,494] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:09:11,494] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:09:11,494] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:09:11,501] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:09:11,501] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:09:11,501] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:09:11,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:09:11,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,504] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,504] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:09:11,504] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:09:11,504] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:11,505] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-24 18:09:11,505] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:09:11,505] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:09:11,505] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,507] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,507] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,507] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,507] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,508] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:09:11,508] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:09:11,508] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,508] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,511] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,511] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:11,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,512] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,512] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:11,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,513] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:11,513] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,513] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,519] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,519] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,520] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,521] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,522] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,522] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,522] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:11,523] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,523] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,523] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,523] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,523] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,524] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:11,524] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,524] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,525] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,526] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,526] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,526] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,526] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:11,527] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,527] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,527] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,528] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,528] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,528] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,529] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:11,530] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,530] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:11,531] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,531] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,531] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,532] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,532] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,532] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,533] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a052bf0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-24 18:09:11,534] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,534] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:09:11,535] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,535] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,535] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,536] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,537] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,538] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,538] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,539] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,539] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:11,539] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,540] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,543] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,543] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:11,544] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,544] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,544] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:11,544] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,545] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,545] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:11,546] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,546] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,546] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,547] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,547] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,548] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,548] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,549] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,549] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,549] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,550] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,550] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,550] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,550] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,551] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,552] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,553] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,553] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,553] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,554] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,555] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,555] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,555] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,555] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,555] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:11,556] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,556] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:11,556] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,556] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,556] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,557] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,557] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,557] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,557] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:11,558] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,558] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:09:11,558] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,559] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,559] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:09:11,559] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,559] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:09:11,560] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,560] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,560] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:11,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:09:11,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:11,563] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:11,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:11,565] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,565] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:11,565] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,566] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,566] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,566] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:09:11,568] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:09:11,568] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,569] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,569] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,569] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,569] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:11,571] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:09:11,572] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:09:11,572] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,573] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,573] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,573] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,574] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,574] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,574] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,575] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:09:11,576] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,576] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,576] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,576] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:09:11,577] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,578] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:11,578] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,579] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,580] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:11,580] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,580] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,580] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,582] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,582] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,583] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,583] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,583] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,585] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,585] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,585] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,586] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,586] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,588] [0/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:09:11,588] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,589] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,591] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:11,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,593] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,594] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,594] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,594] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,596] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,596] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,596] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:11,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:11,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:11,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,602] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,602] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,603] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-24 18:09:11,603] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,604] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,604] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,604] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-24 18:09:11,604] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-24 18:09:11,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,606] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,606] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-24 18:09:11,606] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:09:11,606] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,606] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-24 18:09:11,607] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,607] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,607] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-24 18:09:11,608] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,608] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,608] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-24 18:09:11,608] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,609] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,610] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,611] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,611] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-24 18:09:11,612] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,615] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,615] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:11,615] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,615] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,615] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:11,616] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,616] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,617] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:11,617] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,619] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,619] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,622] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,622] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,623] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,624] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,626] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,627] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,627] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,627] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,627] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:11,627] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,628] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:09:11,628] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,628] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,628] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,630] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:09:11,630] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,630] [0/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,631] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:09:11,633] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,633] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:09:11,634] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:09:11,634] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:09:11,634] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:09:11,635] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:09:11,635] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:09:11,635] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:09:11,635] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,636] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,636] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:09:11,636] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:09:11,637] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:09:11,638] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:11,638] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:11,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:09:11,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,640] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,640] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,640] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,640] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:09:11,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,642] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:09:11,643] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,645] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,646] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,647] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,647] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,647] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,647] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,649] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,649] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,649] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,650] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,650] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,650] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,654] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,655] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,655] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,655] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,657] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,658] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,659] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,660] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,660] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,660] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,664] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,664] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,664] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,664] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,665] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,666] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,666] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,666] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,667] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,667] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,667] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,744] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,744] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:09:11,745] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:11,746] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:11,746] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,748] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,748] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,749] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,749] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,749] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,749] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,749] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:11,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:11,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,753] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,753] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,753] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:11,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:09:11,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:11,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:11,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,758] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,758] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,759] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,760] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,760] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,760] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,761] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:11,762] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:11,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,764] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,764] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,764] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:11,765] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,765] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,765] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,765] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:09:11,766] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:11,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:11,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,768] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,773] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,773] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,774] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,774] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,774] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,776] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:11,777] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:11,778] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,778] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,779] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,780] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,780] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,780] [0/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:11,782] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,782] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,782] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:09:11,783] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:09:11,783] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,784] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,785] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,785] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,785] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:11,786] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:09:11,787] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:09:11,788] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,788] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:09:11,789] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:09:11,789] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-24 18:09:11,789] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:11,789] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:11,790] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:11,790] [0/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:11,791] [0/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:09:11,791] [0/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:09:11,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:11,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,792] [0/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:11,793] [0/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:11,793] [0/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x74731a052bf0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-24 18:09:11,793] [0/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:09:11,794] [0/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:11,794] [0/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,795] [0/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:11,795] [0/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:09:11,799] [0/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:11,799] [0/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_1020204/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_0 =====\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.0 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:11,800] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_0 <eval_with_key>.0 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7473c3d1cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-24 18:09:11,801] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_0 =====\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:11,804] [0/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:11,808] [0/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:11,849] [0/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:11,850] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749707920)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1020204/343866.py:28 in forward\n",
      "[2024-12-24 18:09:11,851] [0/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1020204/343866.py:28 in forward\n",
      "[2024-12-24 18:09:11,851] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 115763376)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_1020204/343866.py:31 in forward\n",
      "[2024-12-24 18:09:11,852] [0/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:11,852] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:11,853] [0/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:11,853] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:11,854] [0/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:11,855] [0/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:11,858] torch._dynamo.eval_frame: [DEBUG] skipping _fn /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-24 18:09:11,858] torch._dynamo.eval_frame: [DEBUG] skipping nothing /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2024-12-24 18:09:11,880] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,880] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/contextlib.py\n",
      "[2024-12-24 18:09:11,880] torch._dynamo.eval_frame: [DEBUG] skipping __getattr__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
      "[2024-12-24 18:09:11,881] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:11,882] [1/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-24 18:09:11,883] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-24 18:09:11,883] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:09:11,883] [1/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:11,884] [1/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:09:11,885] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,885] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-24 18:09:11,885] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,886] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:11,887] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,888] [1/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:11,890] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,891] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,891] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:11,891] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,892] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,892] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,893] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,893] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,893] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,894] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,894] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,894] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,894] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,895] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,895] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,896] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,896] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,896] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,897] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,897] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,897] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,897] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,898] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,899] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,900] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,901] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,901] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,901] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,901] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,901] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:11,902] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,902] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:11,902] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,903] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,903] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,903] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,903] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,903] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,904] [1/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:11,904] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,904] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:09:11,905] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,905] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,905] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:09:11,905] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,905] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:09:11,907] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,907] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,907] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:11,907] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,907] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:11,908] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,909] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,910] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,910] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,910] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,910] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:09:11,910] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:09:11,911] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,911] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,911] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,911] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,911] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:11,913] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:09:11,914] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:09:11,915] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,915] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,919] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,919] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,920] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,920] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:11,920] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,921] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:09:11,922] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,922] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,922] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:11,922] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:09:11,927] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,928] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:11,928] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,928] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,929] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:11,929] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,929] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,929] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,931] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,931] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:11,931] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,931] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,931] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,932] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,932] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,932] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:11,932] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,933] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,933] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,933] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,934] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,934] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,934] [1/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:09:11,935] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,935] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,936] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,937] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,937] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,937] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:11,937] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:11,938] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:11,938] [1/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:11,938] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:11,938] [1/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-24 18:09:11,939] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-24 18:09:11,940] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-24 18:09:11,941] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-24 18:09:11,942] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:09:11,943] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-24 18:09:11,944] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,945] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:11,945] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,945] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,945] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-24 18:09:11,946] [1/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:11,949] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,949] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:11,950] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,950] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,950] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:11,950] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:11,950] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:11,951] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:11,951] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,951] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:11,951] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:11,951] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,952] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,953] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,954] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,955] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,956] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:11,957] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,958] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,958] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,958] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:11,958] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:11,958] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:11,959] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:09:11,959] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,959] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,960] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:09:11,961] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:11,961] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:11,961] [1/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,961] [1/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:09:11,962] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,962] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:09:11,963] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:09:11,963] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:09:11,963] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:09:11,963] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:09:11,963] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:09:11,964] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:09:11,965] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:11,965] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:11,965] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:09:11,966] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,966] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,966] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,967] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,967] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:09:11,967] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,967] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,967] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:09:11,968] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,968] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,968] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:11,969] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,969] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,969] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,969] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,969] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,970] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,970] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,970] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,970] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,970] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,974] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,975] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,975] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,975] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,975] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,976] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,980] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,980] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,980] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,980] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:11,981] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,984] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:11,985] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,986] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,986] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,986] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,986] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:11,987] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,987] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,987] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,987] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,987] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:11,988] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:11,989] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:11,990] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,990] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,991] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,991] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,991] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,991] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:11,992] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:11,993] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:09:11,993] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:11,995] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:09:11,996] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:11,999] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:11,999] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:11,999] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,000] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,000] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,000] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,001] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,001] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,002] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,002] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,002] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,004] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,004] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,005] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,006] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,006] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,006] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,006] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,006] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,008] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,008] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,008] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,008] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:09:12,008] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:12,009] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:12,009] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,009] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,009] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,010] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,010] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,010] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,010] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,011] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,011] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,011] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,012] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,012] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,013] [1/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,014] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,015] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:12,016] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:09:12,016] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:12,017] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,018] [1/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,018] [1/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:12,018] [1/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:09:12,019] [1/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:09:12,019] [1/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:09:12,019] [1/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,019] [1/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:12,019] [1/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:09:12,021] [1/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:12,021] [1/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:09:12,023] [1/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_2 =====\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.1 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_2 <eval_with_key>.1 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7473c3d1cde0>  (add,)                                    {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-24 18:09:12,024] [1/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_2 =====\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,026] [1/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,030] [1/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:12,030] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749745808)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,031] [1/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,031] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,032] [1/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,032] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,032] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,033] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 115763376)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-24 18:09:12,033] [1/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,034] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,034] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,034] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,034] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,035] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:09:12,035] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,035] [1/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,036] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,036] [1/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,036] [1/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-24 18:09:12,037] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,037] [1/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,037] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,038] [1/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,038] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,038] [1/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,039] [1/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,039] [1/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,040] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,040] [1/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,074] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,077] [2/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-24 18:09:12,078] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-24 18:09:12,078] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:09:12,079] [2/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:12,080] [2/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:09:12,081] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:09:12,082] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,083] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-24 18:09:12,083] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:09:12,083] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:09:12,083] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:09:12,084] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:12,084] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:12,084] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,085] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,086] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:09:12,086] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,086] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,086] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,087] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-24 18:09:12,087] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,087] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,087] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,087] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,088] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,088] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,088] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-24 18:09:12,088] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,088] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,091] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,091] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-24 18:09:12,091] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,091] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,091] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,092] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,094] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,094] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-24 18:09:12,094] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,094] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,095] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,096] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-24 18:09:12,096] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,096] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,097] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,098] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:09:12,098] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,098] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:09:12,098] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:12,098] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:12,099] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,099] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,099] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,100] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,101] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,102] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,103] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,104] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:09:12,104] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,104] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:09:12,104] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:12,104] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:12,105] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,105] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,105] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,105] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,106] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,107] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,108] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,108] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,108] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,108] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,109] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:09:12,109] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,109] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,109] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,110] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:09:12,110] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,110] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:09:12,110] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:09:12,110] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:09:12,111] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,111] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,111] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,111] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,111] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,112] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,112] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,112] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:09:12,112] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,112] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,113] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,113] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,114] [2/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,115] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,115] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-24 18:09:12,115] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:09:12,115] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:12,116] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:09:12,117] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:09:12,117] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-24 18:09:12,117] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:09:12,117] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:09:12,118] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:09:12,118] [2/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:12,118] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,118] [2/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,118] [2/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:09:12,119] [2/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:09:12,119] [2/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:09:12,120] [2/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_4 =====\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.2 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,121] [2/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_4 <eval_with_key>.2 opcode       name              target            args                                      kwargs\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-24 18:09:12,123] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_4 =====\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,124] [2/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:12,125] [2/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,126] [2/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,138] [2/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:12,138] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037686901648)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-24 18:09:12,139] [2/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-24 18:09:12,139] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,140] [2/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,140] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,140] [2/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,141] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-24 18:09:12,141] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,142] [2/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,142] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,142] [2/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,143] [2/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 38319184)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-24 18:09:12,144] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,144] [2/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,168] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,168] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* warning_once             /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/utils/logging.py 319\n",
      "[2024-12-24 18:09:12,169] torch._dynamo.eval_frame: [DEBUG] skipping warning /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,169] torch._dynamo.eval_frame: [DEBUG] skipping isEnabledFor /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,169] torch._dynamo.eval_frame: [DEBUG] skipping _acquireLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,169] torch._dynamo.eval_frame: [DEBUG] skipping disable /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping getEffectiveLevel /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping _releaseLock /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping _log /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping findCaller /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping <lambda> /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,170] torch._dynamo.eval_frame: [DEBUG] skipping _is_internal_frame /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,171] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,171] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* normcase             <frozen posixpath> 52\n",
      "[2024-12-24 18:09:12,172] torch._dynamo.eval_frame: [DEBUG] skipping makeRecord /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,172] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,172] torch._dynamo.eval_frame: [DEBUG] skipping getLevelName /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,172] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,172] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* basename             <frozen posixpath> 140\n",
      "[2024-12-24 18:09:12,173] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,173] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _get_sep             <frozen posixpath> 41\n",
      "[2024-12-24 18:09:12,173] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,174] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* splitext             <frozen posixpath> 117\n",
      "[2024-12-24 18:09:12,174] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,174] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _splitext             <frozen genericpath> 121\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping current_thread /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping current_process /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping name /home/gaurav/anaconda3/lib/python3.11/multiprocessing/process.py\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,175] torch._dynamo.eval_frame: [DEBUG] skipping filter /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping callHandlers /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping handle /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping acquire /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping emit /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,176] torch._dynamo.eval_frame: [DEBUG] skipping getMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._dynamo.eval_frame: [DEBUG] skipping usesTime /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._dynamo.eval_frame: [DEBUG] skipping formatMessage /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._dynamo.eval_frame: [DEBUG] skipping format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._dynamo.eval_frame: [DEBUG] skipping _format /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,177] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,178] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* write             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 624\n",
      "[2024-12-24 18:09:12,178] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,178] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _is_master_process             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 519\n",
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
      "[2024-12-24 18:09:12,178] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,179] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _schedule_flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 546\n",
      "[2024-12-24 18:09:12,179] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,179] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* schedule             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 258\n",
      "[2024-12-24 18:09:12,179] torch._dynamo.eval_frame: [DEBUG] skipping is_alive /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,179] torch._dynamo.eval_frame: [DEBUG] skipping is_set /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,179] torch._dynamo.eval_frame: [DEBUG] skipping _wait_for_tstate_lock /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,180] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,180] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* _event_pipe             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 137\n",
      "[2024-12-24 18:09:12,180] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,180] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* send             /home/gaurav/anaconda3/lib/python3.11/site-packages/zmq/sugar/socket.py 621\n",
      "[2024-12-24 18:09:12,181] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,181] torch._dynamo.convert_frame: [DEBUG] skipping because no torch.* flush             /home/gaurav/anaconda3/lib/python3.11/site-packages/ipykernel/iostream.py 561\n",
      "[2024-12-24 18:09:12,181] torch._dynamo.eval_frame: [DEBUG] skipping ident /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,181] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,181] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,182] torch._dynamo.eval_frame: [DEBUG] skipping wait /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,182] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,182] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/gaurav/anaconda3/lib/python3.11/threading.py\n",
      "[2024-12-24 18:09:12,182] torch._dynamo.eval_frame: [DEBUG] skipping release /home/gaurav/anaconda3/lib/python3.11/logging/__init__.py\n",
      "[2024-12-24 18:09:12,182] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,185] [3/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:09:12,186] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:09:12,186] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:09:12,187] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:09:12,189] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:09:12,191] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:09:12,192] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:09:12,193] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:12,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-24 18:09:12,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:09:12,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,194] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,195] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,196] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,196] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,196] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-24 18:09:12,196] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-24 18:09:12,196] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,197] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:12,199] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,200] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,200] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:12,200] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,200] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,201] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,202] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,202] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,202] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,203] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,204] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,204] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,204] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,204] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,204] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,205] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,206] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,206] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,206] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,207] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,208] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:12,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:12,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,209] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:12,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,210] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,211] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,211] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,211] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,211] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7473d804a670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-24 18:09:12,212] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,212] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-24 18:09:12,212] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-24 18:09:12,212] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-24 18:09:12,213] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-24 18:09:12,214] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-24 18:09:12,214] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,214] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,214] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,214] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-24 18:09:12,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,215] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,216] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,216] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,216] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,216] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,216] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9bfcd00, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-24 18:09:12,217] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,217] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-24 18:09:12,217] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,218] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,218] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-24 18:09:12,218] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-24 18:09:12,218] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,218] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,219] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,220] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,220] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,220] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:09:12,220] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,221] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,221] [3/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:09:12,222] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,222] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,222] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:09:12,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,223] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:09:12,224] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,226] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-24 18:09:12,226] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,227] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,227] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,227] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:09:12,227] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:09:12,227] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:09:12,228] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:09:12,228] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-24 18:09:12,229] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-24 18:09:12,229] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:09:12,230] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,231] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,232] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,233] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,234] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:09:12,234] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,234] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,234] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:09:12,234] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,236] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-24 18:09:12,236] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,237] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,237] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,237] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:09:12,237] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:09:12,238] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-24 18:09:12,238] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,238] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-24 18:09:12,238] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:09:12,238] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-24 18:09:12,239] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:09:12,239] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,239] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,239] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-24 18:09:12,240] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-24 18:09:12,240] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-24 18:09:12,240] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,240] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-24 18:09:12,241] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-24 18:09:12,241] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,241] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-24 18:09:12,242] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,242] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,242] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-24 18:09:12,243] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,244] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,244] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-24 18:09:12,245] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-24 18:09:12,245] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,245] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,245] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,247] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-24 18:09:12,247] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-24 18:09:12,247] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,247] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,248] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,248] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,249] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,249] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,250] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,250] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,250] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:09:12,251] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,251] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,252] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,252] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:09:12,253] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,253] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,253] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:09:12,253] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,254] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,254] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,254] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,256] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,257] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,257] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,258] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,258] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,258] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,258] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,258] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,259] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,261] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,261] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:09:12,261] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,262] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,263] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,263] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,263] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,263] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:09:12,263] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,264] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,264] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,265] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,265] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:09:12,265] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,266] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,266] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,266] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-24 18:09:12,266] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,266] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,267] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-24 18:09:12,267] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-24 18:09:12,267] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,267] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-24 18:09:12,267] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-24 18:09:12,268] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,268] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,268] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-24 18:09:12,268] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,268] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,269] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-24 18:09:12,269] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-24 18:09:12,269] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,269] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-24 18:09:12,269] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-24 18:09:12,270] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,270] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,270] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-24 18:09:12,271] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-24 18:09:12,272] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,272] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:09:12,272] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:09:12,272] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-24 18:09:12,272] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,273] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:12,273] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,273] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:09:12,273] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,274] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:09:12,275] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,275] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:09:12,275] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-24 18:09:12,275] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-24 18:09:12,275] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,276] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:12,276] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,276] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:09:12,276] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,277] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:09:12,277] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,277] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:09:12,278] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:09:12,278] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:09:12,278] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:12,279] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:09:12,280] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,280] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,280] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,281] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,281] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:09:12,281] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,281] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:09:12,281] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,282] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:12,282] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:09:12,283] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,283] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,284] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,284] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:09:12,284] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:09:12,284] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,285] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,285] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x9bfcd00, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-24 18:09:12,286] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,287] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,287] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,287] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,288] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,288] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,288] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7473d804a670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-24 18:09:12,288] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,288] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,289] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,289] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,289] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:09:12,289] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-24 18:09:12,290] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-24 18:09:12,290] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-24 18:09:12,290] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-24 18:09:12,290] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,291] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,291] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,291] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,291] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,291] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x74731a06e430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,292] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-24 18:09:12,293] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,293] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,293] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,293] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:09:12,293] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:09:12,294] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:09:12,294] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,295] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,295] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,295] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,295] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,296] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:09:12,296] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,296] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,297] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-24 18:09:12,297] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:09:12,297] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:09:12,297] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,297] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,298] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,298] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,298] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,299] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-24 18:09:12,300] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,301] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,302] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:09:12,303] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:09:12,303] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:09:12,303] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,303] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:09:12,304] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-24 18:09:12,304] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,305] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,305] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,305] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,306] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:09:12,306] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,306] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,306] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,306] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,308] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-24 18:09:12,308] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,308] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,308] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:09:12,308] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:09:12,309] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:09:12,309] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-24 18:09:12,310] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-24 18:09:12,310] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,311] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,311] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,311] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,311] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,311] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:09:12,312] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,312] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,312] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,312] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,313] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-24 18:09:12,313] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,313] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,313] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,313] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,314] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,314] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,314] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,314] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,314] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-24 18:09:12,315] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,315] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,315] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:09:12,315] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,316] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,316] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,316] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,316] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,316] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,317] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,317] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:09:12,317] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,317] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,318] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:09:12,319] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,320] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,320] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,320] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-24 18:09:12,320] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-24 18:09:12,320] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,321] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:09:12,322] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,323] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:09:12,324] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-24 18:09:12,324] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,324] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,325] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,325] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,325] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:09:12,326] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,326] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,326] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,326] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,327] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-24 18:09:12,327] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,327] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,328] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:09:12,328] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:09:12,328] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:09:12,328] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-24 18:09:12,329] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-24 18:09:12,329] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,330] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,330] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,330] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,331] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,331] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:09:12,331] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,332] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,332] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,332] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,333] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-24 18:09:12,333] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,333] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,333] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,334] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-24 18:09:12,335] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,336] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,336] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:09:12,336] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,336] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,336] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,337] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,337] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,337] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,338] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,338] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:09:12,338] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,339] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,339] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,339] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,339] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-24 18:09:12,340] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,340] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,340] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,340] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,341] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,342] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x74731a06e430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-24 18:09:12,342] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,342] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,343] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,344] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,344] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-24 18:09:12,344] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:09:12,344] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-24 18:09:12,344] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,345] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,345] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,345] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,346] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,346] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-24 18:09:12,346] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:09:12,346] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,347] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:09:12,347] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,347] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-24 18:09:12,348] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,348] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,348] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-24 18:09:12,348] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,348] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-24 18:09:12,349] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-24 18:09:12,349] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,349] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,349] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,350] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,351] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,351] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,351] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,351] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,351] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,352] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,352] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,352] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,352] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,353] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,353] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,353] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,353] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,354] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:09:12,354] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,354] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,354] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,354] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,355] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,355] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,355] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,357] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:09:12,357] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:09:12,357] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,357] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,358] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:09:12,360] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,361] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,362] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,362] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,362] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,362] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,363] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,363] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:09:12,364] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,365] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,365] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,365] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,366] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-24 18:09:12,367] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,367] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-24 18:09:12,368] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-24 18:09:12,368] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,368] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,368] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,368] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,369] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,369] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-24 18:09:12,369] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-24 18:09:12,369] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,369] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,370] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,370] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,370] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,370] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,370] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,371] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,371] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,371] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,371] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,371] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,372] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,372] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,372] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,372] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,372] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:09:12,373] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,373] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,373] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:09:12,373] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,374] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,374] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,374] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,376] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:09:12,376] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,377] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,378] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,379] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,380] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,380] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,380] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,380] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,380] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,381] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,382] [3/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:09:12,382] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,382] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:09:12,382] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:09:12,382] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,383] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,383] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,383] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,383] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:09:12,384] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,385] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,386] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,386] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:09:12,386] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:09:12,386] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,387] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-24 18:09:12,388] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:12,388] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-24 18:09:12,388] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:09:12,389] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,391] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,392] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,392] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:09:12,392] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:09:12,392] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-24 18:09:12,392] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,393] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-24 18:09:12,393] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>)]\n",
      "[2024-12-24 18:09:12,394] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,394] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,394] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,394] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:12,394] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:12,395] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:12,395] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:09:12,395] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:09:12,395] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,397] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:09:12,398] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:12,398] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:09:12,398] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,398] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:09:12,399] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-24 18:09:12,400] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,400] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-24 18:09:12,400] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>)]\n",
      "[2024-12-24 18:09:12,401] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,401] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,401] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:12,401] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,402] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,402] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,402] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,403] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-24 18:09:12,403] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:09:12,403] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,403] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:09:12,404] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-24 18:09:12,404] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:09:12,404] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,404] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,404] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:09:12,405] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,407] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,407] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-24 18:09:12,407] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-24 18:09:12,408] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:09:12,408] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:09:12,408] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:12,408] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:09:12,409] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-24 18:09:12,409] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,409] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,409] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,409] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,410] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,410] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,410] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-24 18:09:12,410] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,411] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:09:12,411] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:09:12,411] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:09:12,411] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:09:12,411] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:09:12,412] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:09:12,414] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-24 18:09:12,414] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-24 18:09:12,414] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-24 18:09:12,415] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:09:12,415] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:09:12,415] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:09:12,415] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,416] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-24 18:09:12,416] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:09:12,416] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:09:12,416] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:09:12,416] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:09:12,417] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,417] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,418] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,418] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,418] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-24 18:09:12,418] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:09:12,418] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,420] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,420] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-24 18:09:12,420] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:09:12,421] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,421] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,421] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:09:12,422] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,423] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,423] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,424] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,424] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,424] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-24 18:09:12,424] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:09:12,424] [3/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,426] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,426] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-24 18:09:12,426] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-24 18:09:12,427] [3/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-24 18:09:12,428] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:09:12,428] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:09:12,428] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,428] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,428] [3/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,429] [3/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:09:12,429] [3/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:09:12,429] [3/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:09:12,430] [3/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_6 =====\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.3 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,431] [3/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_6 <eval_with_key>.3 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7473d83198a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7473c3d1cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7473d8319bc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7473c3d1cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7473c3d1cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7473c3d1cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7473cf53e5c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7473cf53d940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7473c3d1cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-24 18:09:12,433] [3/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_6 =====\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,437] [3/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:12,438] [3/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,438] [3/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,442] [3/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:12,443] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:09:12,443] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:09:12,443] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037686901648)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,444] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,444] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:09:12,444] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:09:12,445] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 115763376)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-24 18:09:12,445] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,446] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 115763376)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-24 18:09:12,446] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,446] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 115763376)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-24 18:09:12,447] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,447] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 115763376)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-24 18:09:12,447] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,448] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,448] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-24 18:09:12,448] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-24 18:09:12,449] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-24 18:09:12,449] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,449] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-24 18:09:12,449] [3/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,450] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,450] [3/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,451] [3/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-24 18:09:12,451] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-24 18:09:12,451] [3/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-24 18:09:12,452] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,452] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,452] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,452] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,453] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,453] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,453] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,453] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,454] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,454] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,454] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,455] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,455] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,486] torch._dynamo.eval_frame: [DEBUG] skipping __call__ /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-24 18:09:12,487] torch._dynamo.eval_frame: [DEBUG] skipping del_ten /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_subclasses/meta_utils.py\n",
      "[2024-12-24 18:09:12,487] torch._dynamo.eval_frame: [DEBUG] skipping pop /home/gaurav/anaconda3/lib/python3.11/weakref.py\n",
      "[2024-12-24 18:09:12,487] torch._dynamo.eval_frame: [DEBUG] skipping __hash__ /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/weak.py\n",
      "[2024-12-24 18:09:12,488] torch._dynamo.eval_frame: [DEBUG] skipping expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\n",
      "[2024-12-24 18:09:12,488] torch._dynamo.eval_frame: [DEBUG] skipping _expired /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/storage.py\n",
      "[2024-12-24 18:09:12,488] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,489] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:12,490] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:09:12,490] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:09:12,491] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:12,493] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:12,494] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,494] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-24 18:09:12,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,496] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,497] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-24 18:09:12,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:09:12,497] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,498] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:09:12,498] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-24 18:09:12,498] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:12,498] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,498] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,499] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,499] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,499] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,500] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-24 18:09:12,500] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-24 18:09:12,500] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,500] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,503] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,503] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:12,503] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,504] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,504] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:12,504] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,504] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,504] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:12,505] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,505] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,505] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,505] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,506] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,508] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,508] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,508] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,509] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,509] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,509] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,509] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,510] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,510] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,510] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,512] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,513] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,514] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:12,515] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:12,515] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,515] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:12,515] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,515] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,516] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,516] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,516] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,516] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,516] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:09:12,517] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:12,518] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,519] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:12,519] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:09:12,519] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,519] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:12,519] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:09:12,520] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:09:12,521] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,521] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,521] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,521] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:12,521] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:12,522] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:09:12,522] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:12,523] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,525] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:09:12,525] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,525] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,525] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,525] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:09:12,526] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,526] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,526] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,526] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,527] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:09:12,527] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,527] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,527] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,528] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,528] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,528] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,528] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,528] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,529] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,530] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,530] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,530] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,530] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,531] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,531] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:12,531] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,531] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,531] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:09:12,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:09:12,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,533] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:09:12,533] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,533] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:12,533] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,534] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,534] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,534] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:12,534] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,534] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:09:12,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,536] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-24 18:09:12,536] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-24 18:09:12,536] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,536] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,536] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,537] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,537] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,537] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-24 18:09:12,537] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-24 18:09:12,537] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,538] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,540] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,540] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:09:12,540] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,541] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,541] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:09:12,541] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,541] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,542] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:09:12,542] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,542] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:09:12,542] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:09:12,542] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,545] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,546] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,547] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,548] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:09:12,549] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:09:12,549] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable())]\n",
      "[2024-12-24 18:09:12,551] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:09:12,551] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,552] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,552] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:09:12,553] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:09:12,553] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:09:12,553] [4/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,553] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c10f60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-24 18:09:12,554] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,554] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-24 18:09:12,554] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-24 18:09:12,555] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-24 18:09:12,555] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-24 18:09:12,555] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-24 18:09:12,555] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-24 18:09:12,555] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,556] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,556] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:09:12,556] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,556] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,557] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:09:12,558] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,558] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,558] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,559] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,559] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,559] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,559] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,559] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,560] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,560] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,560] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,561] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,561] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,561] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,563] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,563] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,563] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:12,568] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,568] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,569] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,569] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,569] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,572] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,574] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,574] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,575] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,575] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,576] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,576] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,576] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:09:12,580] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,581] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,581] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,581] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,582] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,582] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,582] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,582] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,582] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,585] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-24 18:09:12,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-24 18:09:12,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-24 18:09:12,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-24 18:09:12,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x9c10f60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-24 18:09:12,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,587] [4/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:09:12,588] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:09:12,588] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-24 18:09:12,588] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-24 18:09:12,588] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-24 18:09:12,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:09:12,590] [4/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_7 =====\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.4 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,592] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_7 <eval_with_key>.4 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7473c3d1cde0>  (add_1,)                                           {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-24 18:09:12,593] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_7 =====\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,594] [4/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,597] [4/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:12,597] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749745808)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,597] [4/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,598] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,598] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,598] [4/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,599] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-24 18:09:12,600] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,600] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-24 18:09:12,600] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-24 18:09:12,601] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-24 18:09:12,601] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,601] [4/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,602] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,602] [4/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,602] [4/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-24 18:09:12,602] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,603] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,603] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,603] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,603] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,604] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,604] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,604] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:09:12,605] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,605] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,613] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:09:12,614] [5/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:09:12,615] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:09:12,615] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:09:12,616] [5/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:09:12,618] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:09:12,618] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:09:12,618] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,618] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-24 18:09:12,619] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,620] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,620] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:37\n",
      "[2024-12-24 18:09:12,620] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:09:12,620] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:09:12,621] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:09:12,622] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:09:12,622] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:09:12,622] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,622] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,623] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:09:12,623] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_1020204/343866.py:37\n",
      "[2024-12-24 18:09:12,623] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:09:12,623] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,625] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-24 18:09:12,625] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:40\n",
      "[2024-12-24 18:09:12,625] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:09:12,625] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,625] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_1020204/343866.py:40\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:09:12,626] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:09:12,629] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-24 18:09:12,629] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:43\n",
      "[2024-12-24 18:09:12,629] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-24 18:09:12,629] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:09:12,629] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_1020204/343866.py:43\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-24 18:09:12,630] [5/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-24 18:09:12,632] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-24 18:09:12,632] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:45\n",
      "[2024-12-24 18:09:12,632] [5/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-24 18:09:12,632] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-24 18:09:12,632] [5/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1020204/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_8 =====\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.5 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:09:12,633] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_8 <eval_with_key>.5 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7473c3d1cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_8 =====\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-24 18:09:12,634] [5/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:09:12,635] [5/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,635] [5/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function dynamo_graph_accumulating_compiler\n",
      "[2024-12-24 18:09:12,636] [5/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:09:12,636] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749707920)                   # logits = self.linear(pooled_output)  # mp/ipykernel_1020204/343866.py:40 in <resume in forward>\n",
      "[2024-12-24 18:09:12,637] [5/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_1020204/343866.py:40 in <resume in forward>\n",
      "[2024-12-24 18:09:12,637] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,637] [5/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:09:12,638] [5/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:09:12,638] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,639] [5/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,639] [5/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,639] [5/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:09:12,640] [5/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Count: 6\n",
      "Graph Break Count: 5\n",
      "Op Count: 44\n",
      "Break Reasons:\n",
      "  Break Reason 1:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /tmp/ipykernel_1020204/343866.py, line 34 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 2:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "  Break Reason 3:\n",
      "    Reason: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}\n",
      "    User Stack:\n",
      "      <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>\n",
      "Ops per Graph:\n",
      "  Ops 1:\n",
      "    <built-in method arange of type object at 0x7473c3d1cde0>\n",
      "  Ops 2:\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7473c3d1cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "  Ops 3:\n",
      "  Ops 4:\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <function _enter_autocast at 0x7473d83198a0>\n",
      "    <built-in function matmul>\n",
      "    <built-in method cat of type object at 0x7473c3d1cde0>\n",
      "    <function _exit_autocast at 0x7473d8319bc0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function _set_grad_enabled>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7473c3d1cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function mul>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in function neg>\n",
      "    <built-in method cat of type object at 0x7473c3d1cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "    <built-in function getitem>\n",
      "    <built-in function getitem>\n",
      "    <built-in method matmul of type object at 0x7473c3d1cde0>\n",
      "    <built-in function truediv>\n",
      "    <function softmax at 0x7473cf53e5c0>\n",
      "    <function dropout at 0x7473cf53d940>\n",
      "    <built-in method matmul of type object at 0x7473c3d1cde0>\n",
      "  Ops 5:\n",
      "    <built-in function add>\n",
      "    <built-in function add>\n",
      "    <built-in method rsqrt of type object at 0x7473c3d1cde0>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function mul>\n",
      "    <built-in function add>\n",
      "  Ops 6:\n",
      "    <built-in method mean of type object at 0x7473c3d1cde0>\n",
      "Out Guards:\n",
      "  Guard 1:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 2:\n",
      "    Name: \"L['self'].embed_tokens\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 3:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 4:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 5:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037749707920)\"]\n",
      "    Object Weakref: <weakref at 0x7473181d2d90; to 'LLaMAFirstLayerModel' at 0x74731c96d490>\n",
      "    Guarded Class Weakref: <weakref at 0x74731c971df0; to 'type' at 0x977dc60 (LLaMAFirstLayerModel)>\n",
      "  Guard 6:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 7:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 8:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['input_ids'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x74731867bb00; to 'Tensor' at 0x74731874ac30>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 9:\n",
      "    Name: \"L['self'].first_layer\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 10:\n",
      "    Name: \"L['input_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74731867bb00; to 'Tensor' at 0x74731874ac30>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 11:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 12:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dfed350; to 'Tensor' at 0x7473186c0470>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 13:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 14:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 15:\n",
      "    Name: \"L['cache_position']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['cache_position'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 16:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 17:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 18:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 19:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 20:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dfece50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 21:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037749745808)\"]\n",
      "    Object Weakref: <weakref at 0x74731869c400; to 'LlamaDecoderLayer' at 0x74731c976890>\n",
      "    Guarded Class Weakref: <weakref at 0x7473187cfce0; to 'type' at 0x9edcb10 (LlamaDecoderLayer)>\n",
      "  Guard 22:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 23:\n",
      "    Name: \"L['self'].input_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 24:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f317b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 25:\n",
      "    Name: \"L['self'].input_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 26:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 27:\n",
      "    Name: \"L['self'].input_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 28:\n",
      "    Name: \"L['self'].input_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 29:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f67ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 30:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 31:\n",
      "    Name: \"L['self'].input_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 32:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 33:\n",
      "    Name: \"L['self'].self_attn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 34:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 35:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['hidden_states'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x74730dfed350; to 'Tensor' at 0x7473186c0470>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 36:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f67ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 37:\n",
      "    Name: \"L['self'].input_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 38:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 39:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 40:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e020cb30; to 'type' at 0x7473c3d19080 (dtype)>\n",
      "  Guard 41:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 42:\n",
      "    Name: \"L['self'].input_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 43:\n",
      "    Name: \"L['self'].k_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 44:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 45:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dff8360; to 'Tensor' at 0x74730dfdc8f0>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 46:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 47:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037686901648)\"]\n",
      "    Object Weakref: <weakref at 0x747318085580; to 'LlamaAttention' at 0x747318d87b90>\n",
      "    Guarded Class Weakref: <weakref at 0x747319108270; to 'type' at 0x9ed1cb0 (LlamaAttention)>\n",
      "  Guard 48:\n",
      "    Name: \"L['self'].q_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 49:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 50:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 51:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 52:\n",
      "    Name: \"L['kwargs']\"\n",
      "    Source: local\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(L['kwargs'], 8835648)\", \"set(L['kwargs'].keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f317b0; to 'type' at 0x86d240 (dict)>\n",
      "  Guard 53:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 54:\n",
      "    Name: \"L['self'].num_key_value_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 55:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dfece50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 56:\n",
      "    Name: \"G['logger']\"\n",
      "    Source: global\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(G['logger'], 38319184)\"]\n",
      "    Object Weakref: <weakref at 0x7472e8518400; to 'Logger' at 0x747319b21890>\n",
      "    Guarded Class Weakref: <weakref at 0x7473e4fc4ae0; to 'type' at 0x248b450 (Logger)>\n",
      "  Guard 57:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 58:\n",
      "    Name: \"L['self'].v_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 59:\n",
      "    Name: \"L['position_embeddings']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['position_embeddings'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 60:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 61:\n",
      "    Name: \"L['attention_mask']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['attention_mask'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 62:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 63:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['key_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7472e8533c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 64:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 65:\n",
      "    Name: \"G['apply_rotary_pos_emb'].__defaults__[1]\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)\", \"G['apply_rotary_pos_emb'].__defaults__[1] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f427a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 66:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037686901648)\"]\n",
      "    Object Weakref: <weakref at 0x747318085580; to 'LlamaAttention' at 0x747318d87b90>\n",
      "    Guarded Class Weakref: <weakref at 0x747319108270; to 'type' at 0x9ed1cb0 (LlamaAttention)>\n",
      "  Guard 67:\n",
      "    Name: \"L['self'].training\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 68:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 69:\n",
      "    Name: \"G['repeat_kv']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 70:\n",
      "    Name: \"L['self'].rotary_emb._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 71:\n",
      "    Name: \"L['q_len']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['q_len'], 8837664)\", \"L['q_len'] == 7\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f427a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 72:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dfece50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 73:\n",
      "    Name: \"L['self'].rotary_emb\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 74:\n",
      "    Name: \"L['self'].rotary_emb._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 75:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 76:\n",
      "    Name: \"L['self'].rotary_emb._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 77:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 78:\n",
      "    Name: \"G['apply_rotary_pos_emb']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 79:\n",
      "    Name: \"G['math']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 80:\n",
      "    Name: \"G['nn']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 81:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f67ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 82:\n",
      "    Name: \"L['self'].rotary_emb._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 83:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['query_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dff73d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 84:\n",
      "    Name: \"L['self'].rotary_emb.rope_type\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 85:\n",
      "    Name: \"L['position_ids']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['position_ids'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x74730dfece50; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 86:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 87:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 88:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 89:\n",
      "    Name: \"L['query_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['query_states'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x74730dff73d0; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 90:\n",
      "    Name: \"L['key_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['key_states'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x7472e8533c90; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 91:\n",
      "    Name: \"G['rotate_half']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 92:\n",
      "    Name: \"L['self'].rotary_emb.attention_scaling\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 93:\n",
      "    Name: \"L['self'].rotary_emb.forward.__closure__[1].cell_contents\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 94:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 95:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 96:\n",
      "    Name: \"L['self'].o_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 97:\n",
      "    Name: \"G['isinstance']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 98:\n",
      "    Name: \"L['self'].num_heads\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 99:\n",
      "    Name: \"L['self'].attention_dropout\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 100:\n",
      "    Name: \"L['self'].config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 101:\n",
      "    Name: \"L['self'].head_dim\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 102:\n",
      "    Name: \"L['hidden_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dff8360; to 'Tensor' at 0x74730dfdc8f0>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 103:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['value_states'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7472e852af20; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 104:\n",
      "    Name: \"L['past_key_value']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['past_key_value'], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 105:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 106:\n",
      "    Name: \"L['self'].rotary_emb.inv_freq\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 107:\n",
      "    Name: \"G['str']\"\n",
      "    Source: global\n",
      "    Create Function: BUILTIN_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 108:\n",
      "    Name: \"L['self'].num_key_value_groups\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 109:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 110:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e020cb30; to 'type' at 0x7473c3d19080 (dtype)>\n",
      "  Guard 111:\n",
      "    Name: \"L['value_states']\"\n",
      "    Source: local\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: ['TYPE_MATCH']\n",
      "    Code List: [\"___check_type_id(L['value_states'], 115763376)\"]\n",
      "    Object Weakref: <weakref at 0x7472e852af20; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 112:\n",
      "    Name: \"L['bsz']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"___check_type_id(L['bsz'], 8837664)\", \"L['bsz'] == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f427a0; to 'type' at 0x86da20 (int)>\n",
      "  Guard 113:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 114:\n",
      "    Name: \"L['___stack0'][1]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][1], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 115:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 116:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037749745808)\"]\n",
      "    Object Weakref: <weakref at 0x74731869c400; to 'LlamaDecoderLayer' at 0x74731c976890>\n",
      "    Guarded Class Weakref: <weakref at 0x7473187cfce0; to 'type' at 0x9edcb10 (LlamaDecoderLayer)>\n",
      "  Guard 117:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 118:\n",
      "    Name: \"L['self'].mlp._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 119:\n",
      "    Name: \"L['self'].mlp.config\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TYPE_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 120:\n",
      "    Name: \"L['___stack0'][2]\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['___stack0'][2], 8820832)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 121:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 122:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module'].torch\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 123:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7472e85dfc90; to 'Tensor' at 0x7472e813e690>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 124:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 125:\n",
      "    Name: \"L['self'].mlp.up_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 126:\n",
      "    Name: \"L['self'].mlp._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 127:\n",
      "    Name: \"L['output_attentions']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['output_attentions'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f67ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 128:\n",
      "    Name: \"L['self'].post_attention_layernorm\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 129:\n",
      "    Name: \"L['self'].post_attention_layernorm._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 130:\n",
      "    Name: \"L['self'].mlp.down_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 131:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 132:\n",
      "    Name: \"L['self'].mlp.act_fn\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 133:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 134:\n",
      "    Name: \"L['residual']\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['residual'], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x74730dfed350; to 'Tensor' at 0x7473186c0470>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 135:\n",
      "    Name: \"L['self'].mlp._forward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 136:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 137:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 138:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 3\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f4f6a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 139:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 140:\n",
      "    Name: \"L['use_cache']\"\n",
      "    Source: local\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['use_cache'], 8905664)\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f67ce0; to 'type' at 0x87e3e0 (bool)>\n",
      "  Guard 141:\n",
      "    Name: \"L['self'].post_attention_layernorm.variance_epsilon\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 142:\n",
      "    Name: \"L['self'].post_attention_layernorm.weight\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 143:\n",
      "    Name: \"L['self'].mlp.gate_proj\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 144:\n",
      "    Name: \"L['self'].post_attention_layernorm._backward_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 145:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 146:\n",
      "    Name: \"L['self'].mlp\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 147:\n",
      "    Name: \"L['self'].mlp._backward_pre_hooks\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: BOOL_FALSE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 148:\n",
      "    Name: \"G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks\"\n",
      "    Source: global\n",
      "    Create Function: DICT_KEYS\n",
      "    Guard Types: ['DICT_KEYS']\n",
      "    Code List: [\"___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)\", \"set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f6c950; to 'type' at 0x86b860 (OrderedDict)>\n",
      "  Guard 149:\n",
      "    Name: \"G['torch'].float32\"\n",
      "    Source: global\n",
      "    Create Function: CONSTANT_MATCH\n",
      "    Guard Types: ['EQUALS_MATCH']\n",
      "    Code List: [\"str(G['torch'].float32) == 'torch.float32'\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e020cb30; to 'type' at 0x7473c3d19080 (dtype)>\n",
      "  Guard 150:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DETERMINISTIC_ALGORITHMS\n",
      "    Guard Types: ['DETERMINISTIC_ALGORITHMS']\n",
      "    Code List: ['not ___are_deterministic_algorithms_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 151:\n",
      "    Name: \"L['self'].linear\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 152:\n",
      "    Name: \"L['self'].softmax\"\n",
      "    Source: local_nn_module\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 153:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: TORCH_FUNCTION_STATE\n",
      "    Guard Types: ['TORCH_FUNCTION_STATE']\n",
      "    Code List: ['___is_torch_function_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 154:\n",
      "    Name: ''\n",
      "    Source: shape_env\n",
      "    Create Function: SHAPE_ENV\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 155:\n",
      "    Name: \"L['___stack0'][0]\"\n",
      "    Source: local\n",
      "    Create Function: TENSOR_MATCH\n",
      "    Guard Types: ['TENSOR_MATCH']\n",
      "    Code List: [\"hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False\"]\n",
      "    Object Weakref: <weakref at 0x7472e812d940; dead>\n",
      "    Guarded Class Weakref: <weakref at 0x7473d9767790; to 'torch._C._TensorMeta' at 0x6e668b0 (Tensor)>\n",
      "  Guard 156:\n",
      "    Name: \"L['___stack0']\"\n",
      "    Source: local\n",
      "    Create Function: LIST_LENGTH\n",
      "    Guard Types: ['LIST_LENGTH']\n",
      "    Code List: [\"___check_type_id(L['___stack0'], 8810304)\", \"len(L['___stack0']) == 1\"]\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: <weakref at 0x7473e5f4f6a0; to 'type' at 0x866f40 (tuple)>\n",
      "  Guard 157:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: DEFAULT_DEVICE\n",
      "    Guard Types: ['DEFAULT_DEVICE']\n",
      "    Code List: ['utils_device.CURRENT_DEVICE == None']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 158:\n",
      "    Name: \"G['torch']\"\n",
      "    Source: global\n",
      "    Create Function: FUNCTION_MATCH\n",
      "    Guard Types: None\n",
      "    Code List: None\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "  Guard 159:\n",
      "    Name: \"L['self']\"\n",
      "    Source: local\n",
      "    Create Function: NN_MODULE\n",
      "    Guard Types: ['ID_MATCH']\n",
      "    Code List: [\"___check_obj_id(L['self'], 128037749707920)\"]\n",
      "    Object Weakref: <weakref at 0x7473181d2d90; to 'LLaMAFirstLayerModel' at 0x74731c96d490>\n",
      "    Guarded Class Weakref: <weakref at 0x74731c971df0; to 'type' at 0x977dc60 (LLaMAFirstLayerModel)>\n",
      "  Guard 160:\n",
      "    Name: ''\n",
      "    Source: global\n",
      "    Create Function: GRAD_MODE\n",
      "    Guard Types: ['GRAD_MODE']\n",
      "    Code List: ['___is_grad_enabled()']\n",
      "    Object Weakref: None\n",
      "    Guarded Class Weakref: None\n",
      "Compile Times: TorchDynamo compilation metrics:\n",
      "Function                         Runtimes (s)\n",
      "-------------------------------  ----------------------------------------------\n",
      "_compile.<locals>.compile_inner  0.4007, 0.1626, 0.0716, 0.2754, 0.1197, 0.0278\n",
      "OutputGraph.call_user_compiler   0.0036, 0.0005, 0.0009, 0.0004, 0.0004, 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use TorchDynamo's explain to capture the graph\n",
    "# Extract the input_ids tensor from BatchEncoding\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "explanation = torch._dynamo.explain(model, input_ids)\n",
    "\n",
    "# Print the explanation\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph break to Python `forward`\n",
    "\n",
    "Using `dynamo` explain to evaluate the graph and breaks generated by `torch._dynamo`, use `torch._dynamo.optimize`\n",
    "generate the Python `forward` function for each of these graph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-24 18:15:17,314] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:17,315] [6/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /tmp/ipykernel_1020204/343866.py:26\n",
      "[2024-12-24 18:15:17,315] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:26\n",
      "[2024-12-24 18:15:17,315] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, input_ids):\n",
      "[2024-12-24 18:15:17,316] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['input_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:15:17,317] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,317] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:28\n",
      "[2024-12-24 18:15:17,317] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:15:17,318] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,318] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD embed_tokens [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,319] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,319] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,319] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,320] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___embed_tokens from forward /tmp/ipykernel_1020204/343866.py:28\n",
      "[2024-12-24 18:15:17,320] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:15:17,320] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,322] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST embeddings [TensorVariable()]\n",
      "[2024-12-24 18:15:17,323] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:15:17,323] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:15:17,323] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,323] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD arange [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,324] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,324] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,324] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-24 18:15:17,324] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,325] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,325] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), NullVariable, GetAttrVariable(TensorVariable(), size), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,325] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_ids [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,326] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TensorVariable()]\n",
      "[2024-12-24 18:15:17,326] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device',) [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:15:17,327] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:15:17,327] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<built-in method arange of type object at 0x7473c3d1cde0>), ConstantVariable(int), ConstantVariable(int), TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:15:17,327] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call arange from forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:15:17,327] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:15:17,327] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,328] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from forward /tmp/ipykernel_1020204/343866.py:31\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:15:17,329] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:17,330] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids [TensorVariable()]\n",
      "[2024-12-24 18:15:17,330] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:15:17,330] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:15:17,331] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,331] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD first_layer [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,332] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST embeddings [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,332] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,332] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('position_ids',) [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,332] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,333] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,334] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:15:17,334] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:15:17,334] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,334] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,337] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,337] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,338] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,338] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,338] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,338] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,338] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,339] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,339] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,340] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,340] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,341] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,341] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,341] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,342] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,342] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,342] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,342] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,343] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,343] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,343] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,344] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,344] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,345] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,345] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,345] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,346] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,346] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,346] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,346] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,347] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,347] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,347] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,348] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,349] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,349] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,349] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,350] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,350] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,350] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,350] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,350] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,351] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,352] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,352] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,352] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,353] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,353] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,353] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,353] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,354] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,354] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:17,354] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,354] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,355] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaDecoderLayer.forward at 0x7473187ecea0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,356] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,356] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,356] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,356] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a052bf0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-24 18:15:17,358] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,358] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:15:17,358] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,359] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,359] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:15:17,359] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,359] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:15:17,360] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,360] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:17,360] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,361] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,361] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,362] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,363] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,364] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,364] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:17,364] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,364] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,368] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,368] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,368] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,369] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,369] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,369] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,369] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,370] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,370] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,371] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,371] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,371] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,372] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,372] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,372] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,372] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,372] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,373] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,373] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,373] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,373] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,374] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,374] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,374] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,375] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,375] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,375] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,376] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,377] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,377] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,377] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,377] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,377] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,378] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,379] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,379] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,379] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,380] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,380] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,380] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,380] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,380] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,381] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,381] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,381] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,382] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,382] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,382] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,382] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,382] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,383] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,383] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:17,383] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,383] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,383] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,384] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,384] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,384] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,385] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:15:17,386] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,386] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:15:17,386] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,387] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,387] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:17,387] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,387] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:15:17,387] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,388] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,388] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:17,388] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:17,389] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,389] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:17,389] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,390] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,390] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,390] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,390] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,390] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:15:17,391] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:15:17,391] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,392] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,392] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,392] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,392] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:17,393] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:15:17,394] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:15:17,394] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,395] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,395] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,395] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,396] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,396] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,396] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,398] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:15:17,398] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,398] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,398] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,398] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:15:17,399] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,399] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,399] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,400] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,400] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:17,400] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,400] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,400] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,402] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,402] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,403] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,403] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,403] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,404] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,404] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,404] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,404] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,405] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,406] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,406] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,406] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,406] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,407] [6/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].first_layer.input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:15:17,407] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,407] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,408] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,409] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,410] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,410] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,410] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,411] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,411] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:17,412] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,412] [6/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,412] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,412] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,412] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,413] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,413] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-24 18:15:17,413] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,414] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,414] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,414] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-24 18:15:17,414] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,415] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-24 18:15:17,416] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,417] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,418] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:15:17,419] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,419] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-24 18:15:17,419] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,419] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,419] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,420] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,420] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-24 18:15:17,421] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,424] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,425] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,426] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,426] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,427] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,427] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,428] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,428] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,430] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,430] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,430] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,431] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,431] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,431] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,432] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,433] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,434] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,434] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,435] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,435] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,435] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,436] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,436] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,437] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,437] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,438] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,439] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,439] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,439] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,440] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,440] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,440] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,440] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,441] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,441] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,441] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,441] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,441] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,442] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,442] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,442] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,443] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,444] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,444] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,444] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,444] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,445] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,445] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:15:17,445] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,446] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,446] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,448] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,448] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,448] [6/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,449] [6/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:15:17,450] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,450] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:15:17,451] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:15:17,451] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:15:17,451] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:15:17,451] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:15:17,451] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:15:17,452] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:15:17,452] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,452] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,452] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:15:17,452] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:15:17,453] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:15:17,453] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,453] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,454] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,455] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:15:17,456] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,456] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,456] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,457] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,457] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,457] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,457] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,458] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,462] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,463] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,463] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,463] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,463] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,464] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,465] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,465] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,465] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,465] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,465] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,468] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,469] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,469] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,469] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,469] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,470] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,470] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,470] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,471] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___first_layer_self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,471] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,471] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,473] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,473] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,473] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,474] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:15:17,474] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,474] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,474] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,475] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,475] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,475] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,476] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,477] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,477] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,478] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,478] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,478] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,480] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,481] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,481] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,481] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,481] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,482] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,482] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,482] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,484] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,484] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,484] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,484] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:15:17,484] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,485] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,485] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,485] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,485] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,486] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,486] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,487] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,488] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,488] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,488] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,488] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,490] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,490] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,490] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,491] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,491] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,491] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,491] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,491] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,492] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,493] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,493] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,493] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:15:17,493] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,493] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,494] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,494] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,494] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,495] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,495] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,496] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,496] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,496] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,496] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,496] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,498] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,499] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,499] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,499] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,499] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,500] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,500] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,500] [6/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,501] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,501] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,501] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:15:17,501] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:15:17,501] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,502] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,502] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,502] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,502] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,502] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:15:17,503] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:15:17,503] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,503] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 4)\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,504] [6/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,505] [6/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:15:17,505] [6/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:15:17,505] [6/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,506] [6/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,506] [6/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,506] [6/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,506] [6/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x74731a052bf0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 695>\n",
      "[2024-12-24 18:15:17,506] [6/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:15:17,507] [6/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,507] [6/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,507] [6/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,507] [6/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {} from user code at:\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_1020204/343866.py\", line 34, in forward\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 734, in forward\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     logger.warning_once(\n",
      "[2024-12-24 18:15:17,509] [6/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n",
      "[2024-12-24 18:15:17,510] [6/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,510] [6/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_1020204/343866.py, line 34 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_9 =====\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.6 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_input_ids_ : torch.Tensor):\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_input_ids_ = L_input_ids_\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:28, code: embeddings = self.embed_tokens(input_ids)\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:31, code: position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___embed_tokens, unsqueeze)\n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,511] [6/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_9 <eval_with_key>.6 opcode         name                    target                                                     args                                    kwargs\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  ----------------------  ---------------------------------------------------------  --------------------------------------  ----------------------------------------\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_input_ids_            L_input_ids_                                               ()                                      {}\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___embed_tokens  L__self___embed_tokens                                     (l_input_ids_,)                         {}\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  arange                  <built-in method arange of type object at 0x7473c3d1cde0>  (0, 7)                                  {'device': device(type='cuda', index=0)}\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze               unsqueeze                                                  (arange, 0)                             {}\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                  output                                                     ((l__self___embed_tokens, unsqueeze),)  {}\n",
      "[2024-12-24 18:15:17,512] [6/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_9 =====\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_input_ids_: (1, 7)\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___embed_tokens: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] arange: (7,)\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 7)\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:17,513] [6/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:17,516] [6/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:17,516] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749707920)                   # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1020204/343866.py:28 in forward\n",
      "[2024-12-24 18:15:17,517] [6/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # embeddings = self.embed_tokens(input_ids)  # mp/ipykernel_1020204/343866.py:28 in forward\n",
      "[2024-12-24 18:15:17,517] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['input_ids'], 115763376)                   # position_ids = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)  # mp/ipykernel_1020204/343866.py:31 in forward\n",
      "[2024-12-24 18:15:17,518] [6/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False   # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,518] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,518] [6/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,519] [6/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,519] [6/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,520] [6/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['input_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,531] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:17,532] [7/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-24 18:15:17,533] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:695\n",
      "[2024-12-24 18:15:17,533] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:15:17,534] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:17,535] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:15:17,536] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:729\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-24 18:15:17,537] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:17,538] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,538] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD input_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,539] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,539] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,539] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,540] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:731\n",
      "[2024-12-24 18:15:17,540] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.input_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:17,540] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,540] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,543] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,543] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,544] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,544] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,544] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,544] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,544] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,545] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,545] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,546] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,546] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,546] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,546] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,547] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,547] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,547] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,547] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,548] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,548] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,549] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,549] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,549] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,550] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,550] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,550] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,551] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,552] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,553] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,553] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,553] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,553] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,554] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,554] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,554] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,554] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,554] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,555] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,555] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,555] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,556] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,556] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,556] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,556] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,557] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,557] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,557] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,557] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,557] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,558] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,559] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,559] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,559] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,560] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:17,560] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,560] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,561] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,561] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,561] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,561] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,562] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:17,562] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,562] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:15:17,563] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,563] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,563] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:15:17,563] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,563] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:15:17,565] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,566] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,566] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:17,567] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,567] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:15:17,568] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,569] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,569] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:17,570] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:17,570] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,570] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:17,570] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,571] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,571] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,571] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,572] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,572] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:15:17,572] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:15:17,572] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,572] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,573] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,573] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,573] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:17,574] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:15:17,574] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:15:17,574] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,575] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,576] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:15:17,576] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,576] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,577] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,577] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:15:17,577] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,577] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,577] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,578] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,578] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:17,578] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,578] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,578] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,580] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,580] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,580] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,580] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,580] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,582] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,582] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,582] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,582] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,583] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,583] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,583] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,583] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,584] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,584] [7/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].input_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:15:17,585] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,586] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,586] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,586] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,587] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,587] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,587] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,587] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,588] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,588] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,588] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,588] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,589] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,590] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:17,590] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,590] [7/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,590] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,591] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:17,591] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,591] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,591] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable]\n",
      "[2024-12-24 18:15:17,591] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR self_attn [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,592] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST () [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,592] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:735\n",
      "[2024-12-24 18:15:17,592] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 hidden_states=hidden_states,\n",
      "[2024-12-24 18:15:17,592] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:736\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attention_mask=attention_mask,\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:737\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_ids=position_ids,\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:738\n",
      "[2024-12-24 18:15:17,593] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 past_key_value=past_key_value,\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 output_attentions=output_attentions,\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:740\n",
      "[2024-12-24 18:15:17,594] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 use_cache=use_cache,\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cache_position=cache_position,\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cache_position [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:742\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,595] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST ('hidden_states', 'attention_mask', 'position_ids', 'past_key_value', 'output_attentions', 'use_cache', 'cache_position', 'position_embeddings') [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_CONST_KEY_MAP 8 [NullVariable, NNModuleVariable(), TupleVariable(), TensorVariable(), ConstantVariable(NoneType), TensorVariable(), ConstantVariable(NoneType), ConstantVariable(bool), ConstantVariable(bool), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:743\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 **kwargs,\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,596] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, NNModuleVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                                               ~~~~~~~~~~~~~~^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             hidden_states=hidden_states,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             attention_mask=attention_mask,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_ids=position_ids,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             past_key_value=past_key_value,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             output_attentions=output_attentions,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             use_cache=use_cache,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cache_position=cache_position,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             position_embeddings=position_embeddings,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             **kwargs,\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             ^^^^^^^^^\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         )\n",
      "[2024-12-24 18:15:17,597] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         ^\n",
      "[2024-12-24 18:15:17,598] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,601] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,602] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,602] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,602] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,603] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,603] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,604] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,604] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,604] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,604] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,604] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,605] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,605] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,605] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,606] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,606] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,607] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,607] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,607] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,607] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,608] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,608] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,608] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,608] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,608] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,609] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,609] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,609] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,609] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,610] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,611] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,611] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,611] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,611] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,611] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,612] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,613] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,613] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,613] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,613] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,613] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,614] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,614] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple)]\n",
      "[2024-12-24 18:15:17,614] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,614] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,615] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaAttention.forward at 0x7473187ecae0>, NNModuleVariable()), ConstantVariable(tuple), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,616] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,616] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,616] [7/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,616] [7/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:15:17,619] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,619] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:15:17,619] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:15:17,619] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,620] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:15:17,621] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:15:17,621] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:15:17,621] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,621] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,621] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,622] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,623] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:15:17,623] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,624] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,624] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,624] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,624] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,624] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,625] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,625] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,625] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,626] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,626] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,626] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,626] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,630] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,630] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,630] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,630] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,630] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,631] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,635] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,636] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,636] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,636] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,636] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,636] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,637] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,637] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,637] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___self_attn_v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,637] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,637] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,641] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,642] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,642] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,642] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:15:17,642] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,642] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,643] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,643] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,643] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,643] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,643] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,644] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,644] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,644] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,644] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,644] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,646] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,646] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,646] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,646] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,647] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,647] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,647] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,647] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,648] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,648] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,648] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,648] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:15:17,648] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,649] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,649] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,649] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,649] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,649] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,650] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,651] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,651] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,652] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,654] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,655] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,655] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,655] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:15:17,655] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,656] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,656] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,656] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,656] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,657] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,657] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,658] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,658] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,658] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,658] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,658] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,659] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,660] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,660] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,660] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,661] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,661] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,661] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,661] [7/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,662] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,662] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,662] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:15:17,662] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:15:17,662] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,663] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,663] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,663] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,663] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,663] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:15:17,664] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:15:17,664] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,664] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:15:17,664] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:15:17,665] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,665] [7/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,665] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,665] [7/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,665] [7/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,666] [7/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object forward at 0x9c13b70, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 364>\n",
      "[2024-12-24 18:15:17,666] [7/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 9 nodes\n",
      "[2024-12-24 18:15:17,667] [7/0] torch._dynamo.symbolic_convert: [DEBUG] empty checkpoint\n",
      "[2024-12-24 18:15:17,667] [7/0] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,667] [7/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,668] [7/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:15:17,669] [7/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,669] [7/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 734 in forward>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py, line 1527 in _call_impl>, <FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_11 =====\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.7 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mean + 1e-05;  mean = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add);  add = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (mul_1,)\n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,671] [7/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_11 <eval_with_key>.7 opcode         name                              target                                                    args                                      kwargs\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  --------------------------------  --------------------------------------------------------  ----------------------------------------  -----------------\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_hidden_states_                  L_hidden_states_                                          ()                                        {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                to                                                        (l_hidden_states_, torch.float32)         {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                             pow                                                       (to, 2)                                   {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                              mean                                                      (pow_1, -1)                               {'keepdim': True}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                               <built-in function add>                                   (mean, 1e-05)                             {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                             <built-in method rsqrt of type object at 0x7473c3d1cde0>  (add,)                                    {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                               <built-in function mul>                                   (to, rsqrt)                               {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___input_layernorm_weight  L__self___input_layernorm_weight                          ()                                        {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                              to                                                        (mul, torch.float32)                      {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                             <built-in function mul>                                   (l__self___input_layernorm_weight, to_1)  {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                            output                                                    ((mul_1,),)                               {}\n",
      "[2024-12-24 18:15:17,672] [7/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_11 =====\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 1)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___input_layernorm_weight: (2048,)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,673] [7/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:17,674] [7/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:17,674] [7/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:17,678] [7/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:17,678] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749745808)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,679] [7/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,679] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:17,679] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:17,680] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,681] [7/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,681] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['hidden_states'], 115763376)               # return self.weight * hidden_states.to(input_dtype)  # transformers/models/llama/modeling_llama.py:125 in forward\n",
      "[2024-12-24 18:15:17,682] [7/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,682] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,683] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['cache_position'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,683] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,684] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,684] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in forward\n",
      "[2024-12-24 18:15:17,684] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,685] [7/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,686] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,686] [7/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,687] [7/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-24 18:15:17,687] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,688] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,688] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,689] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,689] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,690] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,690] [7/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,690] [7/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:17,691] [7/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,691] [7/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,697] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:17,699] [8/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-24 18:15:17,700] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:364\n",
      "[2024-12-24 18:15:17,700] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(\n",
      "[2024-12-24 18:15:17,701] [8/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:17,702] [8/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:15:17,704] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL hidden_states []\n",
      "[2024-12-24 18:15:17,704] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL attn_output []\n",
      "[2024-12-24 18:15:17,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL key_slices []\n",
      "[2024-12-24 18:15:17,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL o_proj_slices []\n",
      "[2024-12-24 18:15:17,705] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL query_slices []\n",
      "[2024-12-24 18:15:17,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL value_slices []\n",
      "[2024-12-24 18:15:17,706] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,706] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:376\n",
      "[2024-12-24 18:15:17,706] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             bsz, q_len, _ = hidden_states.size()\n",
      "[2024-12-24 18:15:17,707] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states []\n",
      "[2024-12-24 18:15:17,707] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:15:17,708] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,708] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:17,708] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [SizeVariable()]\n",
      "[2024-12-24 18:15:17,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST bsz [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_len [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,709] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST _ [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,710] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:378\n",
      "[2024-12-24 18:15:17,710] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:15:17,710] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,711] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,712] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:15:17,712] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,712] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,713] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 762 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,713] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-24 18:15:17,713] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,713] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_input_ids_ : torch.Tensor):\n",
      "    l_input_ids_ = L_input_ids_\n",
      "    l__self___embed_tokens = self.L__self___embed_tokens(l_input_ids_);  l_input_ids_ = None\n",
      "    arange = torch.arange(0, 7, device = device(type='cuda', index=0))\n",
      "    unsqueeze = arange.unsqueeze(0);  arange = None\n",
      "    return (l__self___embed_tokens, unsqueeze)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    to = l_hidden_states_.to(torch.float32);  l_hidden_states_ = None\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add);  add = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___input_layernorm_weight = self.L__self___input_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___input_layernorm_weight * to_1;  l__self___input_layernorm_weight = to_1 = None\n",
      "    return (mul_1,)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-24 18:15:17,714] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD q_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,714] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,715] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,715] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,716] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___q_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396\n",
      "[2024-12-24 18:15:17,716] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,716] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,719] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,720] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-24 18:15:17,720] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,720] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,721] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD k_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___k_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,722] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                          ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,724] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,725] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-24 18:15:17,725] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,725] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,725] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD v_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___v_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,726] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,728] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,729] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:15:17,729] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,729] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states []\n",
      "[2024-12-24 18:15:17,729] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,730] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,731] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,731] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,731] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,732] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,732] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:15:17,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,732] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,733] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,734] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,734] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,734] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,734] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,735] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400\n",
      "[2024-12-24 18:15:17,735] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,735] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,736] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,736] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:15:17,736] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,736] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states []\n",
      "[2024-12-24 18:15:17,736] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,737] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,738] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,738] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,738] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,739] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,739] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:15:17,739] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,739] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,740] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,741] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,741] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,741] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,741] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,742] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401\n",
      "[2024-12-24 18:15:17,742] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,742] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,743] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,743] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:15:17,743] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,743] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states []\n",
      "[2024-12-24 18:15:17,743] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD view [TensorVariable()]\n",
      "[2024-12-24 18:15:17,744] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), view)]\n",
      "[2024-12-24 18:15:17,744] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,745] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,746] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,746] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call view_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:15:17,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,746] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,747] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:17,748] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,748] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,748] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,748] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,749] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402\n",
      "[2024-12-24 18:15:17,749] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,749] [8/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,750] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,750] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:404\n",
      "[2024-12-24 18:15:17,750] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if position_embeddings is None:\n",
      "[2024-12-24 18:15:17,750] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_embeddings []\n",
      "[2024-12-24 18:15:17,751] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,751] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 1 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,753] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1324 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,754] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:15:17,754] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,754] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL logger []\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD warning_once [UserDefinedObjectVariable(Logger)]\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:406\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     \"The attention layers in this model are transitioning from computing the RoPE embeddings internally \"\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory. [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once)]\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:15:17,755] [8/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,756] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,756] [8/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(UserDefinedObjectVariable(Logger), warning_once), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,756] [8/0] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "[2024-12-24 18:15:17,757] [8/0] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2024-12-24 18:15:17,757] [8/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='call_method UserDefinedObjectVariable(Logger) warning_once [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 405 in forward>], graph_break=True)\n",
      "[2024-12-24 18:15:17,758] [8/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['position_ids']\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_13 =====\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.8 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_hidden_states_ = L_hidden_states_\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:396, code: query_states = self.q_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:397, code: key_states = self.k_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:398, code: value_states = self.v_proj(hidden_states)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:400, code: query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = view.transpose(1, 2);  view = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:401, code: key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:402, code: value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (transpose, transpose_1, transpose_2)\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_13 <eval_with_key>.8 opcode       name              target            args                                      kwargs\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] -----------  ----------------  ----------------  ----------------------------------------  --------\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder  l_hidden_states_  L_hidden_states_  ()                                        {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___q_proj  L__self___q_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___k_proj  L__self___k_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module  l__self___v_proj  L__self___v_proj  (l_hidden_states_,)                       {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view              view              (l__self___q_proj, 1, 7, 32, 64)          {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose         transpose         (view, 1, 2)                              {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_1            view              (l__self___k_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_1       transpose         (view_1, 1, 2)                            {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  view_2            view              (l__self___v_proj, 1, 7, 8, 64)           {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method  transpose_2       transpose         (view_2, 1, 2)                            {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] output       output            output            ((transpose, transpose_1, transpose_2),)  {}\n",
      "[2024-12-24 18:15:17,759] [8/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_13 =====\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_hidden_states_: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___q_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___k_proj: (1, 7, 512)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___v_proj: (1, 7, 512)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view: (1, 7, 32, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_1: (1, 7, 8, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] view_2: (1, 7, 8, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:17,760] [8/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:17,761] [8/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:17,761] [8/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:17,773] [8/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:17,774] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037686901648)                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-24 18:15:17,774] [8/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if self.config.pretraining_tp > 1:  # transformers/models/llama/modeling_llama.py:378 in forward\n",
      "[2024-12-24 18:15:17,774] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['kwargs'], 8835648)                        # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:17,775] [8/0] torch._dynamo.guards.__guards: [DEBUG] set(L['kwargs'].keys()) == set()                              # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:17,775] [8/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,776] [8/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,776] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['position_embeddings'], 8820832)            # if position_embeddings is None:  # transformers/models/llama/modeling_llama.py:404 in forward\n",
      "[2024-12-24 18:15:17,776] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,777] [8/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,777] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,778] [8/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:17,778] [8/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['logger'], 38319184)                       # logger.warning_once(  # transformers/models/llama/modeling_llama.py:405 in forward\n",
      "[2024-12-24 18:15:17,779] [8/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,779] [8/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:17,781] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:17,784] [9/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:15:17,785] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:405\n",
      "[2024-12-24 18:15:17,785] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 logger.warning_once(\n",
      "[2024-12-24 18:15:17,785] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['position_ids'] (1, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None]\n",
      "[2024-12-24 18:15:17,787] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['query_states'] (1, 32, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:15:17,788] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['key_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:15:17,789] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['value_states'] (1, 8, 7, 64) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2024-12-24 18:15:17,790] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['hidden_states'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:17,791] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 6 []\n",
      "[2024-12-24 18:15:17,791] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,791] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:15:17,791] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1278 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,791] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,792] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-24 18:15:17,792] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-24 18:15:17,792] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,792] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD rotary_emb [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,792] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:411\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             cos, sin = self.rotary_emb(value_states, position_ids)\n",
      "[2024-12-24 18:15:17,793] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,794] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:17,797] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,798] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,798] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:17,798] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,798] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:17,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,799] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,800] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,801] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,802] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:17,803] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,804] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,805] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:17,806] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:17,807] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,807] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,807] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRotaryEmbedding.forward at 0x7473187ec400>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,808] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call decorate_context from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,808] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,808] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,808] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object decorate_context at 0x7473d804a670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:112 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @functools.wraps(func)\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COPY_FREE_VARS 2 []\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-24 18:15:17,809] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:17,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF ctx_factory [NullVariable]\n",
      "[2024-12-24 18:15:17,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-24 18:15:17,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, UserDefinedObjectVariable(clone)]\n",
      "[2024-12-24 18:15:17,810] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [GradModeVariable()]\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return func(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF func [WithExitFunctionVariable(), NullVariable]\n",
      "[2024-12-24 18:15:17,811] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [WithExitFunctionVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,812] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,812] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,812] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,813] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [WithExitFunctionVariable(), NullVariable, UserFunctionVariable(), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:17,813] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,813] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return func(*args, **kwargs)\n",
      "[2024-12-24 18:15:17,813] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,813] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9bfcd00, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-24 18:15:17,814] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:197 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,814] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         @torch.no_grad()\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:199 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if \"dynamic\" in self.rope_type:\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST dynamic []\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,815] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rope_type [ConstantVariable(str), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,816] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CONTAINS_OP 0 [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,816] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,816] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,816] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:15:17,816] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:17,817] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR inv_freq [NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,817] [9/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].rotary_emb.inv_freq (32,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:15:17,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,818] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,819] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:15:17,819] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,819] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,820] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,820] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:15:17,820] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,821] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-24 18:15:17,822] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,822] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:15:17,822] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:15:17,823] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:15:17,824] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:15:17,824] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [NullVariable, GetAttrVariable(TensorVariable(), expand), TensorVariable()]\n",
      "[2024-12-24 18:15:17,825] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable()]\n",
      "[2024-12-24 18:15:17,825] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [NullVariable, GetAttrVariable(TensorVariable(), expand), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,826] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,826] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,826] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,826] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,827] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,827] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:15:17,827] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,828] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST inv_freq_expanded [TensorVariable()]\n",
      "[2024-12-24 18:15:17,828] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,828] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:15:17,829] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids []\n",
      "[2024-12-24 18:15:17,829] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,829] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,829] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,830] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,831] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:15:17,831] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:15:17,831] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,833] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [TensorVariable()]\n",
      "[2024-12-24 18:15:17,833] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,834] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,834] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,834] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:15:17,834] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST position_ids_expanded [TensorVariable()]\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:206 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = x.device.type\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR device [TensorVariable()]\n",
      "[2024-12-24 18:15:17,836] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR type [TorchVariable(cuda:0)]\n",
      "[2024-12-24 18:15:17,837] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,837] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:207 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,837] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
      "[2024-12-24 18:15:17,837] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2024-12-24 18:15:17,837] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, BuiltinVariable(isinstance)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL str [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, BuiltinVariable(isinstance), ConstantVariable(str), BuiltinVariable(str)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST mps [ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,838] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [ConstantVariable(str), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,839] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 360 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,839] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type []\n",
      "[2024-12-24 18:15:17,839] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 362 [ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,840] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST device_type [ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,840] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,840] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-24 18:15:17,840] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,840] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR autocast [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST device_type [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>)]\n",
      "[2024-12-24 18:15:17,841] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST False [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str)]\n",
      "[2024-12-24 18:15:17,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('device_type', 'enabled') [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,842] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<class 'torch.amp.autocast_mode.autocast'>), ConstantVariable(str), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,843] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BEFORE_WITH None [AutocastModeVariable()]\n",
      "[2024-12-24 18:15:17,844] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [WithExitFunctionVariable(), None]\n",
      "[2024-12-24 18:15:17,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,844] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,844] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST inv_freq_expanded [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,845] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,845] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,846] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,846] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_3 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,846] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,846] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:15:17,848] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST position_ids_expanded [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,848] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD float [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,849] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,849] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), float)]\n",
      "[2024-12-24 18:15:17,849] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call float_4 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,849] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,849] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:15:17,851] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 4 [WithExitFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,851] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,851] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,851] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                      ~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,854] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:17,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,855] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,856] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,856] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,856] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:17,856] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:17,858] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST freqs [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,859] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,859] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:15:17,859] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,860] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [WithExitFunctionVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,860] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,860] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST freqs [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,861] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,861] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:15:17,862] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,862] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,862] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,863] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,863] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:15:17,863] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,864] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST emb [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,865] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,865] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 cos = emb.cos()\n",
      "[2024-12-24 18:15:17,865] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,865] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,866] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-24 18:15:17,866] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), cos)]\n",
      "[2024-12-24 18:15:17,866] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cos from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,866] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             cos = emb.cos()\n",
      "[2024-12-24 18:15:17,866] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-24 18:15:17,868] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,868] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,868] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 sin = emb.sin()\n",
      "[2024-12-24 18:15:17,868] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST emb [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,868] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-24 18:15:17,869] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [WithExitFunctionVariable(), NullVariable, GetAttrVariable(TensorVariable(), sin)]\n",
      "[2024-12-24 18:15:17,869] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call sin from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,869] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             sin = emb.sin()\n",
      "[2024-12-24 18:15:17,869] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                   ~~~~~~~^^\n",
      "[2024-12-24 18:15:17,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [WithExitFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,871] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:208 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,871] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with torch.autocast(device_type=device_type, enabled=False):\n",
      "[2024-12-24 18:15:17,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,871] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,872] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [None]\n",
      "[2024-12-24 18:15:17,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 706 []\n",
      "[2024-12-24 18:15:17,873] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,873] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:15:17,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:15:17,873] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-24 18:15:17,874] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,875] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:17,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:15:17,875] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,876] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:15:17,876] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,876] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:15:17,876] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-24 18:15:17,877] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable()]\n",
      "[2024-12-24 18:15:17,877] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_scaling [TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,878] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:17,878] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,878] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:15:17,878] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,879] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:15:17,879] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,879] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:15:17,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:15:17,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:15:17,880] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,881] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:15:17,882] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,883] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,883] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,883] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,883] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:15:17,883] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:15:17,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:17,885] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:15:17,886] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dtype',) [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,887] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,887] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:17,887] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218 (inline depth: 3)\n",
      "[2024-12-24 18:15:17,887] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:15:17,887] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                       ~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,888] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x9bfcd00, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 197>\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line decorate_context /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:114 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             with ctx_factory():\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE SWAP 2 [WithExitFunctionVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable()]\n",
      "[2024-12-24 18:15:17,889] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [TupleVariable(), WithExitFunctionVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_TOP None [TupleVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,890] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:17,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object decorate_context at 0x7473d804a670, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 112>\n",
      "[2024-12-24 18:15:17,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:17,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:17,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-24 18:15:17,891] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 1342 []\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL apply_rotary_pos_emb []\n",
      "[2024-12-24 18:15:17,892] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,893] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,893] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,893] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,894] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,894] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, UserFunctionVariable(), TensorVariable(), TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,894] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call apply_rotary_pos_emb from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:414\n",
      "[2024-12-24 18:15:17,894] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
      "[2024-12-24 18:15:17,894] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,895] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object apply_rotary_pos_emb at 0x74731a06e430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-24 18:15:17,895] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:253 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,895] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
      "[2024-12-24 18:15:17,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,896] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,896] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:17,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos []\n",
      "[2024-12-24 18:15:17,896] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:17,897] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,898] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:15:17,898] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,898] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:17,898] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin []\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD unsqueeze [TensorVariable()]\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST unsqueeze_dim [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze)]\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), unsqueeze), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call unsqueeze_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:17,899] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,900] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST sin [TensorVariable()]\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q []\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:17,901] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-24 18:15:17,902] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:17,903] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:17,904] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:15:17,905] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:15:17,905] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:15:17,905] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,905] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:15:17,906] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-24 18:15:17,906] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,907] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,907] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,907] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,908] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:15:17,908] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,908] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,908] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:17,908] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:15:17,910] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:15:17,911] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-24 18:15:17,912] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-24 18:15:17,912] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,913] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,913] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,913] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,913] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,914] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:15:17,914] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,914] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_3 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,914] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:17,914] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,916] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-24 18:15:17,916] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,916] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,916] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,916] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,917] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,917] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,917] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,917] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,917] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-24 18:15:17,918] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,918] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,918] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,919] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_3 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:17,921] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-24 18:15:17,922] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,922] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,922] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:17,922] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,923] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST q_embed [TensorVariable()]\n",
      "[2024-12-24 18:15:17,923] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,923] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:17,923] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k []\n",
      "[2024-12-24 18:15:17,923] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST cos [TensorVariable()]\n",
      "[2024-12-24 18:15:17,924] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,924] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_4 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,924] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:17,924] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~^~~~~\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL rotate_half [TensorVariable()]\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k [TensorVariable(), NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call rotate_half from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:17,925] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                            ~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:246 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def rotate_half(x):\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,926] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:17,927] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:15:17,927] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:15:17,927] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:15:17,927] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,928] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:15:17,929] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable()]\n",
      "[2024-12-24 18:15:17,929] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,929] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,930] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,930] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(NoneType), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,930] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:15:17,930] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,931] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_4 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,931] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:17,931] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,933] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x1 [TensorVariable()]\n",
      "[2024-12-24 18:15:17,933] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,933] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:17,933] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2024-12-24 18:15:17,933] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST Ellipsis [TensorVariable()]\n",
      "[2024-12-24 18:15:17,934] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable(), ConstantVariable(ellipsis)]\n",
      "[2024-12-24 18:15:17,934] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable(), ConstantVariable(ellipsis), TensorVariable()]\n",
      "[2024-12-24 18:15:17,935] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable()]\n",
      "[2024-12-24 18:15:17,935] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstantVariable(ellipsis), ShapeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,937] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,937] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,938] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,938] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(ellipsis), ConstantVariable(int), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,938] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), ConstantVariable(ellipsis), SliceVariable()]\n",
      "[2024-12-24 18:15:17,939] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,940] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_5 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,940] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:17,940] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]          ~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,942] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x2 [TensorVariable()]\n",
      "[2024-12-24 18:15:17,942] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,942] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,942] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:17,942] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR cat [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:17,943] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:17,943] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,944] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call neg_1 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,944] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,944] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ^^^\n",
      "[2024-12-24 18:15:17,945] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:17,945] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,946] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable()]\n",
      "[2024-12-24 18:15:17,946] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,946] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,947] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method cat of type object at 0x7473c3d1cde0>), TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,947] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call cat_2 from rotate_half /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250 (inline depth: 2)\n",
      "[2024-12-24 18:15:17,947] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:17,947] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,949] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object rotate_half at 0x74731a012550, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 246>\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST sin [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_5 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:17,950] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                            ~~~~~~~~~~~~~~~^~~~~\n",
      "[2024-12-24 18:15:17,952] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,952] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,952] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:17,952] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]               ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:17,953] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST k_embed [TensorVariable()]\n",
      "[2024-12-24 18:15:17,953] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line apply_rotary_pos_emb /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:277 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,953] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return q_embed, k_embed\n",
      "[2024-12-24 18:15:17,954] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_embed []\n",
      "[2024-12-24 18:15:17,954] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST k_embed [TensorVariable()]\n",
      "[2024-12-24 18:15:17,954] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 2 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,954] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:17,955] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object apply_rotary_pos_emb at 0x74731a06e430, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 253>\n",
      "[2024-12-24 18:15:17,955] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 2 [TupleVariable()]\n",
      "[2024-12-24 18:15:17,955] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST query_states [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,956] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,956] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:416\n",
      "[2024-12-24 18:15:17,956] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if past_key_value is not None:\n",
      "[2024-12-24 18:15:17,956] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value []\n",
      "[2024-12-24 18:15:17,957] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,957] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,957] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1468 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,958] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-24 18:15:17,958] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:15:17,958] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-24 18:15:17,958] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,959] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,959] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,959] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,960] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,960] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:421\n",
      "[2024-12-24 18:15:17,960] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:15:17,960] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                      ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,960] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:15:17,961] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,961] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-24 18:15:17,961] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_hidden_states_ : torch.Tensor):\n",
      "    l_hidden_states_ = L_hidden_states_\n",
      "    l__self___q_proj = self.L__self___q_proj(l_hidden_states_)\n",
      "    l__self___k_proj = self.L__self___k_proj(l_hidden_states_)\n",
      "    l__self___v_proj = self.L__self___v_proj(l_hidden_states_);  l_hidden_states_ = None\n",
      "    view = l__self___q_proj.view(1, 7, 32, 64);  l__self___q_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    view_1 = l__self___k_proj.view(1, 7, 8, 64);  l__self___k_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    view_2 = l__self___v_proj.view(1, 7, 8, 64);  l__self___v_proj = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    return (transpose, transpose_1, transpose_2)\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-24 18:15:17,961] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,961] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-24 18:15:17,962] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,962] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-24 18:15:17,962] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,963] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-24 18:15:17,964] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-24 18:15:17,964] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,964] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,965] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,965] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,965] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,965] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,965] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,966] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,966] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,966] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,966] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,967] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,967] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,967] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,967] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,968] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,968] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:15:17,968] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,968] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,969] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,969] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,969] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_6 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,969] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,969] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,972] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,973] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,974] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,974] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,974] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,975] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,975] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,975] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,976] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,976] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:15:17,976] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:15:17,976] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,977] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,977] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,977] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,977] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,977] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,978] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,978] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,978] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,978] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,979] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,980] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:15:17,980] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST key_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,980] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-24 18:15:17,980] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:15:17,980] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL repeat_kv []\n",
      "[2024-12-24 18:15:17,981] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, UserFunctionVariable()]\n",
      "[2024-12-24 18:15:17,981] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, UserFunctionVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:17,981] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_key_value_groups [NullVariable, UserFunctionVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:17,981] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,981] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, UserFunctionVariable(), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call repeat_kv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:422\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:314 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,982] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]     def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
      "[2024-12-24 18:15:17,983] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:17,983] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:319 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,983] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
      "[2024-12-24 18:15:17,983] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,983] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR shape [TensorVariable()]\n",
      "[2024-12-24 18:15:17,984] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 4 [ShapeVariable()]\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST batch [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST num_key_value_heads [ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST slen [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST head_dim [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:320 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,985] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         if n_rep == 1:\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep []\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP == [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 42 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,986] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,987] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,988] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,988] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,988] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,988] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,989] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable()]\n",
      "[2024-12-24 18:15:17,989] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,989] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_SLICE 2 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:17,989] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 5 [TensorVariable(), SliceVariable(), SliceVariable(), ConstantVariable(NoneType), SliceVariable(), SliceVariable()]\n",
      "[2024-12-24 18:15:17,990] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:17,990] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call getitem_7 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,990] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,990] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,992] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD expand [TensorVariable()]\n",
      "[2024-12-24 18:15:17,992] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), expand)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 5 [NullVariable, GetAttrVariable(TensorVariable(), expand), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call expand_2 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,993] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,995] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:17,995] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,995] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,995] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:17,995] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:15:17,996] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST batch [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:15:17,996] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST num_key_value_heads [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,996] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST n_rep [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,996] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST slen [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST head_dim [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 4 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_1 from repeat_kv /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323 (inline depth: 1)\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]     return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:17,997] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]            ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:17,999] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:17,999] [9/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object repeat_kv at 0x747319f05b80, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 314>\n",
      "[2024-12-24 18:15:17,999] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST value_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,000] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:15:18,000] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:15:18,000] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:18,000] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,000] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:18,001] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST key_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,001] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,001] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:18,001] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 3 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,002] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,002] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,002] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:15:18,002] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:15:18,002] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                   ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:18,003] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,003] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,003] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_1 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:15:18,003] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:15:18,003] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,005] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL math [TensorVariable()]\n",
      "[2024-12-24 18:15:18,005] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sqrt [TensorVariable(), NullVariable, TorchVariable(<module 'math' from '/home/gaurav/anaconda3/lib/python3.11/lib-dynload/math.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:18,005] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>)]\n",
      "[2024-12-24 18:15:18,006] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,006] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,006] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in function sqrt>), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,006] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 11 [TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:18,007] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call truediv from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424\n",
      "[2024-12-24 18:15:18,007] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:15:18,007] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,007] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:426\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attention_mask is not None:  # no matter the length, we just slice it\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attention_mask []\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE IS_OP 0 [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,008] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 1766 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,009] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:15:18,009] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:15:18,009] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-24 18:15:18,009] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,009] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-24 18:15:18,010] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>)]\n",
      "[2024-12-24 18:15:18,010] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,010] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,010] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim', 'dtype') [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function softmax at 0x7473cf53e5c0>), TensorVariable(), ConstantVariable(int), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call softmax from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:15:18,011] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,014] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:15:18,015] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST query_states [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:18,015] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [NullVariable, GetAttrVariable(TensorVariable(), to), TensorVariable()]\n",
      "[2024-12-24 18:15:18,015] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:18,015] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-24 18:15:18,016] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:15:18,017] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL nn []\n",
      "[2024-12-24 18:15:18,017] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR functional [TorchVariable(<module 'torch.nn' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,017] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD dropout [TorchVariable(<module 'torch.nn.functional' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py'>)]\n",
      "[2024-12-24 18:15:18,018] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>)]\n",
      "[2024-12-24 18:15:18,019] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,019] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR attention_dropout [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,020] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:18,021] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR training [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,021] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('p', 'training') [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,023] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,023] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, TorchVariable(<function dropout at 0x7473cf53d940>), TensorVariable(), ConstantVariable(float), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,024] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call dropout from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432\n",
      "[2024-12-24 18:15:18,024] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:15:18,024] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                        ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,025] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:15:18,025] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-24 18:15:18,025] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:15:18,026] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:18,026] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR matmul [NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,027] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:18,029] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST value_states [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,029] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,030] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method matmul of type object at 0x7473c3d1cde0>), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,031] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call matmul_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433\n",
      "[2024-12-24 18:15:18,031] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:15:18,031] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,034] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,034] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:435\n",
      "[2024-12-24 18:15:18,034] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
      "[2024-12-24 18:15:18,035] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:15:18,035] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD size [TensorVariable()]\n",
      "[2024-12-24 18:15:18,035] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:18,036] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), size)]\n",
      "[2024-12-24 18:15:18,036] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [SizeVariable()]\n",
      "[2024-12-24 18:15:18,036] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,037] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR num_heads [SizeVariable(), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,037] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [SizeVariable(), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,037] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,038] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR head_dim [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,038] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 4 [SizeVariable(), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,038] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP != [SizeVariable(), TupleVariable()]\n",
      "[2024-12-24 18:15:18,038] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2214 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD transpose [TensorVariable()]\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, GetAttrVariable(TensorVariable(), transpose)]\n",
      "[2024-12-24 18:15:18,039] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,040] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,040] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), transpose), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,040] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call transpose_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:15:18,040] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:15:18,040] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "[2024-12-24 18:15:18,041] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD contiguous [TensorVariable()]\n",
      "[2024-12-24 18:15:18,041] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-24 18:15:18,041] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, GetAttrVariable(TensorVariable(), contiguous)]\n",
      "[2024-12-24 18:15:18,042] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call contiguous from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441\n",
      "[2024-12-24 18:15:18,042] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:15:18,042] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "[2024-12-24 18:15:18,042] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,043] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-24 18:15:18,043] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:15:18,043] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:15:18,043] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD reshape [TensorVariable()]\n",
      "[2024-12-24 18:15:18,043] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST bsz [NullVariable, GetAttrVariable(TensorVariable(), reshape)]\n",
      "[2024-12-24 18:15:18,044] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST q_len [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,044] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,044] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,044] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 3 [NullVariable, GetAttrVariable(TensorVariable(), reshape), ConstantVariable(int), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,045] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call reshape_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443\n",
      "[2024-12-24 18:15:18,045] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:15:18,045] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                       ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,046] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,046] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:445\n",
      "[2024-12-24 18:15:18,046] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:15:18,046] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,047] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,047] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:15:18,047] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,048] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,048] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 2660 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,048] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-24 18:15:18,048] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:15:18,048] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,049] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD o_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,049] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,049] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,049] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,050] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___o_proj from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450\n",
      "[2024-12-24 18:15:18,050] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:15:18,050] [9/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                           ~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,052] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_DEREF attn_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,052] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:452\n",
      "[2024-12-24 18:15:18,052] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not output_attentions:\n",
      "[2024-12-24 18:15:18,052] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-24 18:15:18,052] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 2710 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:453\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 attn_weights = None\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None []\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST attn_weights [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:455\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return attn_output, attn_weights, past_key_value\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF attn_output []\n",
      "[2024-12-24 18:15:18,053] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST attn_weights [TensorVariable()]\n",
      "[2024-12-24 18:15:18,054] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST past_key_value [TensorVariable(), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,054] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 3 [TensorVariable(), ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,054] [9/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:18,054] [9/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:15:18,055] [9/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:15:18,055] [9/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 455 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:15:18,056] [9/0] torch._dynamo.output_graph: [DEBUG] REMOVE UNUSED GRAPHARG L['hidden_states']\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_15 =====\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.9 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_position_ids_ = L_position_ids_\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_query_states_ = L_query_states_\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_key_states_ = L_key_states_\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_value_states_ = L_value_states_\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:203, code: inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_1 = getitem.float();  getitem = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:204, code: position_ids_expanded = position_ids[:, None, :].float()\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_2 = getitem_1.float();  getitem_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:209, code: freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_3 = expand.float();  expand = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         float_4 = float_2.float();  float_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose = matmul.transpose(1, 2);  matmul = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:210, code: emb = torch.cat((freqs, freqs), dim=-1)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:211, code: cos = emb.cos()\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cos = cat.cos()\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:212, code: sin = emb.sin()\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         sin = cat.sin();  cat = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:215, code: cos = cos * self.attention_scaling\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = cos * 1.0;  cos = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:216, code: sin = sin * self.attention_scaling\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = sin * 1.0;  sin = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:218, code: return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = mul.to(dtype = torch.float32);  mul = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # No stacktrace found for following nodes\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:273, code: cos = cos.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze = to.unsqueeze(1);  to = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:274, code: sin = sin.unsqueeze(unsqueeze_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l_query_states_ * unsqueeze\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg = -getitem_3;  getitem_3 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:275, code: q_embed = (q * cos) + (rotate_half(q) * sin)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:248, code: x1 = x[..., : x.shape[-1] // 2]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:249, code: x2 = x[..., x.shape[-1] // 2 :]\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:250, code: return torch.cat((-x2, x1), dim=-1)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         neg_1 = -getitem_5;  getitem_5 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:276, code: k_embed = (k * cos) + (rotate_half(k) * sin)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:322, code: hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323, code: return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:424, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:431, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_2 = softmax.to(torch.float32);  softmax = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:432, code: attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:433, code: attn_output = torch.matmul(attn_weights, value_states)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:441, code: attn_output = attn_output.transpose(1, 2).contiguous()\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:443, code: attn_output = attn_output.reshape(bsz, q_len, -1)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:450, code: attn_output = self.o_proj(attn_output)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___o_proj,)\n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,058] [9/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_15 <eval_with_key>.9 opcode         name                           target                                                     args                                                                                                                           kwargs\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------  ---------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------  -----------------------------------\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_position_ids_                L_position_ids_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_query_states_                L_query_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_key_states_                  L_key_states_                                              ()                                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_value_states_                L_value_states_                                            ()                                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled              <built-in function _set_grad_enabled>                      (False,)                                                                                                                       {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___rotary_emb_inv_freq  L__self___rotary_emb_inv_freq                              ()                                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem                        <built-in function getitem>                                (l__self___rotary_emb_inv_freq, (None, slice(None, None, None), None))                                                         {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_1                        float                                                      (getitem,)                                                                                                                     {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand                         expand                                                     (float_1, 1, -1, 1)                                                                                                            {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_1                      <built-in function getitem>                                (l_position_ids_, (slice(None, None, None), None, slice(None, None, None)))                                                    {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_2                        float                                                      (getitem_1,)                                                                                                                   {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _enter_autocast                <function _enter_autocast at 0x7473d83198a0>               ('cuda', None, False, None)                                                                                                    {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_3                        float                                                      (expand,)                                                                                                                      {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    float_4                        float                                                      (float_2,)                                                                                                                     {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul                         <built-in function matmul>                                 (float_3, float_4)                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose                      transpose                                                  (matmul, 1, 2)                                                                                                                 {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat                            <built-in method cat of type object at 0x7473c3d1cde0>     ((transpose, transpose),)                                                                                                      {'dim': -1}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    cos                            cos                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    sin                            sin                                                        (cat,)                                                                                                                         {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _exit_autocast                 <function _exit_autocast at 0x7473d8319bc0>                (_enter_autocast,)                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                            <built-in function mul>                                    (cos, 1.0)                                                                                                                     {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                          <built-in function mul>                                    (sin, 1.0)                                                                                                                     {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                             to                                                         (mul,)                                                                                                                         {'dtype': torch.float32}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                           to                                                         (mul_1,)                                                                                                                       {'dtype': torch.float32}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  _set_grad_enabled_1            <built-in function _set_grad_enabled>                      (True,)                                                                                                                        {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze                      unsqueeze                                                  (to, 1)                                                                                                                        {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    unsqueeze_1                    unsqueeze                                                  (to_1, 1)                                                                                                                      {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                          <built-in function mul>                                    (l_query_states_, unsqueeze)                                                                                                   {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_2                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(None, 32, None)))                                                                           {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_3                      <built-in function getitem>                                (l_query_states_, (Ellipsis, slice(32, None, None)))                                                                           {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg                            <built-in function neg>                                    (getitem_3,)                                                                                                                   {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_1                          <built-in method cat of type object at 0x7473c3d1cde0>     ((neg, getitem_2),)                                                                                                            {'dim': -1}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_3                          <built-in function mul>                                    (cat_1, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                            <built-in function add>                                    (mul_2, mul_3)                                                                                                                 {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_4                          <built-in function mul>                                    (l_key_states_, unsqueeze)                                                                                                     {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_4                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(None, 32, None)))                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_5                      <built-in function getitem>                                (l_key_states_, (Ellipsis, slice(32, None, None)))                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  neg_1                          <built-in function neg>                                    (getitem_5,)                                                                                                                   {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  cat_2                          <built-in method cat of type object at 0x7473c3d1cde0>     ((neg_1, getitem_4),)                                                                                                          {'dim': -1}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_5                          <built-in function mul>                                    (cat_2, unsqueeze_1)                                                                                                           {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                          <built-in function add>                                    (mul_4, mul_5)                                                                                                                 {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_6                      <built-in function getitem>                                (add_1, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))            {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_1                       expand                                                     (getitem_6, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape                        reshape                                                    (expand_1, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  getitem_7                      <built-in function getitem>                                (l_value_states_, (slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None)))  {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    expand_2                       expand                                                     (getitem_7, 1, 8, 4, 7, 64)                                                                                                    {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_1                      reshape                                                    (expand_2, 1, 32, 7, 64)                                                                                                       {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_1                    transpose                                                  (reshape, 2, 3)                                                                                                                {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_1                       <built-in method matmul of type object at 0x7473c3d1cde0>  (add, transpose_1)                                                                                                             {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  truediv                        <built-in function truediv>                                (matmul_1, 8.0)                                                                                                                {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  softmax                        <function softmax at 0x7473cf53e5c0>                       (truediv,)                                                                                                                     {'dim': -1, 'dtype': torch.float32}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_2                           to                                                         (softmax, torch.float32)                                                                                                       {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  dropout                        <function dropout at 0x7473cf53d940>                       (to_2,)                                                                                                                        {'p': 0.0, 'training': False}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  matmul_2                       <built-in method matmul of type object at 0x7473c3d1cde0>  (dropout, reshape_1)                                                                                                           {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    transpose_2                    transpose                                                  (matmul_2, 1, 2)                                                                                                               {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    contiguous                     contiguous                                                 (transpose_2,)                                                                                                                 {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    reshape_2                      reshape                                                    (contiguous, 1, 7, -1)                                                                                                         {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___o_proj               L__self___o_proj                                           (reshape_2,)                                                                                                                   {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                         output                                                     ((l__self___o_proj,),)                                                                                                         {}\n",
      "[2024-12-24 18:15:18,060] [9/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_15 =====\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_position_ids_: (1, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_query_states_: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_key_states_: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_value_states_: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___rotary_emb_inv_freq: (32,)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem: (1, 32, 1)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_1: (1, 32, 1)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand: (1, 32, 1)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_1: (1, 1, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_2: (1, 1, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_3: (1, 32, 1)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] float_4: (1, 1, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul: (1, 32, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose: (1, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cos: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] sin: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze: (1, 1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] unsqueeze_1: (1, 1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_2: (1, 32, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_3: (1, 32, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg: (1, 32, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_1: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_3: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_4: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_4: (1, 8, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_5: (1, 8, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] neg_1: (1, 8, 7, 32)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] cat_2: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_5: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 8, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_6: (1, 8, 1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_1: (1, 8, 4, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getitem_7: (1, 8, 1, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] expand_2: (1, 8, 4, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_1: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_1: (1, 32, 64, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_1: (1, 32, 7, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] truediv: (1, 32, 7, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] softmax: (1, 32, 7, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_2: (1, 32, 7, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] dropout: (1, 32, 7, 7)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] matmul_2: (1, 32, 7, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] transpose_2: (1, 7, 32, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] contiguous: (1, 7, 32, 64)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] reshape_2: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___o_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:18,065] [9/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:18,066] [9/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:18,072] [9/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:18,072] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['bsz'], 8837664)                           # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:15:18,073] [9/0] torch._dynamo.guards.__guards: [DEBUG] L['bsz'] == 1                                                 # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:15:18,073] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037686901648)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,074] [9/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,074] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['q_len'], 8837664)                         # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:15:18,075] [9/0] torch._dynamo.guards.__guards: [DEBUG] L['q_len'] == 7                                               # if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):  # transformers/models/llama/modeling_llama.py:435 in <resume in forward>\n",
      "[2024-12-24 18:15:18,075] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['key_states'], 115763376)                  # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-24 18:15:18,076] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['key_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,076] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['position_ids'], 115763376)                # inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)  # transformers/models/llama/modeling_llama.py:203 in forward\n",
      "[2024-12-24 18:15:18,077] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['position_ids'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,077] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['query_states'], 115763376)                # x1 = x[..., : x.shape[-1] // 2]  # transformers/models/llama/modeling_llama.py:248 in rotate_half\n",
      "[2024-12-24 18:15:18,078] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['query_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,078] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['value_states'], 115763376)                # device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"  # transformers/models/llama/modeling_llama.py:207 in forward\n",
      "[2024-12-24 18:15:18,079] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['value_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,079] [9/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['hidden_states'], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,079] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['attention_mask'], 8820832)                 # if attention_mask is not None:  # no matter the length, we just slice it  # transformers/models/llama/modeling_llama.py:426 in <resume in forward>\n",
      "[2024-12-24 18:15:18,080] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['past_key_value'], 8820832)                 # if past_key_value is not None:  # transformers/models/llama/modeling_llama.py:416 in <resume in forward>\n",
      "[2024-12-24 18:15:18,080] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if not output_attentions:  # transformers/models/llama/modeling_llama.py:452 in <resume in forward>\n",
      "[2024-12-24 18:15:18,081] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,081] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # with ctx_factory():  # utils/_contextlib.py:114 in decorate_context\n",
      "[2024-12-24 18:15:18,081] [9/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,081] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,082] [9/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,082] [9/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)  # transformers/models/llama/modeling_llama.py:431 in <resume in forward>\n",
      "[2024-12-24 18:15:18,082] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['apply_rotary_pos_emb'].__defaults__[1], 8837664)  # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-24 18:15:18,083] [9/0] torch._dynamo.guards.__guards: [DEBUG] G['apply_rotary_pos_emb'].__defaults__[1] == 1                # cos = cos.unsqueeze(unsqueeze_dim)  # transformers/models/llama/modeling_llama.py:273 in apply_rotary_pos_emb\n",
      "[2024-12-24 18:15:18,083] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,084] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,084] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,084] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,084] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,085] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,085] [9/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,085] [9/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,086] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['key_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,086] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['position_ids'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.int64, device=0, requires_grad=False, size=[1, 7], stride=[7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,086] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['query_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32, 7, 64], stride=[14336, 64, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,086] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['value_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 8, 7, 64], stride=[3584, 64, 512, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,087] [9/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['hidden_states'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,091] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:18,092] [10/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:18,092] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\n",
      "[2024-12-24 18:15:18,092] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "[2024-12-24 18:15:18,092] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:18,094] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['residual'] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:18,094] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,095] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:15:18,095] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 96 [TupleVariable()]\n",
      "[2024-12-24 18:15:18,095] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNPACK_SEQUENCE 3 [TupleVariable()]\n",
      "[2024-12-24 18:15:18,095] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [ConstantVariable(NoneType), ConstantVariable(NoneType), TensorVariable()]\n",
      "[2024-12-24 18:15:18,095] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST self_attn_weights [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST present_key_value [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,096] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,097] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745\n",
      "[2024-12-24 18:15:18,097] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,097] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,097] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:748\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             residual = hidden_states\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST residual [TensorVariable()]\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,098] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD post_attention_layernorm [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,099] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,099] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,099] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,100] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:749\n",
      "[2024-12-24 18:15:18,100] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.post_attention_layernorm(hidden_states)\n",
      "[2024-12-24 18:15:18,100] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,100] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:18,102] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,102] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:18,102] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,103] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,103] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:18,103] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:18,103] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,104] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:18,104] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:18,104] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,105] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,106] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,106] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,106] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,106] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,107] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,107] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,107] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,107] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,107] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,108] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,109] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,110] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,110] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:18,110] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:18,110] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,110] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,111] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:18,112] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:18,113] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:18,113] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:18,113] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:18,113] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,113] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,114] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaRMSNorm.forward at 0x7473187ec0e0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:120 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,115] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, hidden_states):\n",
      "[2024-12-24 18:15:18,116] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,116] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:121 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,116] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             input_dtype = hidden_states.dtype\n",
      "[2024-12-24 18:15:18,116] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,116] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR dtype [TensorVariable()]\n",
      "[2024-12-24 18:15:18,117] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST input_dtype [TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:18,117] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,117] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:18,117] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,117] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable()]\n",
      "[2024-12-24 18:15:18,118] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:18,118] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR float32 [NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,118] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:18,119] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), to), ConstantVariable(dtype)]\n",
      "[2024-12-24 18:15:18,119] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,119] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:18,119] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,120] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,120] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,120] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:18,120] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,120] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD pow [TensorVariable()]\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [NullVariable, GetAttrVariable(TensorVariable(), pow)]\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, GetAttrVariable(TensorVariable(), pow), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call pow_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:18,121] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:18,123] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TensorVariable()]\n",
      "[2024-12-24 18:15:18,123] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [NullVariable, GetAttrVariable(TensorVariable(), mean)]\n",
      "[2024-12-24 18:15:18,123] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST True [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,123] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('keepdim',) [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,123] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,124] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, GetAttrVariable(TensorVariable(), mean), ConstantVariable(int), ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,124] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,124] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:18,124] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,125] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST variance [TensorVariable()]\n",
      "[2024-12-24 18:15:18,125] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,125] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:18,125] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,126] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [TensorVariable()]\n",
      "[2024-12-24 18:15:18,126] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR rsqrt [TensorVariable(), NullVariable, TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,126] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST variance [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR variance_epsilon [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(float)]\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:18,127] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                     ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,128] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,129] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, TorchVariable(<built-in method rsqrt of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,129] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call rsqrt from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,129] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:18,129] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                         ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,130] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,130] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,130] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:18,130] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,131] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,131] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,131] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:18,131] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,131] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR weight [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,132] [10/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['self'].post_attention_layernorm.weight (2048,) [<DimDynamic.STATIC: 2>] [None]\n",
      "[2024-12-24 18:15:18,132] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD to [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST input_dtype [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to)]\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [TensorVariable(), NullVariable, GetAttrVariable(TensorVariable(), to), TorchVariable(torch.float32)]\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call to_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:18,133] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,134] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,134] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_1 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,134] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:18,134] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,135] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:18,135] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x74731a1972d0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 120>\n",
      "[2024-12-24 18:15:18,135] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:18,135] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:18,136] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,136] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-24 18:15:18,136] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-24 18:15:18,136] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,136] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mlp [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call _call_impl from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:750\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]         hidden_states = self.mlp(hidden_states)\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                         ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,137] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1521 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:18,140] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/_C.cpython-311-x86_64-linux-gnu.so'>)]\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 0 [NullVariable, TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7473d9734180>)]\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 76 [ConstantVariable(NoneType)]\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,141] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,142] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,143] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,143] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,143] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,143] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,143] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:18,144] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1525 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,145] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,146] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1526 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1524 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_TRUE 218 [ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,147] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PUSH_NULL None []\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call [NullVariable]\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable())]\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable()]\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,148] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE DICT_MERGE 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,149] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [NullVariable, UserMethodVariable(<function LlamaMLP.forward at 0x7473187ec900>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2024-12-24 18:15:18,149] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG] TRACE inlined call forward from _call_impl /home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527 (inline depth: 1)\n",
      "[2024-12-24 18:15:18,149] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]             return forward_call(*args, **kwargs)\n",
      "[2024-12-24 18:15:18,149] [10/0] torch._dynamo.symbolic_convert.__trace_call: [DEBUG]                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,149] [10/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x9c10f60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-24 18:15:18,150] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:291 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,150] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2024-12-24 18:15:18,150] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL x []\n",
      "[2024-12-24 18:15:18,150] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL down_proj_slices []\n",
      "[2024-12-24 18:15:18,150] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL gate_proj_slices []\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL intermediate_states []\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE MAKE_CELL up_proj_slices []\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:292 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.config.pretraining_tp > 1:\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,151] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR config [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pretraining_tp [HFPretrainedConfigVariable()]\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [ConstantVariable(int), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 712 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,152] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,153] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,153] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD down_proj [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,153] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,153] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD act_fn [NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,154] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,154] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD gate_proj [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,154] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,154] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,155] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,155] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_gate_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,155] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,155] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                    ~~~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:18,158] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,159] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,159] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_act_fn from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,159] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,159] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,161] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,161] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD up_proj [NullVariable, NNModuleVariable(), TensorVariable(), NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,161] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_DEREF x [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,162] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,162] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable(), NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,162] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_up_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,162] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,162] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                                                         ~~~~~~~~~~~~^^^\n",
      "[2024-12-24 18:15:18,166] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 5 [NullVariable, NNModuleVariable(), TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,166] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mul_2 from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,166] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,166] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,167] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,168] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,169] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___mlp_down_proj from forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,169] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]             down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,169] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,173] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST down_proj [TensorVariable()]\n",
      "[2024-12-24 18:15:18,174] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:311 (inline depth: 2)\n",
      "[2024-12-24 18:15:18,174] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return down_proj\n",
      "[2024-12-24 18:15:18,174] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST down_proj []\n",
      "[2024-12-24 18:15:18,174] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:18,175] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x9c10f60, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 291>\n",
      "[2024-12-24 18:15:18,175] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:18,175] [10/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x70217f0, file \"/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2024-12-24 18:15:18,175] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST residual []\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call add_2 from <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,176] [10/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "[2024-12-24 18:15:18,178] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST hidden_states [TensorVariable()]\n",
      "[2024-12-24 18:15:18,178] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:753\n",
      "[2024-12-24 18:15:18,178] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             outputs = (hidden_states,)\n",
      "[2024-12-24 18:15:18,179] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST hidden_states []\n",
      "[2024-12-24 18:15:18,179] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_TUPLE 1 [TensorVariable()]\n",
      "[2024-12-24 18:15:18,179] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST outputs [TupleVariable()]\n",
      "[2024-12-24 18:15:18,179] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:755\n",
      "[2024-12-24 18:15:18,179] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if output_attentions:\n",
      "[2024-12-24 18:15:18,180] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST output_attentions []\n",
      "[2024-12-24 18:15:18,180] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 236 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,180] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:758\n",
      "[2024-12-24 18:15:18,180] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if use_cache:\n",
      "[2024-12-24 18:15:18,181] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST use_cache []\n",
      "[2024-12-24 18:15:18,181] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_FORWARD_IF_FALSE 252 [ConstantVariable(bool)]\n",
      "[2024-12-24 18:15:18,181] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:761\n",
      "[2024-12-24 18:15:18,181] [10/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return outputs\n",
      "[2024-12-24 18:15:18,181] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST outputs []\n",
      "[2024-12-24 18:15:18,182] [10/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TupleVariable()]\n",
      "[2024-12-24 18:15:18,182] [10/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:15:18,182] [10/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:15:18,183] [10/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py, line 761 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_16 =====\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.10 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_residual_ = L_residual_\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:745, code: hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:122, code: hidden_states = hidden_states.to(torch.float32)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to = add.to(torch.float32)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:123, code: variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         pow_1 = to.pow(2)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:124, code: hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_1 = mean + 1e-05;  mean = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul = to * rsqrt;  to = rsqrt = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:125, code: return self.weight * hidden_states.to(input_dtype)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         to_1 = mul.to(torch.float32);  mul = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:309, code: down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/gaurav/anaconda3/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:751, code: hidden_states = residual + hidden_states\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (add_2,)\n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,184] [10/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_16 <eval_with_key>.10 opcode         name                                       target                                                    args                                               kwargs\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------------------------------  --------------------------------------------------------  -------------------------------------------------  -----------------\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_                                L_stack0_0_                                               ()                                                 {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_residual_                                L_residual_                                               ()                                                 {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add                                        <built-in function add>                                   (l_residual_, l_stack0_0_)                         {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to                                         to                                                        (add, torch.float32)                               {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    pow_1                                      pow                                                       (to, 2)                                            {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    mean                                       mean                                                      (pow_1, -1)                                        {'keepdim': True}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_1                                      <built-in function add>                                   (mean, 1e-05)                                      {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  rsqrt                                      <built-in method rsqrt of type object at 0x7473c3d1cde0>  (add_1,)                                           {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul                                        <built-in function mul>                                   (to, rsqrt)                                        {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] get_attr       l__self___post_attention_layernorm_weight  L__self___post_attention_layernorm_weight                 ()                                                 {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_method    to_1                                       to                                                        (mul, torch.float32)                               {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_1                                      <built-in function mul>                                   (l__self___post_attention_layernorm_weight, to_1)  {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_gate_proj                    L__self___mlp_gate_proj                                   (mul_1,)                                           {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_act_fn                       L__self___mlp_act_fn                                      (l__self___mlp_gate_proj,)                         {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_up_proj                      L__self___mlp_up_proj                                     (mul_1,)                                           {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mul_2                                      <built-in function mul>                                   (l__self___mlp_act_fn, l__self___mlp_up_proj)      {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___mlp_down_proj                    L__self___mlp_down_proj                                   (mul_2,)                                           {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  add_2                                      <built-in function add>                                   (add, l__self___mlp_down_proj)                     {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                     output                                                    ((add_2,),)                                        {}\n",
      "[2024-12-24 18:15:18,185] [10/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_16 =====\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_residual_: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] pow_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 7, 1)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_1: (1, 7, 1)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] rsqrt: (1, 7, 1)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___post_attention_layernorm_weight: (2048,)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] to_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_1: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_gate_proj: (1, 7, 8192)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_act_fn: (1, 7, 8192)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_up_proj: (1, 7, 8192)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mul_2: (1, 7, 8192)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___mlp_down_proj: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] add_2: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,186] [10/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:18,187] [10/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:18,187] [10/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:18,189] [10/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:18,190] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749745808)                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,190] [10/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == False                                   # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,191] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['residual'], '_dynamo_dynamic_indices') == False    # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,191] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:18,191] [10/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 3                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:18,191] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['use_cache'], 8905664)                      # if use_cache:  # transformers/models/llama/modeling_llama.py:758 in <resume in forward>\n",
      "[2024-12-24 18:15:18,192] [10/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,192] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][1], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-24 18:15:18,192] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['___stack0'][2], 8820832)                   # hidden_states, self_attn_weights, present_key_value = self.self_attn(  # transformers/models/llama/modeling_llama.py:734 in <resume in forward>\n",
      "[2024-12-24 18:15:18,192] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['output_attentions'], 8905664)              # if output_attentions:  # transformers/models/llama/modeling_llama.py:755 in <resume in forward>\n",
      "[2024-12-24 18:15:18,193] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,193] [10/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,193] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,194] [10/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,194] [10/0] torch._dynamo.guards.__guards: [DEBUG] str(G['torch'].float32) == 'torch.float32'                    # hidden_states = hidden_states.to(torch.float32)  # transformers/models/llama/modeling_llama.py:122 in forward\n",
      "[2024-12-24 18:15:18,194] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,195] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,196] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,196] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,196] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,197] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,197] [10/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 8829024)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,197] [10/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2024-12-24 18:15:18,198] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['residual'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,198] [10/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,201] torch._logging._internal: [WARNING] Using TORCH_LOGS environment variable for log settings, ignoring call to set_logs\n",
      "[2024-12-24 18:15:18,202] [11/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <resume in forward> /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:15:18,202] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:34\n",
      "[2024-12-24 18:15:18,202] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             layer_output = self.first_layer(embeddings, position_ids=position_ids)[0]\n",
      "[2024-12-24 18:15:18,203] [11/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['___stack0'][0] (1, 7, 2048) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None]\n",
      "[2024-12-24 18:15:18,204] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RESUME 0 []\n",
      "[2024-12-24 18:15:18,204] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2024-12-24 18:15:18,204] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_FORWARD 238 [TupleVariable()]\n",
      "[2024-12-24 18:15:18,204] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TupleVariable()]\n",
      "[2024-12-24 18:15:18,204] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TupleVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST layer_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:37\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD mean [TorchVariable(<module 'torch' from '/home/gaurav/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>)]\n",
      "[2024-12-24 18:15:18,205] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST layer_output [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>)]\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable()]\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE KW_NAMES ('dim',) [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 2 [NullVariable, TorchVariable(<built-in method mean of type object at 0x7473c3d1cde0>), TensorVariable(), ConstantVariable(int)]\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call mean from <resume in forward> /tmp/ipykernel_1020204/343866.py:37\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:15:18,206] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,207] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST pooled_output [TensorVariable()]\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:40\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD linear [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pooled_output [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,208] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,209] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___linear from <resume in forward> /tmp/ipykernel_1020204/343866.py:40\n",
      "[2024-12-24 18:15:18,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:15:18,209] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                  ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "[2024-12-24 18:15:18,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST logits [TensorVariable()]\n",
      "[2024-12-24 18:15:18,212] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:43\n",
      "[2024-12-24 18:15:18,212] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             probs = self.softmax(logits)\n",
      "[2024-12-24 18:15:18,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2024-12-24 18:15:18,212] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_METHOD softmax [NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST logits [NullVariable, NNModuleVariable()]\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE PRECALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL 1 [NullVariable, NNModuleVariable(), TensorVariable()]\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG] TRACE FX call l__self___softmax from <resume in forward> /tmp/ipykernel_1020204/343866.py:43\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]         probs = self.softmax(logits)\n",
      "[2024-12-24 18:15:18,213] [11/0] torch._dynamo.output_graph.__trace_call: [DEBUG]                 ~~~~~~~~~~~~^^^^^^^^\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST probs [TensorVariable()]\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line <resume in forward> /tmp/ipykernel_1020204/343866.py:45\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return probs\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST probs []\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <resume in forward> (RETURN_VALUE)\n",
      "[2024-12-24 18:15:18,216] [11/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_1020204/343866.py, line 45 in <resume in forward>>], graph_break=False)\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_17 =====\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.11 class GraphModule(torch.nn.Module):\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_stack0_0_ = L_stack0_0_\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:37, code: pooled_output = torch.mean(layer_output, dim=1)\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:40, code: logits = self.linear(pooled_output)\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /tmp/ipykernel_1020204/343866.py:43, code: probs = self.softmax(logits)\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___softmax,)\n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2024-12-24 18:15:18,217] [11/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_17 <eval_with_key>.11 opcode         name               target                                                   args                     kwargs\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -----------------  -------------------------------------------------------  -----------------------  ----------\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_stack0_0_        L_stack0_0_                                              ()                       {}\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  mean               <built-in method mean of type object at 0x7473c3d1cde0>  (l_stack0_0_,)           {'dim': 1}\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___linear   L__self___linear                                         (mean,)                  {}\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___softmax  L__self___softmax                                        (l__self___linear,)      {}\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output             output                                                   ((l__self___softmax,),)  {}\n",
      "[2024-12-24 18:15:18,218] [11/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_17 =====\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_stack0_0_: (1, 7, 2048)\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] mean: (1, 2048)\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___linear: (1, 10)\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___softmax: (1, 10)\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_callback\n",
      "[2024-12-24 18:15:18,219] [11/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_callback\n",
      "[2024-12-24 18:15:18,221] [11/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2024-12-24 18:15:18,221] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 128037749707920)                   # logits = self.linear(pooled_output)  # mp/ipykernel_1020204/343866.py:40 in <resume in forward>\n",
      "[2024-12-24 18:15:18,221] [11/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # logits = self.linear(pooled_output)  # mp/ipykernel_1020204/343866.py:40 in <resume in forward>\n",
      "[2024-12-24 18:15:18,222] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(L['___stack0'], 8810304)                     # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:18,222] [11/0] torch._dynamo.guards.__guards: [DEBUG] len(L['___stack0']) == 1                                      # _dynamo/symbolic_convert.py:2071 in init_local_index_guards_hack\n",
      "[2024-12-24 18:15:18,222] [11/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['___stack0'][0], '_dynamo_dynamic_indices') == False  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2024-12-24 18:15:18,225] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,225] [11/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,226] [11/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,226] [11/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2024-12-24 18:15:18,228] [11/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['___stack0'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 7, 2048], stride=[14336, 2048, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, L_position_ids_ : torch.Tensor, L_query_states_ : torch.Tensor, L_key_states_ : torch.Tensor, L_value_states_ : torch.Tensor):\n",
      "    l_position_ids_ = L_position_ids_\n",
      "    l_query_states_ = L_query_states_\n",
      "    l_key_states_ = L_key_states_\n",
      "    l_value_states_ = L_value_states_\n",
      "    _set_grad_enabled = torch._C._set_grad_enabled(False)\n",
      "    l__self___rotary_emb_inv_freq = self.L__self___rotary_emb_inv_freq\n",
      "    getitem = l__self___rotary_emb_inv_freq[(None, slice(None, None, None), None)];  l__self___rotary_emb_inv_freq = None\n",
      "    float_1 = getitem.float();  getitem = None\n",
      "    expand = float_1.expand(1, -1, 1);  float_1 = None\n",
      "    getitem_1 = l_position_ids_[(slice(None, None, None), None, slice(None, None, None))];  l_position_ids_ = None\n",
      "    float_2 = getitem_1.float();  getitem_1 = None\n",
      "    _enter_autocast = torch.amp.autocast_mode._enter_autocast('cuda', None, False, None)\n",
      "    float_3 = expand.float();  expand = None\n",
      "    float_4 = float_2.float();  float_2 = None\n",
      "    matmul = float_3 @ float_4;  float_3 = float_4 = None\n",
      "    transpose = matmul.transpose(1, 2);  matmul = None\n",
      "    cat = torch.cat((transpose, transpose), dim = -1);  transpose = None\n",
      "    cos = cat.cos()\n",
      "    sin = cat.sin();  cat = None\n",
      "    _exit_autocast = torch.amp.autocast_mode._exit_autocast(_enter_autocast);  _enter_autocast = None\n",
      "    mul = cos * 1.0;  cos = None\n",
      "    mul_1 = sin * 1.0;  sin = None\n",
      "    to = mul.to(dtype = torch.float32);  mul = None\n",
      "    to_1 = mul_1.to(dtype = torch.float32);  mul_1 = None\n",
      "    _set_grad_enabled_1 = torch._C._set_grad_enabled(True)\n",
      "    unsqueeze = to.unsqueeze(1);  to = None\n",
      "    unsqueeze_1 = to_1.unsqueeze(1);  to_1 = None\n",
      "    mul_2 = l_query_states_ * unsqueeze\n",
      "    getitem_2 = l_query_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_3 = l_query_states_[(Ellipsis, slice(32, None, None))];  l_query_states_ = None\n",
      "    neg = -getitem_3;  getitem_3 = None\n",
      "    cat_1 = torch.cat((neg, getitem_2), dim = -1);  neg = getitem_2 = None\n",
      "    mul_3 = cat_1 * unsqueeze_1;  cat_1 = None\n",
      "    add = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "    mul_4 = l_key_states_ * unsqueeze;  unsqueeze = None\n",
      "    getitem_4 = l_key_states_[(Ellipsis, slice(None, 32, None))]\n",
      "    getitem_5 = l_key_states_[(Ellipsis, slice(32, None, None))];  l_key_states_ = None\n",
      "    neg_1 = -getitem_5;  getitem_5 = None\n",
      "    cat_2 = torch.cat((neg_1, getitem_4), dim = -1);  neg_1 = getitem_4 = None\n",
      "    mul_5 = cat_2 * unsqueeze_1;  cat_2 = unsqueeze_1 = None\n",
      "    add_1 = mul_4 + mul_5;  mul_4 = mul_5 = None\n",
      "    getitem_6 = add_1[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  add_1 = None\n",
      "    expand_1 = getitem_6.expand(1, 8, 4, 7, 64);  getitem_6 = None\n",
      "    reshape = expand_1.reshape(1, 32, 7, 64);  expand_1 = None\n",
      "    getitem_7 = l_value_states_[(slice(None, None, None), slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  l_value_states_ = None\n",
      "    expand_2 = getitem_7.expand(1, 8, 4, 7, 64);  getitem_7 = None\n",
      "    reshape_1 = expand_2.reshape(1, 32, 7, 64);  expand_2 = None\n",
      "    transpose_1 = reshape.transpose(2, 3);  reshape = None\n",
      "    matmul_1 = torch.matmul(add, transpose_1);  add = transpose_1 = None\n",
      "    truediv = matmul_1 / 8.0;  matmul_1 = None\n",
      "    softmax = torch.nn.functional.softmax(truediv, dim = -1, dtype = torch.float32);  truediv = None\n",
      "    to_2 = softmax.to(torch.float32);  softmax = None\n",
      "    dropout = torch.nn.functional.dropout(to_2, p = 0.0, training = False);  to_2 = None\n",
      "    matmul_2 = torch.matmul(dropout, reshape_1);  dropout = reshape_1 = None\n",
      "    transpose_2 = matmul_2.transpose(1, 2);  matmul_2 = None\n",
      "    contiguous = transpose_2.contiguous();  transpose_2 = None\n",
      "    reshape_2 = contiguous.reshape(1, 7, -1);  contiguous = None\n",
      "    l__self___o_proj = self.L__self___o_proj(reshape_2);  reshape_2 = None\n",
      "    return (l__self___o_proj,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor, L_residual_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    l_residual_ = L_residual_\n",
      "    add = l_residual_ + l_stack0_0_;  l_residual_ = l_stack0_0_ = None\n",
      "    to = add.to(torch.float32)\n",
      "    pow_1 = to.pow(2)\n",
      "    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None\n",
      "    add_1 = mean + 1e-05;  mean = None\n",
      "    rsqrt = torch.rsqrt(add_1);  add_1 = None\n",
      "    mul = to * rsqrt;  to = rsqrt = None\n",
      "    l__self___post_attention_layernorm_weight = self.L__self___post_attention_layernorm_weight\n",
      "    to_1 = mul.to(torch.float32);  mul = None\n",
      "    mul_1 = l__self___post_attention_layernorm_weight * to_1;  l__self___post_attention_layernorm_weight = to_1 = None\n",
      "    l__self___mlp_gate_proj = self.L__self___mlp_gate_proj(mul_1)\n",
      "    l__self___mlp_act_fn = self.L__self___mlp_act_fn(l__self___mlp_gate_proj);  l__self___mlp_gate_proj = None\n",
      "    l__self___mlp_up_proj = self.L__self___mlp_up_proj(mul_1);  mul_1 = None\n",
      "    mul_2 = l__self___mlp_act_fn * l__self___mlp_up_proj;  l__self___mlp_act_fn = l__self___mlp_up_proj = None\n",
      "    l__self___mlp_down_proj = self.L__self___mlp_down_proj(mul_2);  mul_2 = None\n",
      "    add_2 = add + l__self___mlp_down_proj;  add = l__self___mlp_down_proj = None\n",
      "    return (add_2,)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, L_stack0_0_ : torch.Tensor):\n",
      "    l_stack0_0_ = L_stack0_0_\n",
      "    mean = torch.mean(l_stack0_0_, dim = 1);  l_stack0_0_ = None\n",
      "    l__self___linear = self.L__self___linear(mean);  mean = None\n",
      "    l__self___softmax = self.L__self___softmax(l__self___linear);  l__self___linear = None\n",
      "    return (l__self___softmax,)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0962, 0.1018, 0.1038, 0.0996, 0.1004, 0.1000, 0.1052, 0.0968, 0.0978,\n",
       "         0.0983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Python code from the torch._dynamo graph\n",
    "def debug_callback(graph_module, example_inputs):\n",
    "    # Generate Python code for the traced graph\n",
    "    print(graph_module.code)\n",
    "    return graph_module\n",
    "\n",
    "# Wrap your model with the debug callback\n",
    "model_optimized = torch._dynamo.optimize(debug_callback)(model)\n",
    "\n",
    "# Run your model to trigger the tracing\n",
    "model_optimized(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps - Capturing `nn.Module` with Custom ops\n",
    "\n",
    "There are instances where PyTorch implementation can have custom ops - for instance where the programmer wants to force `kernel` fusion, they can define a custom op as such and would need `torch.compile` to respect that. And similarly in cases where there ops on `numpy` or `scipy` defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
