{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "torch_device = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel to load every other element from a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def stride_copy_kernel(in_ptr, out_ptr, N, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(0)\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    # Mask for input (every other element)\n",
    "    input_mask = (offsets * 2) < N\n",
    "    \n",
    "    # Mask for output (contiguous elements)\n",
    "    output_mask = offsets < (N // 2)\n",
    "    \n",
    "    inp_data = tl.load(in_ptr + (2 * offsets), mask=input_mask)\n",
    "    tl.store(out_ptr + offsets, inp_data, mask=output_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function to launch the kernel\n",
    "def stride_copy_wrapper(input_tensor, output_tensor):\n",
    "    # Assume last dimension is the one to stride over\n",
    "    n_elements = input_tensor.shape[-1]\n",
    "    assert n_elements % 2 == 0, \"Input tensor must have an even number of elements\"\n",
    "    \n",
    "    BLOCK_SIZE = 64\n",
    "    grid = (triton.cdiv(n_elements // 2, BLOCK_SIZE),)\n",
    "    \n",
    "    stride_copy_kernel[grid](\n",
    "        input_tensor, \n",
    "        output_tensor, \n",
    "        n_elements, \n",
    "        BLOCK_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create input tensor\n",
    "input_tensor = torch.arange(300, dtype=torch.float32, device='cuda')\n",
    "# Create output tensor to hold the result\n",
    "output_tensor = torch.empty(150, dtype=torch.float32, device='cuda')\n",
    "\n",
    "# Call the wrapper function\n",
    "stride_copy_wrapper(input_tensor, output_tensor)\n",
    "\n",
    "# Verify the result\n",
    "print(output_tensor)  # Should contain [1, 3, 5, ..., 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoPE Forward Pass Implementation\n",
    "\n",
    "A work in progress implementation of RoPE forward pass in Triton.\n",
    "Trying to understand the micro kernels required to make this efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the initial implementation for the RoPE kernel in Triton\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n",
    "@triton.jit\n",
    "def rope_kernel(\n",
    "    q_ptr,\n",
    "    k_ptr,\n",
    "    cos_ptr,\n",
    "    sin_ptr,\n",
    "    out_ptr,\n",
    "    n_elements,\n",
    "    BLOCK_SIZE: tl.constexpr  # Block size for parallel processing\n",
    "):\n",
    "    # Define the program's index in the grid\n",
    "    pid = tl.program_id(0)\n",
    "\n",
    "    # Calculate start index for this program\n",
    "    start = pid * BLOCK_SIZE\n",
    "\n",
    "    # Create offsets within the block\n",
    "    offsets = start + tl.arange(0, BLOCK_SIZE)\n",
    "\n",
    "    # Check if offsets are within bounds\n",
    "    mask = offsets < n_elements\n",
    "\n",
    "    # Load query, key, cos and sin values from memory with masking\n",
    "    q = tl.load(q_ptr + offsets, mask=mask)\n",
    "    k = tl.load(k_ptr + offsets, mask=mask)\n",
    "    cos = tl.load(cos_ptr + offsets, mask=mask)\n",
    "    sin = tl.load(sin_ptr + offsets, mask=mask)\n",
    "\n",
    "    q_real = q[:, :, ::2]  # Even indices\n",
    "    q_imag = q[:, :, 1::2]  # Odd indices\n",
    "    q_rotated_real = q_real * cos - q_imag * sin\n",
    "    q_rotated_imag = q_real * sin + q_imag * cos\n",
    "\n",
    "    # For key: k_rotated = [k_real * cos - k_imag * sin,\n",
    "    #                       k_real * sin + k_imag * cos]\n",
    "    k_real = k[..., ::2]  # Even indices\n",
    "    k_imag = k[..., 1::2]  # Odd indices\n",
    "    k_rotated_real = k_real * cos - k_imag * sin\n",
    "    k_rotated_imag = k_real * sin + k_imag * cos\n",
    "\n",
    "    # Store rotated vectors back to memory\n",
    "    tl.store(out_ptr + offsets * 2, q_rotated_real, mask=mask)\n",
    "    tl.store(out_ptr + offsets * 2 + 1, q_rotated_imag, mask=mask)\n",
    "    tl.store(out_ptr + n_elements * 2 + offsets * 2, k_rotated_real, mask=mask)\n",
    "    tl.store(out_ptr + n_elements * 2 + offsets * 2 + 1, k_rotated_imag, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "n_elements = 1024\n",
    "DEVICE = 'cuda:0' # There should be a better way to capture this\n",
    "q_ptr = torch.randn((1, n_elements), device=DEVICE)\n",
    "k_ptr = torch.randn((1, n_elements), device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ptr = torch.zeros((1, n_elements), device=DEVICE)\n",
    "# DEVICE = triton.runtime.driver.active.get_active_torch_device()\n",
    "\n",
    "torch_device = torch.device(DEVICE)\n",
    "assert q_ptr.device == torch_device and k_ptr.device == torch_device and \\\n",
    "    out_ptr.device == torch_device\n",
    "\n",
    "# Use a 1D grid.\n",
    "grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
    "rope_kernel[grid](\n",
    "    q_ptr,\n",
    "    k_ptr,\n",
    "    rope_ref.cos,\n",
    "    rope_ref.sin,\n",
    "    out_ptr,\n",
    "    n_elements,\n",
    "    BLOCK_SIZE=32\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
